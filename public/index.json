[{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"https://nabergoj.org/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"https://nabergoj.org/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"Leetcode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"https://nabergoj.org/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"Leetcode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"https://nabergoj.org/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"Leetcode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. Leetcode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"https://nabergoj.org/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"Leetcode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"https://nabergoj.org/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"}]