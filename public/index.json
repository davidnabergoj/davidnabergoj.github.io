[{"content":"This is the first post in a series solving problems from Fifty Challenging Problems in Probability by Frederick Mosteller (1987). The problem is paraphrased below; for reference, it is inspired by the original book.\nA drawer contains some red and black socks. Two socks are drawn at random, and the probability that both are red is \\(1/2\\).\nWhat is the minimum total number of socks? What is the minimum if the number of black socks is even? Let\u0026rsquo;s dive in!\nSetting up the basic equation We want to express the probability of drawing two red socks. Let \\(r\\) denote the number of red socks and let \\(b\\) denote the number of black socks. We consider two events:\n\\(R_1\\), the event that the first sock we draw is red. \\(R_2\\), the event that the second sock we draw is red. The probability that they are both red can be expressed as \\(p = P(R_1) P(R_2 | R_1)\\). In other words, the probability that we draw red first multiplied by the probability that we draw red second under the condition that we already drew red first.\nWe can compute the first as \\(P(R_1) = r / (r + b)\\), since we wish to draw one of \\(r\\) red socks out of a drawer containing \\(r + b\\) total socks. We can compute the second as \\(P(R_2 | R_1) = (r - 1) / (r + b - 1)\\). That\u0026rsquo;s because we are picking between \\(r-1\\) remaining red socks (remember: we already drew one) among \\(r + b - 1\\) remaining total socks.\nLet\u0026rsquo;s summarize the basic equation: \\[\r\\frac{r}{r+b} \\frac{r-1}{r+b-1} = \\frac{1}{2}.\r\\]The key idea We observe that \\(r / (r + b) \u003e (r - 1) / (r + b - 1)\\). Let\u0026rsquo;s verify this:\n$$\r\\begin{align}\r\\frac{r}{r+b} \u0026\u003e \\frac{r-1}{r+b-1} \\\\\rr(r+b-1) \u0026\u003e (r+b)(r-1) \\\\\rr^2 + rb - r \u0026\u003e r^2 - r + rb - b \\\\\r0 \u0026\u003e -b \\\\\rb \u0026\u003e 0\r\\end{align}\r$$\\[\r\\frac{r}{r+b} \u003e \\frac{r-1}{r+b-1} \\\\\rr(r+b-1) \u003e (r+b)(r-1) \\\\\rr^2+rb-r \u003e r^2-r+rb-b \\\\\r0 \u003e -b \\\\\rb \u003e 0\r\\]Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More FCPP solutions coming soon :)\n","permalink":"http://localhost:1313/posts/fcpp_1_the_sock_drawer/","summary":"\u003cp\u003eThis is the first post in a series solving problems from \u003ca href=\"https://www.amazon.com/Challenging-Problems-Probability-Solutions-Mathematics/dp/0486653552\"\u003e\u003cem\u003eFifty Challenging Problems in Probability\u003c/em\u003e by Frederick Mosteller (1987)\u003c/a\u003e.\nThe problem is paraphrased below; for reference, it is inspired by the original book.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eA drawer contains some red and black socks. Two socks are drawn at random, and the probability that both are red is  \\(1/2\\).\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eWhat is the minimum total number of socks?\u003c/li\u003e\n\u003cli\u003eWhat is the minimum if the number of black socks is even?\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"FCPP 1: The Sock Drawer"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 2462: Total Cost to Hire K Workers. The instructions are as follows:\nYou are given a 0-indexed integer array costs where costs[i] is the cost of hiring the \\(i\\)-th worker. You are also given two integers \\(k\\) and candidates. We want to hire exactly \\(k\\) workers according to the following rules:\nYou will run \\(k\\) sessions and hire exactly one worker in each session. In each hiring session, choose the worker with the lowest cost from either the first candidates workers or the last candidates workers. Break the tie by the smallest index. For example, if costs = [3,2,7,7,1,2] and candidates = 2, then in the first hiring session, we will choose the 4th worker because they have the lowest cost [3,2,7,7,**1**,2]. In the second hiring session, we will choose 1st worker because they have the same lowest cost as 4th worker but they have the smallest index [3,**2**,7,7,2]. Please note that the indexing may be changed in the process. If there are fewer than candidates workers remaining, choose the worker with the lowest cost among them. Break the tie by the smallest index. A worker can only be chosen once. Return the total cost to hire exactly \\(k\\) workers.\nConstraints:\n1 \u0026lt;= costs.length \u0026lt;= 10^5 1 \u0026lt;= costs[i] \u0026lt;= 10^5 1 \u0026lt;= k, candidates \u0026lt;= costs.length Let\u0026rsquo;s dive in!\nStrategy Let \\(c\\) denote candidates for brevity.\nA naive strategy is to find the minimum from the first and last \\(c\\) options during each round. Each such round requires \\(2c\\) checking operations, which would give a time complexity of \\(O(kc)\\) across \\(k\\) rounds.\nWe can do better. Let\u0026rsquo;s maintain two priority queues: front and back. front will hold the first \\(c\\) unprocessed workers and back will hold the last \\(c\\) unprocessed workers. Each queue will grant access to its cheapest worker in \\(O(1)\\) time.\nDuring each round, we decide whether to choose the worker from front or back according to their cost. If we choose a worker from front, we add the next unprocessed worker from the left to front. If we choose a worker from back, we add the next unprocessed worker from the right to back. Each time we choose a worker, we increase the running cost to hire our workers.\nThere are two edge cases:\nIf there are at most \\(k\\) workers, then all workers will be accepted. If there are at most \\(2c\\) workers (i.e., \\(n \\leq 2c\\)), then we don\u0026rsquo;t need to maintain two priority queues. We can simply sort the workers by their cost in non-decreasing order and select the first \\(k\\). Implementation Let\u0026rsquo;s look at the code below. We maintain two indices: left and right. left tells us which worker we should add next to front. right tells us which worker we should add next to back. We also consider a technical edge case: if front is empty, we choose from back and vice-versa.\nclass Solution { public: long long totalCost(vector\u0026lt;int\u0026gt;\u0026amp; costs, int k, int candidates) { long long total = 0; size_t n = costs.size(); // Edge case 1 if (n \u0026lt;= k) { for (size_t i = 0; i \u0026lt; k; ++i) { total += costs[i]; } return total; } // Edge case 2 if (n \u0026lt;= 2 * candidates) { sort(costs.begin(), costs.end()); for (size_t i = 0; i \u0026lt; k; ++i) { total += costs[i]; } return total; } priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; front; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; back; for (size_t i = 0; i \u0026lt; candidates; ++i) { front.push(costs[i]); back.push(costs[n - 1 - i]); } size_t left = candidates - 1; size_t right = n - candidates; for (size_t i = 0; i \u0026lt; k; ++i) { if (front.empty() || back.top() \u0026lt; front.top()) { // Hire worker from the back total += back.top(); back.pop(); --right; if (left \u0026lt; right) { // Add new worker to the back back.push(costs[right]); } } else { // Hire worker from the front total += front.top(); front.pop(); ++left; if (left \u0026lt; right) { // Add new worker to the front front.push(costs[left]); } } } return total; } }; We break down the time complexity as follows:\nEdge case 1 requires \\(O(k)\\) time to sum the costs of all workers. This is equal to \\(O(n)\\) since this case only occurs when \\(k \\geq n\\). Edge case 2 requires \\(O(n \\log n)\\) time to sort the workers. Summing the first \\(k\\) costs takes \\(O(k)\\) time, but this is subsumed by the sorting time. The general case: We first make \\(c\\) insertions to each priority queue, with each insertion requiring \\(O(\\log c)\\) time. The time complexity for queue construction is thus \\(O(c \\log c)\\). We then make \\(k\\) iterations. In each iteration, we perform exactly one removal in \\(O(\\log c)\\) time and at most one insertion in \\(O(\\log c)\\) time. Overall, we need \\(O(k \\log c)\\) time for queue processing. The worst-case time complexity over all inputs is \\(O(n\\log n\\). However, time complexity becomes \\(O(c\\log c + k \\log c)\\) for inputs that are not edge cases.\nSince each priority queue holds at most \\(c\\) elements, the auxiliary space complexity is \\(O(c)\\).\nLeetCode indeed reports a runtime of 15 ms (beating 99.48% of other solutions) and a memory use of 74.50 MB (beating 100% of other solutions).\nMinor optimization Instead of constructing the heaps via incremental insertions into a priority_queue (which costs \\(O(c\\log c)\\) time), we can build them in linear time using make_heap (see the documentation). We construct front and back as vector objects and not priority queues. We then push the unsorted worker costs into each one in \\(O(c)\\) time. Finally, we call make_heap, which only requires \\(O(c)\\) time. We also have to modify the push and pop calls, though the high-level logic stays the same.\nLet\u0026rsquo;s look at the modified code for the general case. The actual runtime and space usage are pretty much the exact same, though this method is theoretically slightly faster, requiring \\(O(c)\\) time to construct each heap instead of the previous \\(O(c \\log c)\\).\nvector\u0026lt;int\u0026gt; front, back; front.reserve(candidates); back.reserve(candidates); for (int i = 0; i \u0026lt; candidates; ++i) { front.push_back(costs[i]); back.push_back(costs[n - 1 - i]); } // Build min-heaps make_heap(front.begin(), front.end(), greater\u0026lt;int\u0026gt;()); make_heap(back.begin(), back.end(), greater\u0026lt;int\u0026gt;()); size_t left = candidates - 1; size_t right = n - candidates; for (int i = 0; i \u0026lt; k; ++i) { if (front.empty() || (!back.empty() \u0026amp;\u0026amp; back.front() \u0026lt; front.front())) { // Take from back total += back.front(); pop_heap(back.begin(), back.end(), greater\u0026lt;int\u0026gt;()); back.pop_back(); --right; if (left \u0026lt; right) { back.push_back(costs[right]); push_heap(back.begin(), back.end(), greater\u0026lt;int\u0026gt;()); } } else { // Take from front total += front.front(); pop_heap(front.begin(), front.end(), greater\u0026lt;int\u0026gt;()); front.pop_back(); ++left; if (left \u0026lt; right) { front.push_back(costs[left]); push_heap(front.begin(), front.end(), greater\u0026lt;int\u0026gt;()); } } } Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\nSide note: with this blog post, I\u0026rsquo;ve finished the LeetCode 75 problem list! ðŸ¥³ðŸŽ‰ðŸŽ‰ðŸŽ‰\n","permalink":"http://localhost:1313/posts/leetcode_2462/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/total-cost-to-hire-k-workers/\"\u003eLeetCode problem 2462: Total Cost to Hire K Workers\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou are given a 0-indexed integer array \u003ccode\u003ecosts\u003c/code\u003e where \u003ccode\u003ecosts[i]\u003c/code\u003e is the cost of hiring the \\(i\\)-th worker.\nYou are also given two integers \\(k\\) and \u003ccode\u003ecandidates\u003c/code\u003e. We want to hire exactly \\(k\\) workers according to the following rules:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYou will run \\(k\\) sessions and hire exactly one worker in each session.\u003c/li\u003e\n\u003cli\u003eIn each hiring session, choose the worker with the lowest cost from either the first candidates workers or the last candidates workers. Break the tie by the smallest index.\n\u003cul\u003e\n\u003cli\u003eFor example, if \u003ccode\u003ecosts = [3,2,7,7,1,2]\u003c/code\u003e and \u003ccode\u003ecandidates = 2\u003c/code\u003e, then in the first hiring session, we will choose the 4th worker because they have the lowest cost \u003ccode\u003e[3,2,7,7,**1**,2]\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eIn the second hiring session, we will choose 1st worker because they have the same lowest cost as 4th worker but they have the smallest index \u003ccode\u003e[3,**2**,7,7,2]\u003c/code\u003e. Please note that the indexing may be changed in the process.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eIf there are fewer than candidates workers remaining, choose the worker with the lowest cost among them. Break the tie by the smallest index.\u003c/li\u003e\n\u003cli\u003eA worker can only be chosen once.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eReturn the total cost to hire exactly \\(k\\) workers.\u003c/p\u003e","title":"LeetCode 2462: Total Cost to Hire K Workers"},{"content":"Let\u0026rsquo;s solve LeetCode problem 88: Merge Sorted Array. This problem is quite short and straightforward.\nThe instructions are as follows:\nYou are given two integer arrays nums1 and nums2, sorted in non-decreasing order, and two integers \\(m\\) and \\(n\\), representing the number of elements in nums1 and nums2 respectively. Merge nums1 and nums2 into a single array sorted in non-decreasing order. The final sorted array should not be returned by the function, but instead be stored inside the array nums1. To accommodate this, nums1 has a length of \\(m\\) + \\(n\\), where the first \\(m\\) elements denote the elements that should be merged, and the last \\(n\\) elements are set to 0 and should be ignored. nums2 has a length of \\(n\\).\nConstraints:\nnums1.length == m + n nums2.length == n 0 \u0026lt;= m, n \u0026lt;= 200 1 \u0026lt;= m + n \u0026lt;= 200 -10^9 \u0026lt;= nums1[i], nums2[j] \u0026lt;= 10^9 Let\u0026rsquo;s dive in!\nStrategy and implementation We have to write the result to nums1. If we process the numbers from highest to lowest, we can avoid overwriting the first \\(m\\) values of nums1. Let\u0026rsquo;s create two indices i, j and initialize them to i = m - 1, j = n - 1. We will decrement these indices until they both reach 0. At each step, we do the following:\nIf nums1[i] \u0026gt; nums2[j], then we write nums1[i] to the next slot and decrement i. Otherwise, we write nums2[j] to the next slot and decrement j. The index of the next slot is simply i + j + 1.\nWhen i reaches 0, we write all the remaining values in nums2 to the start of nums1. When j reaches 0, we could write all the remaining values in nums1 to the start of nums1. However, this is already the case! Thus, we don\u0026rsquo;t need to do anything at all.\nLet\u0026rsquo;s look at the code below. I usually use size_t as the index data type, however I opted for int as decrementing past 0 causes an overflow and breaks the program.\nclass Solution { public: void merge(vector\u0026lt;int\u0026gt;\u0026amp; nums1, int m, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int n) { int i = m - 1; int j = n - 1; while (i \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026gt;= 0) { if (nums1[i] \u0026gt;= nums2[j]) { nums1[i + j + 1] = nums1[i]; i--; } else { nums1[i + j + 1] = nums2[j]; j--; } } while (j \u0026gt;= 0) { nums1[j] = nums2[j]; j--; } } }; LeetCode reports a runtime of 0 ms (beating 100% of other solutions) and memory usage of 12.17 MB (beating 95.41% of other solutions). I\u0026rsquo;m pretty sure this is effectively optimal and the memory usage is the lowest it could be.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_88/","summary":"\u003cp\u003eLet\u0026rsquo;s solve \u003ca href=\"https://leetcode.com/problems/merge-sorted-array/\"\u003eLeetCode problem 88: Merge Sorted Array\u003c/a\u003e.\nThis problem is quite short and straightforward.\u003c/p\u003e\n\u003cp\u003eThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou are given two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e, sorted in non-decreasing order, and two integers \\(m\\) and \\(n\\), representing the number of elements in \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e respectively.\nMerge \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e into a single array sorted in non-decreasing order.\nThe final sorted array should not be returned by the function, but instead be stored inside the array \u003ccode\u003enums1\u003c/code\u003e. To accommodate this, \u003ccode\u003enums1\u003c/code\u003e has a length of \\(m\\) + \\(n\\), where the first \\(m\\) elements denote the elements that should be merged, and the last \\(n\\) elements are set to 0 and should be ignored. \u003ccode\u003enums2\u003c/code\u003e has a length of \\(n\\).\u003c/p\u003e","title":"LeetCode 88: Merge Sorted Array"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 216: Combination Sum III. The instructions are as follows:\nFind all valid combinations of \\(k\\) numbers that sum up to \\(n\\) such that the following conditions are true:\nOnly numbers 1 through 9 are used. Each number is used at most once. Return a list of all possible valid combinations. The list must not contain the same combination twice, and the combinations may be returned in any order.\nConstraints:\n2 \u0026lt;= k \u0026lt;= 9 1 \u0026lt;= n \u0026lt;= 60 Let\u0026rsquo;s dive in!\nStrategy and implementation We can approach this problem by trying to fill up an empty vector v to size \\(k\\). Once v has length \\(k\\) and sums to \\(n\\), we add it to the vector of results. If it has length \\(k\\), but does not sum to \\(n\\), then we replace some elements in it.\nA systematic way of doing this is via backtracking. We create a recursive function void solve(size_t total), where total is the current sum of v. The function solve also has access to a global vector v, a global vector of vectors results, a target vector length variable, and a target sum variable.\nDuring each recursive call, we apply one of these three rules:\nIf v has length \\(k\\) and total equals \\(n\\), then we add v to results. If v is shorter than \\(k\\) and total \u0026lt; n, then we add recursively call solve several times. Before each call, we add a new number j to the end of the vector (j has to be bigger than the last element of v, but at most 9). We then call the function with solve(total + j) to indicate the change in the vector sum. During this call, solutions may be added to results. After the call finishes, we pop the last element of v and apply the procedure for the next value of j. If neither of the two rules above applies, we do nothing. Rule 1 and rule 3 are base cases for recursion. If rule 1 applies, we\u0026rsquo;ve identified v as one possible solution. If rule 3 applies, we did not. Rule 2 is the general case, during which we try to recursively construct solution vectors. In rule 2, backtracking occurs when we pop the last element of v.\nLet\u0026rsquo;s look at the code below. In combinationSum3, we set up two global variables and call solve with an empty vector v that has sum 0. Rule 2 is the most interesting part of solve. We start adding digits from j0 onward. If v is empty, we set j0 to 1, as that\u0026rsquo;s the smallest permissible number. If not, we set j0 to be one bigger than the last element of v. Then we add digits j from j0 to 9 inclusive. We apply the recursive call to solve and backtrack after the call finishes.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; results; vector\u0026lt;int\u0026gt; v; size_t targetLength; size_t targetSum; void solve(size_t total) { // Rule 1 if (v.size() == targetLength \u0026amp;\u0026amp; total == targetSum) { results.push_back(v); return; } // Rule 2 if (v.size() \u0026lt; targetLength \u0026amp;\u0026amp; total \u0026lt; targetSum) { size_t j0; if (v.size() == 0) { j0 = 1; } else { j0 = v.back() + 1; } for (size_t j = j0; j \u0026lt;= 9; j++) { v.push_back(j); solve(total + j); v.pop_back(); } return; } // Rule 3: nothing } vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; combinationSum3(int k, int n) { targetLength = k; targetSum = n; solve(0); return results; } }; We can bound the number of solutions to check with \\(9^k\\). A tighter bound is the number of strictly increasing sequences of length \\(k\\) with elements from \\(\\{1, \\dots, 9\\}\\). There are \\(\\binom{9}{k} = 9! / ((9-k)!k!)\\) such sequences. The maximal number of sequences is 126 and occurs at \\(k = 4\\) or \\(k = 5\\). The total number of candidates explored (including those shorter than \\(k\\)) is bounded by \\(\\sum_{i=0}^k \\binom{9}{i}\\), which is maximized when \\(k = 9\\) and equals 512.\nThe space complexity is \\(O(mk)\\) where \\(m\\) is the number of solutions. We can again say \\(m \\leq 126 \\) per the discussion above. Since \\(k \\leq 9\\), we need to store at most \\(9 \\cdot 126 = 1134 \\) digits, which is tiny.\nThe total runtime is effectively constant. LeetCode indeed reports a runtime of 0 ms (beating 100% of other solutions) and a memory use of 8.68 MB (beating 78.86% of other solutions).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_216/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/combination-sum-iii\"\u003eLeetCode problem 216: Combination Sum III\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eFind all valid combinations of \\(k\\) numbers that sum up to \\(n\\) such that the following conditions are true:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eOnly numbers 1 through 9 are used.\u003c/li\u003e\n\u003cli\u003eEach number is used at most once.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eReturn a list of all possible valid combinations. The list must not contain the same combination twice, and the combinations may be returned in any order.\u003c/p\u003e","title":"LeetCode 216: Combination Sum III"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 790: Domino and Tromino Tiling. The instructions are as follows:\nYou have two types of tiles: a 2 x 1 domino shape and a tromino shape. You may rotate these shapes. Given an integer \\(n\\), return the number of ways to tile an 2 x n board. Since the answer may be very large, return it modulo 10^9 + 7. In a tiling, every square must be covered by a tile. Two tilings are different if and only if there are two 4-directionally adjacent cells on the board such that exactly one of the tilings has both squares occupied by a tile.\nLet\u0026rsquo;s dive in!\nCounting the possible tilings Let\u0026rsquo;s look at all possible tilings for a few values of \\(n\\) in the image below. Unique new tilings We notice that each \\(n\\) has a few unique tilings that don\u0026rsquo;t show up before it:\nFor \\(n = 1\\), the last tiling is a unique new vertical domino. For \\(n = 2\\), the last tiling is a unique new pair of horizontal dominos. For \\(n = 3\\), the final two tilings are new and made up of two trominos. For \\(n = 4\\), the final two tilings are new and made up of two trominos and a domino. I\u0026rsquo;ve marked these in the image below. In fact, each new \\(n\\) introduces new unique tilings. Let\u0026rsquo;s look at these for \\(n \\leq 7\\). Clearly, there are always 2 new unique tilings for each \\(n \\geq 3\\).\nHow are the tilings constructed? Aside from these new and unique tilings, we can also notice a pattern in how the other tilings are constructed. Let\u0026rsquo;s consider \\(n = 4\\). I\u0026rsquo;ve purposely arranged the tilings to clearly see the pattern in the image below. The tilings are constructed as follows:\nTake all tilings for \\(n = 3\\) and append the unique tiling from \\(n = 1\\). Take all tilings for \\(n = 2\\) and append the unique tiling from \\(n = 2\\). Take all tilings for \\(n = 1\\) and append the unique tilings from \\(n = 3\\). We cover the edge case of new tilings by taking all the tilings for \\(n = 0\\) (i.e., nothing) and appending the unique tilings from \\(n = 4\\). The number of tilings for \\(n\\) are thus:\n\\[\rt(n) = t(n - 1) + t(n - 2) + \\sum_{i = 0}^{n - 3} 2 t(i).\r\\]The term \\(t(n - 1)\\) corresponds to tilings from \\(n - 1\\) and adding a vertical domino. The term \\(t(n - 2)\\) corresponds to tilings from \\(n - 2\\) and adding a horizontal domino pair. The remaining terms \\(t(i)\\) corresponds to tilings from \\(i\\) and adding two unique tilings (since we know each \\(n \\geq 3\\) has two new unique tilings), which is why each term is multiplied by \\(2\\).\nThis is the dynamic programming recurrence relation.\nSimplifying the recurrence relation We can simplify the equation above with some clever math. First, let\u0026rsquo;s construct a helper term with \\(t(n - 1)\\):\n\\[\rt(n - 1) = t(n - 2) + t(n - 3) + \\sum_{i = 0}^{n - 4} 2 t(i), \\;\\mathrm{therefore} \\\\\rt(n - 2) + t(n - 3) = t(n - 1) - \\sum_{i = 0}^{n - 4} 2 t(i).\r\\]We will use this term as a replacement inside the square brackets in the derivation below:\n\\[\rt(n) = t(n - 1) + t(n - 2) + \\sum_{i = 0}^{n - 3} 2 t(i) \\\\\r= t(n - 1) + t(n - 2) + 2 t(n - 3) + \\sum_{i = 0}^{n - 4} 2 t(i) \\\\\r= t(n - 1) + [t(n - 2) + t(n - 3)] + t(n - 3) + \\sum_{i = 0}^{n - 4} 2 t(i) \\\\\r= t(n - 1) + [t(n - 1) - \\sum_{i = 0}^{n - 4} 2 t(i)] + t(n - 3) + \\sum_{i = 0}^{n - 4} 2 t(i) \\\\\r= 2t(n - 1) + t(n - 3) \\\\\r\\]Full implementation The solution becomes trivial to implement using the simplified formula. We use a, b, c to hold \\(t(i - 3), t(i - 2),\\) and \\(t(i - 1)\\) respectively. We store \\(t(i)\\) inside variable d at each step. We iterate from \\(i = 4\\) to \\(i = n\\). After the loop, the final value \\(t(n)\\) is stored inside d (and c, because of the variable swap). We apply modulo according to the instructions to avoid overflows.\nclass Solution { public: int numTilings(int n) { if (n == 1) { return 1; } else if (n == 2) { return 2; } else if (n == 3) { return 5; } size_t a = 1; size_t b = 2; size_t c = 5; size_t d; for (size_t i = 4; i \u0026lt;= n; ++i) { d = (2 * c + a) % 1000000007; a = b; b = c; c = d; } return d; } }; This solution requires \\(O(n)\\) time and \\(O(1)\\) space. LeetCode reports a runtime of 0 ms (beating 100% of other solutions) and a memory use of 7.78 MB (beating 95.07% of other solutions). Super efficient!\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_790/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/domino-and-tromino-tiling\"\u003eLeetCode problem 790: Domino and Tromino Tiling\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou have two types of tiles: a \u003ccode\u003e2 x 1\u003c/code\u003e domino shape and a tromino shape. You may rotate these shapes.\nGiven an integer \\(n\\), return the number of ways to tile an \u003ccode\u003e2 x n\u003c/code\u003e board. Since the answer may be very large, return it modulo \u003ccode\u003e10^9 + 7\u003c/code\u003e.\nIn a tiling, every square must be covered by a tile. Two tilings are different if and only if there are two 4-directionally adjacent cells on the board such that exactly one of the tilings has both squares occupied by a tile.\u003c/p\u003e","title":"LeetCode 790: Domino and Tromino Tiling"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 875: Koko Eating Bananas. The instructions are as follows:\nKoko loves to eat bananas. There are n piles of bananas, the \\(i\\)-th pile has piles[i] bananas. The guards have gone and will come back in h hours. Koko can decide her bananas-per-hour eating speed of k. Each hour, she chooses some pile of bananas and eats k bananas from that pile. If the pile has less than k bananas, she eats all of them instead and will not eat any more bananas during this hour. Koko likes to eat slowly but still wants to finish eating all the bananas before the guards return. Return the minimum integer k such that she can eat all the bananas within h hours.\nConstraints:\n1 \u0026lt;= piles.length \u0026lt;= 10^4 piles.length \u0026lt;= h \u0026lt;= 10^9 1 \u0026lt;= piles[i] \u0026lt;= 10^9 Let\u0026rsquo;s dive in!\nChecking if a given rate is valid To check if a rate k is valid, we have to first compute the total time spent eating bananas across all piles with rate k and then ensure that this time is at most h. Let\u0026rsquo;s write this as helper function:\nint ceilDivision(int a, int b) { // return ceil(a / b) where a and b are integers return (a + b - 1) / b; } bool validRate(vector\u0026lt;int\u0026gt; *piles, int h, int k) { int total = 0; for (int i = 0; i \u0026lt; piles-\u0026gt;size(); ++i) { total += ceilDivision(piles-\u0026gt;at(i), k); } return total \u0026lt;= h; } If ceilDivision appears too complicated, think about this: the time spent eating pile \\(i\\) is equal to piles[i] / k if k evenly divides piles[i]. If it doesn\u0026rsquo;t, then there are still some bananas leftover and Koko has to spend an hour eating them. We can use the one-liner below.\ntotal += piles-\u0026gt;at(i) / k + (piles-\u0026gt;at(i) % k \u0026gt; 0); This is equivalent to our ceilDivision(piles-\u0026gt;at(i), k) function. More on the function in this StackOverflow discussion.\nBinary search strategy We\u0026rsquo;re trying to find the minimum integer rate k such that Koko can still eat all of the bananas in time h. The maximum possible rate is \\(m\\); the number of bananas on the biggest pile. Since h is at least the number of piles, using rate \\(m\\) means spending one hour for each pile. The minimum possible rate is \\(1\\).\nWe can simply apply binary search on the set \\(\\{1, 2, \\dots, m - 1, m\\}\\). For a candidate rate in the middle between the minimum and maximum rate, we check if it\u0026rsquo;s valid with the validRate function. If the rate is valid, we shift the maximum rate to the candidate rate (since the rate can\u0026rsquo;t be bigger). If it\u0026rsquo;s invalid, we shift the minimum rate to the candidate rate and add \\(1\\) (that\u0026rsquo;s the first rate that could possibly be valid).\nThe implementation is straightforward. Below is the full code.\nclass Solution { public: int ceilDivision(int a, int b) { // return ceil(a / b) where a and b are integers return (a + b - 1) / b; } bool validRate(vector\u0026lt;int\u0026gt; *piles, int h, int k) { int total = 0; for (int i = 0; i \u0026lt; piles-\u0026gt;size(); ++i) { total += ceilDivision(piles-\u0026gt;at(i), k); } return total \u0026lt;= h; } int minEatingSpeed(vector\u0026lt;int\u0026gt;\u0026amp; piles, int h) { int minRate = 1; int maxRate = *max_element(piles.begin(), piles.end()); while (minRate \u0026lt; maxRate) { int midRate = (minRate + maxRate) / 2; if (validRate(\u0026amp;piles, h, midRate)) { maxRate = midRate; } else { minRate = midRate + 1; } } return minRate; } }; This solution requires \\(O(n \\log m)\\) time and \\(O(1)\\) extra space. The time complexity derives from using \\(O(\\log m)\\) binary search steps, each requiring us to check \\(n\\) piles. LeetCode reports a runtime of 11 ms and a memory use of 22.83 MB (beating 76.17% of other solutions).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_875/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/koko-eating-bananas\"\u003eLeetCode problem 875: Koko Eating Bananas\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eKoko loves to eat bananas. There are \u003ccode\u003en\u003c/code\u003e piles of bananas, the \\(i\\)-th pile has \u003ccode\u003epiles[i]\u003c/code\u003e bananas.\nThe guards have gone and will come back in \u003ccode\u003eh\u003c/code\u003e hours.\nKoko can decide her bananas-per-hour eating speed of \u003ccode\u003ek\u003c/code\u003e.\nEach hour, she chooses some pile of bananas and eats \u003ccode\u003ek\u003c/code\u003e bananas from that pile.\nIf the pile has less than \u003ccode\u003ek\u003c/code\u003e bananas, she eats all of them instead and will not eat any more bananas during this hour.\nKoko likes to eat slowly but still wants to finish eating all the bananas before the guards return.\nReturn the minimum integer \u003ccode\u003ek\u003c/code\u003e such that she can eat all the bananas within \u003ccode\u003eh\u003c/code\u003e hours.\u003c/p\u003e","title":"LeetCode 875: Koko Eating Bananas"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 72: Edit distance. The instructions are as follows:\nGiven two strings word1 and word2, return the minimum number of operations required to convert word1 to word2. You have the following three operations permitted on a word:\nInsert a character Delete a character Replace a character Let\u0026rsquo;s dive in!\nThe Wagner-Fischer algorithm There are several types of edit distance. This LeetCode problem defines it as the Levenshtein distance. The most common algorithm to compute it is the Wagner-Fischer algorithm.\nSuppose word1 has length \\(m\\) and word2 has length \\(n\\). The Wagner-Fischer computes a matrix \\(D\\) of size \\((m+1) \\times (n+1)\\) that holds the edit distances between all prefixes of word1 and all prefixes of word2. Computing each edit distance reuses the adjacent edit distances in the matrix, making this a dynamic programming algorithm.\nSuppose word1[:i] is the length-\\(i\\) prefix of word1 and word2[:j] is the length-\\(j\\) prefix of word2. Then \\(D_{i,j}\\) holds the edit distance between word1[:i] and word2[:j].\nWe initialize the first row with values from 0 to \\(n\\) and the first column with values from 0 to \\(m\\). That\u0026rsquo;s because converting an empty string to word2[:j] requires \\(j\\) insertions. Similarly, converting word1[:i] to an empty string requires \\(i\\) deletions.\nHere\u0026rsquo;s the key rule to compute the edit distance:\n\\[\rD_{i,j} = \\min (D_{i-1, j} + 1, D_{i, j - 1} + 1, D_{i-1, j-1} + s),\r\\] where \\(s = 0\\) if word1[i - 1] == word2[j - 1] and \\(s = 1\\) otherwise.\nThe three terms in the minimum respectively correspond to deletion, insertion, and substitution. If we are in cell \\(D_{i,j}\\), then:\n\\(D_{i-1, j} + 1\\) corresponds to deleting word1[i - 1] from word1, \\(D_{i, j - 1} + 1\\) corresponds to inserting word2[j - 1] into word1 to match the longer prefix of word2, \\(D_{i - 1, j - 1} + s\\) corresponds to substituting word1[i - 1] with word2[j - 1] (or doing nothing if they are equal). After filling the matrix in this way, the final edit distance is \\(D_{m,n}\\).\nHere\u0026rsquo;s an example for word1 = \u0026quot;kitten\u0026quot; and word2 = \u0026quot;sitting\u0026quot;. The true edit distance is three: substitute \u0026quot;k\u0026quot; with \u0026quot;s\u0026quot;, substitute \u0026quot;e\u0026quot; with \u0026quot;i\u0026quot;, add \u0026quot;g\u0026quot; to the end.\nk i t t e n 0 1 2 3 4 5 6 s 1 1 1 2 3 4 5 i 2 2 1 2 3 4 5 t 3 3 2 1 2 3 4 t 4 4 3 2 1 2 3 i 5 5 4 3 2 2 3 n 6 6 5 4 3 3 2 g 7 7 6 5 4 4 3 The bottom right value in the matrix is indeed the true distance: 3.\nThe full code is shown below. Before running the Wagner-Fischer algorithm, we check if the two words are equal, which only takes \\(O(\\max(m, n))\\) time. The full algorithm takes \\(O(mn)\\) time and space.\nclass Solution { public: int minDistance(string word1, string word2) { if (word1 == word2) { return 0; } // Wagner-Fischer algorithm size_t m = word1.size(); size_t n = word2.size(); vector\u0026lt;vector\u0026lt;size_t\u0026gt;\u0026gt; d(m + 1, vector\u0026lt;size_t\u0026gt;(n + 1, 0)); for (size_t i = 1; i \u0026lt;= m; ++i) { d[i][0] = i; } for (size_t j = 1; j \u0026lt;= n; ++j) { d[0][j] = j; } for (size_t j = 1; j \u0026lt;= n; ++j) { for (size_t i = 1; i \u0026lt;= m; ++i) { bool substituted = (word1[i - 1] != word2[j - 1]); d[i][j] = min( d[i - 1][j] + 1, // deletion min( d[i][j - 1] + 1, // insertion d[i - 1][j - 1] + substituted // substitution ) ); } } return d[m][n]; } }; Running the code takes 4 ms (beating 81.58% of other solutions) and needs 15 MB of memory (beating 12.96% of other solutions).\nOptimized version with reduced space complexity The Wagner-Fischer algorithm can be optimized to use less space. The code above has to fill the matrix column-by-column. However, filling each cell only needs the values of the cells to the left, above, and to the top-left. This means we only need to keep:\nthe current column (namely the values above the current cell), and the column to the left of the current one. Now the space complexity will only be \\(O(m)\\), substantially less than \\(O(nm)\\). The time complexity remains the same.\nIt\u0026rsquo;s equivalent to keep two rows instead of two columns, as it\u0026rsquo;s essentially working with a transposed matrix \\(D\\). We\u0026rsquo;ll use the rows strategy so we can easily keep track of rows with the swap function. We\u0026rsquo;ll have a top row and a bottom row. Each row will have \\(n + 1\\) elements. After processing all characters in both words, we will implicitly have filled up all rows in the matrix. The result is stored in the last element of the bottom row.\nLet\u0026rsquo;s look at the code below. There\u0026rsquo;s a small optimization: if word1 with length \\(m\\) is shorter than word2 with length \\(n\\), we swap them. This brings down the space complexity to \\(O(\\min (m, n))\\) because \\(m \u003c n\\) and we now only have \\(m+1\\) elements in each row.\nclass Solution { public: int minDistance(string word1, string word2) { if (word1 == word2) { return 0; } if (word1.size() \u0026lt; word2.size()) { swap(word1, word2); } // Wagner-Fischer algorithm size_t m = word1.size(); size_t n = word2.size(); // Only store two rows vector\u0026lt;size_t\u0026gt; top(n + 1, 0); vector\u0026lt;size_t\u0026gt; bottom(n + 1, 0); for (size_t j = 1; j \u0026lt;= n; ++j) { top[j] = j; } for (size_t i = 1; i \u0026lt;= m; ++i) { bottom[0] = i; for (size_t j = 1; j \u0026lt;= n; ++j) { bool substituted = (word1[i - 1] != word2[j - 1]); bottom[j] = min( min( top[j] + 1, // deletion bottom[j - 1] + 1 // insertion ), top[j - 1] + substituted // substitution ); } swap(top, bottom); } return top[n]; // because of the swap } }; Running the code now takes 0 ms (beating 100% of other solutions) and needs 10.4 MB of memory (beating 98.46% of other solutions). The used space in the optimized version is about 2/3 of the space in the basic version of the algorithm.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_72/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/edit-distance\"\u003eLeetCode problem 72: Edit distance\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eGiven two strings \u003ccode\u003eword1\u003c/code\u003e and \u003ccode\u003eword2\u003c/code\u003e, return the minimum number of operations required to convert \u003ccode\u003eword1\u003c/code\u003e to \u003ccode\u003eword2\u003c/code\u003e. You have the following three operations permitted on a word:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eInsert a character\u003c/li\u003e\n\u003cli\u003eDelete a character\u003c/li\u003e\n\u003cli\u003eReplace a character\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLet\u0026rsquo;s dive in!\u003c/p\u003e\n\u003ch2 id=\"the-wagner-fischer-algorithm\"\u003eThe Wagner-Fischer algorithm\u003c/h2\u003e\n\u003cp\u003eThere are several types of \u003ca href=\"https://en.wikipedia.org/wiki/Edit_distance\"\u003eedit distance\u003c/a\u003e.\nThis LeetCode problem defines it as the \u003ca href=\"https://en.wikipedia.org/wiki/Levenshtein_distance\"\u003eLevenshtein distance\u003c/a\u003e.\nThe most common algorithm to compute it is the \u003ca href=\"https://en.wikipedia.org/wiki/Wagner%E2%80%93Fischer_algorithm\"\u003eWagner-Fischer algorithm\u003c/a\u003e.\u003c/p\u003e","title":"LeetCode 72: Edit distance"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 746: Min Cost Climbing Stairs. The instructions are as follows:\nYou are given an integer array cost where cost[i] is the cost of \\(i\\)-th step on a staircase. Once you pay the cost, you can either climb one or two steps. You can either start from the step with index 0, or the step with index 1. Return the minimum cost to reach the top of the floor.\nLet\u0026rsquo;s dive in!\nStrategy and solution Let\u0026rsquo;s think about the minimum cost required to reach stair \\(i\\). We could have arrived there from:\nstair \\(i-2\\), costing cost[i - 2] plus the minimum cost to arrive at stair \\(i - 2\\), or stair \\(i-1\\), costing cost[i - 1] plus the minimum cost to arrive at stair \\(i - 1\\). The cheapest path means taking the stair with the lower cost. If \\(m_i\\) is the minimum cost to arrive at stair \\(i\\) and \\(c_i\\) is cost[i], we can write the recurrence as:\n\\[\rm_i = \\min(c_{i - 2} + m_{i - 2}, c_{i - 1} + m_{i - 1}).\r\\]Since we can start at either stair 0 or stair 1, arriving there costs nothing. Therefore \\(m_0 = m_1 = 0\\). We could program this recursively and memoize the results to avoid recomputation. However, it\u0026rsquo;s much easier to simply use an iterative approach.\nLet\u0026rsquo;s look at the code below. We use minCost1 to hold \\(m_{i-2}\\) and minCost2 to hold \\(m_{i-1}\\). We store \\(m_i\\) inside minCost3. After each iteration, we set minCost1 to minCost2 and minCost2 to minCost3. The final result is in minCost2. This is similar to iteratively computing a number from the Fibonacci sequence.\nclass Solution { public: int minCostClimbingStairs(vector\u0026lt;int\u0026gt;\u0026amp; cost) { size_t minCost1 = 0; // cost to reach first stair size_t minCost2 = 0; // cost to reach second stair size_t minCost3; for (size_t i = 2; i \u0026lt;= cost.size(); ++i) { minCost3 = min( minCost1 + cost[i - 2], minCost2 + cost[i - 1] ); minCost1 = minCost2; minCost2 = minCost3; } return minCost2; } }; Given \\(n\\) stairs, the code requires \\(O(n)\\) time and \\(O(1)\\) space, which looks to be optimal. LeetCode reports a runtime of 0 ms (beating 100% of other solutions) and memory use of 17.56 MB, which is effectively just from the input data. Our actual code only uses a few integers. A very efficient solution!\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_746/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/min-cost-climbing-stairs\"\u003eLeetCode problem 746: Min Cost Climbing Stairs\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou are given an integer array \u003ccode\u003ecost\u003c/code\u003e where \u003ccode\u003ecost[i]\u003c/code\u003e is the cost of \\(i\\)-th step on a staircase. Once you pay the cost, you can either climb one or two steps.\nYou can either start from the step with index 0, or the step with index 1.\nReturn the minimum cost to reach the top of the floor.\u003c/p\u003e","title":"LeetCode 746: Min Cost Climbing Stairs"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 435: Non-overlapping intervals. The instructions are as follows:\nGiven an array of intervals intervals where intervals[i] = [start_i, end_i], return the minimum number of intervals you need to remove to make the rest of the intervals non-overlapping. Note that intervals which only touch at a point are non-overlapping. For example, [1, 2] and [2, 3] are non-overlapping.\nLet\u0026rsquo;s dive in!\nInterval scheduling reformulation Interval scheduling is a class of problems that involve a set of tasks, represented by their start and end times. The interval scheduling maximization problem (ISMP) is about finding the largest set of non-overlapping tasks. This is highly related to our interval removal problem. In fact, the following statements are equivalent:\nn is the total number of tasks and k is the maximum number of non-overlapping tasks that can be executed; the minimum number of intervals to make the rest non-overlapping is n - k. Let\u0026rsquo;s solve a variant of the well-known ISMP and use the result to answer the removal question. This is the single-interval scheduling problem (SISP), where we create an interval schedule in which no intervals overlap. A greedy algorithm called Earliest deadline first (EDF) finds the optimal solution to SISP. It\u0026rsquo;s described as follows:\nSelect the interval x with the earliest finishing time. Remove x and all intervals intersecting it from the set of candidate intervals. Repeat until there are no more candidate intervals. EDF starts by sorting the intervals by their end time in non-decreasing order. It then processes intervals from first to last.\nThis problem is also related to a similar interview question: maximum number of meetings in one room.\nSolving the counting problem Since we only need to count the number of compatible intervals, we don\u0026rsquo;t need to actually perform any removals. Instead, we start by sorting the intervals according to their end times. We initialize a counter k = 1 that counts the number of non-overlapping intervals. The first non-overlapping interval is simply the first one in the sorted list, i.e., the interval at index 0. We store its index in a variable prev = 0. Then loop over the rest of the intervals, starting at index i = 1. At each index, we check if interval at index i overlaps with the previously executed one. If so, we increment k and set prev = i. Otherwise, we simply move forward, as the interval at index i was caught in an overlap. We finally return n - k.\nLet\u0026rsquo;s look at the full code below.\nclass Solution { public: int eraseOverlapIntervals(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; intervals) { // Sort by end times sort( intervals.begin(), intervals.end(), [](const vector\u0026lt;int\u0026gt;\u0026amp; left, const vector\u0026lt;int\u0026gt;\u0026amp; right) { return left[1] \u0026lt; right[1]; } ); // Apply *Earliest deadline first* (EDF) size_t prev = 0; size_t k = 1; for (size_t i = 1; i \u0026lt; intervals.size(); ++i) { if (intervals[i][0] \u0026gt;= intervals[prev][1]) { k++; prev = i; } } // Return the number of intervals to remove return intervals.size() - k; } }; Complexity and empirical performance Our counting variant of EDF takes \\(O(n \\log n)\\) time to sort the intervals and \\(O(n)\\) to count the number of compatible intervals, so the total time complexity is \\(O(n \\log n)\\). Ignoring the input data, the space complexity is \\(O(1)\\) as we only need to use two integers: prev and k. LeetCode reports a runtime of 35 ms, which beats 95.23% of all solutions, as well as memory usage of 93.79 MB, which beats 98.60% of all solutions.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_435/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/non-overlapping-intervals\"\u003eLeetCode problem 435: Non-overlapping intervals\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eGiven an array of intervals intervals where \u003ccode\u003eintervals[i] = [start_i, end_i]\u003c/code\u003e, return the minimum number of intervals you need to remove to make the rest of the intervals non-overlapping.\nNote that intervals which only touch at a point are non-overlapping. For example, \u003ccode\u003e[1, 2]\u003c/code\u003e and \u003ccode\u003e[2, 3]\u003c/code\u003e are non-overlapping.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLet\u0026rsquo;s dive in!\u003c/p\u003e\n\u003ch2 id=\"interval-scheduling-reformulation\"\u003eInterval scheduling reformulation\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Interval_scheduling\"\u003eInterval scheduling\u003c/a\u003e is a class of problems that involve a set of tasks, represented by their start and end times.\nThe \u003cem\u003einterval scheduling maximization problem\u003c/em\u003e (ISMP) is about finding the largest set of non-overlapping tasks.\nThis is highly related to our interval removal problem.\nIn fact, the following statements are equivalent:\u003c/p\u003e","title":"LeetCode 435: Non-overlapping Intervals"},{"content":"Hi, everyone! Today, we\u0026rsquo;ll be looking at LeetCode problem 399. In this problem, we are given a bunch of reference equations of the form \\(a_i / b_i = c_i\\) for \\(i = 1 , \\dots, n\\). The symbols \\(a_i, b_i\\) are given as strings, while \\(c_i\\) are given as floating point numbers. We\u0026rsquo;re then asked to compute the value of a query equation \\(q_1 / q_2\\).\nIf \\(q_1 / q_2\\) is one of the reference equations, we can return that value. Otherwise, we can follow a kind of chain-rule strategy. Suppose we are given \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot; with value 2.0 and \u0026quot;b\u0026quot; / \u0026quot;c\u0026quot; with value 3.0, then we can compute \u0026quot;a\u0026quot; / \u0026quot;c\u0026quot; by the product: \u0026quot;a\u0026quot; / \u0026quot;c\u0026quot; = \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot; * \u0026quot;b\u0026quot; / \u0026quot;c\u0026quot;, which is equal to 2.0 * 3.0 = 6.0. If there\u0026rsquo;s no way to find a solution, we return -1.\nWe\u0026rsquo;ll approach this as a graph problem and use breadth-first search (BFS). Let\u0026rsquo;s dive in!\nConstructing a graph of symbols We approach this problem by first constructing a graph. Each node represents a symbol as given in the reference equations. If there is an edge going from node \u0026quot;a\u0026quot; to node \u0026quot;b\u0026quot;, its value is the reference value \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot;.\nLet\u0026rsquo;s consider an example where the reference equations are [[\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;], [\u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;]] and the reference values are [2.0, 3.0].\nTo find the value of \u0026quot;a\u0026quot; / \u0026quot;c\u0026quot;, we start in node \u0026quot;a\u0026quot;, then traverse past node \u0026quot;b\u0026quot; and arrive at node \u0026quot;c\u0026quot;. We multiply the values of all edges along the way and obtain 6.0.\nIt\u0026rsquo;s possible that an edge might exist from one variable to the other, but we need to traverse the path in the opposite direction. To handle this, we can add another edge whose value is the reciprocal of the reference equation value. For example, if the given equation is \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot; = 2.0, we add edges \u0026quot;a\u0026quot; -\u0026gt; \u0026quot;b\u0026quot; with value 2.0 and \u0026quot;b\u0026quot; -\u0026gt; \u0026quot;a\u0026quot; with value 1 / 2.0.\nEach symbol can be represented as a struct with incoming and outgoing connections. Each connection is a pair containing the other symbol and the edge value.\nstruct Symbol { vector\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; incoming; vector\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; outgoing; }; Let\u0026rsquo;s look at how to construct the graph. We store symbol objects in an unordered map, accessed by string keys. As we traverse the equations, we add new symbols to the map if they don\u0026rsquo;t yet exist. At every step, we also update the incoming and outgoing edges of each symbol with the appropriate equation value.\nvector\u0026lt;double\u0026gt; calcEquation(vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt;\u0026amp; equations, vector\u0026lt;double\u0026gt;\u0026amp; values, vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt;\u0026amp; queries) { unordered_map\u0026lt;string, Symbol*\u0026gt; symbols; for (size_t i = 0; i \u0026lt; equations.size(); ++i) { vector\u0026lt;string\u0026gt; eq = equations[i]; double value = values[i]; string s1 = eq[0]; string s2 = eq[1]; if (!symbols.contains(s1)) { symbols[s1] = new Symbol; } if (!symbols.contains(s2)) { symbols[s2] = new Symbol; } symbols[s1]-\u0026gt;outgoing.push_back({symbols[s2], value}); symbols[s2]-\u0026gt;incoming.push_back({symbols[s1], 1 / value}); } ... // we\u0026#39;ll implement the rest later } Evaluating an equation with BFS We\u0026rsquo;ll evaluate the equation by traversing the graph. However, cycles in the graph might cause us to loop indefinitely. We can avoid this by keeping track of already visited states in a set. We can avoid going to deep into the graph by using BFS instead of depth-first search (DFS), but a DFS solution is possible as well.\nWhen given a query \\(q_1 / q_2\\), we will construct a queue that contains with \\(q_1\\) and the corresponding initial path product 1.0. While the queue is not empty, we will pop its front element and add all its connected nodes to the back of the queue. If the popped element corresponds to \\(q_2\\), we will return the corresponding path product.\nLet\u0026rsquo;s look at the code. We first initialize the set of visited states and a queue containing the symbols and equation values. We then execute the queue loop as outlined above.\ndouble evaluate(Symbol *src, Symbol *dst) { set\u0026lt;Symbol*\u0026gt; visited; queue\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; q; q.push({src, 1.0}); while (!q.empty()) { pair\u0026lt;Symbol*, double\u0026gt; p = q.front(); q.pop(); // If we have not yet visited this symbol if (visited.find(p.first) == visited.end()) { // Have we arrived at the destination? if (p.first == dst) { return p.second; } // Add connecting symbols into ther queue for (auto pNext: p.first-\u0026gt;outgoing) { q.push({pNext.first, pNext.second * p.second}); } for (auto pNext: p.first-\u0026gt;incoming) { q.push({pNext.first, pNext.second * p.second}); } // Mark this symbol as visited visited.insert(p.first); } } // If no solution was found in the loop, return -1 return -1; } Full solution and complexity Below is the full solution code. The only practical addition is constructing an output vector and processing each query equation one-by-one.\nclass Solution { public: struct Symbol { vector\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; incoming; vector\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; outgoing; }; double evaluate(Symbol *src, Symbol *dst) { set\u0026lt;Symbol*\u0026gt; visited; queue\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; q; q.push({src, 1.0}); while (!q.empty()) { pair\u0026lt;Symbol*, double\u0026gt; p = q.front(); q.pop(); if (visited.find(p.first) == visited.end()) { if (p.first == dst) { return p.second; } for (auto pNext: p.first-\u0026gt;outgoing) { q.push({pNext.first, pNext.second * p.second}); } for (auto pNext: p.first-\u0026gt;incoming) { q.push({pNext.first, pNext.second * p.second}); } visited.insert(p.first); } } return -1; } vector\u0026lt;double\u0026gt; calcEquation(vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt;\u0026amp; equations, vector\u0026lt;double\u0026gt;\u0026amp; values, vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt;\u0026amp; queries) { unordered_map\u0026lt;string, Symbol*\u0026gt; symbols; for (size_t i = 0; i \u0026lt; equations.size(); ++i) { vector\u0026lt;string\u0026gt; eq = equations[i]; double value = values[i]; string s1 = eq[0]; string s2 = eq[1]; if (!symbols.contains(s1)) { symbols[s1] = new Symbol; } if (!symbols.contains(s2)) { symbols[s2] = new Symbol; } symbols[s1]-\u0026gt;outgoing.push_back({symbols[s2], value}); symbols[s2]-\u0026gt;incoming.push_back({symbols[s1], 1 / value}); } vector\u0026lt;double\u0026gt; out; for (size_t i = 0; i \u0026lt; queries.size(); ++i) { vector\u0026lt;string\u0026gt; eq = queries[i]; string s1 = eq[0]; string s2 = eq[1]; if (!symbols.contains(s1) || !symbols.contains(s2)) { out.push_back(-1.0); } else { out.push_back(evaluate(symbols[s1], symbols[s2])); } } return out; } }; Suppose there are \\(m\\) symbols in the \\(n\\) referenced equations. To evaluate a new query with BFS, we have to traverse at most \\(m\\) symbols. We can check whether a symbol is in symbol set or not in \\(O(1)\\) time, as the unordered set is implemented as a hash table with constant-time lookup. Given \\(k\\) queries, the worst-case time complexity is thus \\(O(km)\\).\nWe also need to store \\(m\\) symbols, at most \\(n\\) outgoing edges, and at most \\(n\\) incoming edges. Within each evaluation call, the constructed queue contains a variable amount of elements, potentially more than \\(m\\) depending on the input graph. However, never more than \\(m^2\\). The practical space complexity is \\(O(m+n)\\) to hold the graph and \\(O(m)\\) for the queue, although it can be dominated by \\(O(m^2)\\) for complicated input graphs. Let\u0026rsquo;s say \\(O(n+m)\\) for practical cases.\nLeetCode reports that this algorithm runs in 0ms, beating 100% of solution in runtime. It takes 11.75 MB memory, beating 80.54% in space utilization. That\u0026rsquo;s quite good!\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_399/","summary":"\u003cp\u003eHi, everyone! Today, we\u0026rsquo;ll be looking at \u003ca href=\"https://leetcode.com/problems/evaluate-division/?envType=study-plan-v2\u0026amp;envId=leetcode-75\"\u003eLeetCode problem 399\u003c/a\u003e.\nIn this problem, we are given a bunch of reference equations of the form \\(a_i / b_i = c_i\\) for \\(i = 1 , \\dots, n\\).\nThe symbols \\(a_i, b_i\\) are given as strings, while \\(c_i\\) are given as floating point numbers.\nWe\u0026rsquo;re then asked to compute the value of a \u003cem\u003equery\u003c/em\u003e equation \\(q_1 / q_2\\).\u003c/p\u003e\n\u003cp\u003eIf \\(q_1 / q_2\\) is one of the reference equations, we can return that value.\nOtherwise, we can follow a kind of \u003cem\u003echain-rule\u003c/em\u003e strategy.\nSuppose we are given \u003ccode\u003e\u0026quot;a\u0026quot; / \u0026quot;b\u0026quot;\u003c/code\u003e with value \u003ccode\u003e2.0\u003c/code\u003e and \u003ccode\u003e\u0026quot;b\u0026quot; / \u0026quot;c\u0026quot;\u003c/code\u003e with value \u003ccode\u003e3.0\u003c/code\u003e, then we can compute \u003ccode\u003e\u0026quot;a\u0026quot; / \u0026quot;c\u0026quot;\u003c/code\u003e by the product:\n\u003ccode\u003e\u0026quot;a\u0026quot; / \u0026quot;c\u0026quot; = \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot; * \u0026quot;b\u0026quot; / \u0026quot;c\u0026quot;\u003c/code\u003e, which is equal to \u003ccode\u003e2.0 * 3.0 = 6.0\u003c/code\u003e.\nIf there\u0026rsquo;s no way to find a solution, we return \u003ccode\u003e-1\u003c/code\u003e.\u003c/p\u003e","title":"LeetCode 399: Evaluate Division"},{"content":"Very quick post about finding the peak element in an array. This is LeetCode problem 162. We have an array nums with \\(n\\) integers and want to find the index of one of its peaks in \\(O(\\log n)\\) time. The important detail is this: no two neighboring elements have the same value.\nLet\u0026rsquo;s dive in!\nSolution To solve this in logarithmic time, we will use binary search. We start with a left index and a right index. We then compute a mid point mid = (left + right) / 2. Now we investigate what the local behavior around mid is. If nums[mid] \u0026gt; nums[mid + 1], it means that there\u0026rsquo;s no point searching for the peak at mid + 1 or to its right, so we set right = mid. Otherwise, there\u0026rsquo;s no point in searching for the peak at mid or to its left, so we set left = mid + 1.\nWe keep repeating this until left is greater or equal to right. Here\u0026rsquo;s the code:\nclass Solution { public: int findPeakElement(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int left = 0; int right = nums.size() - 1; int mid; while (left \u0026lt; right) { int mid = (left + right) / 2; if (nums[mid] \u0026gt; nums[mid + 1]) { right = mid; } else { left = mid + 1; } } return left; } }; The code beats 100% of other solutions in terms of runtime. The time complexity is \\(O(\\log n)\\), because we narrow down the search to half of the array in each loop iteration. Even more precisely, the number of iterations is at most \\(\\lceil \\log_2 n \\rceil\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_162/","summary":"\u003cp\u003eVery quick post about finding the peak element in an array.\nThis is \u003ca href=\"https://leetcode.com/problems/find-peak-element\"\u003eLeetCode problem 162\u003c/a\u003e.\nWe have an array \u003ccode\u003enums\u003c/code\u003e with \\(n\\) integers and want to find the index of one of its peaks in \\(O(\\log n)\\) time.\nThe important detail is this: no two neighboring elements have the same value.\u003c/p\u003e\n\u003cp\u003eLet\u0026rsquo;s dive in!\u003c/p\u003e\n\u003ch2 id=\"solution\"\u003eSolution\u003c/h2\u003e\n\u003cp\u003eTo solve this in logarithmic time, we will use binary search.\nWe start with a \u003ccode\u003eleft\u003c/code\u003e index and a \u003ccode\u003eright\u003c/code\u003e index.\nWe then compute a mid point \u003ccode\u003emid = (left + right) / 2\u003c/code\u003e.\nNow we investigate what the local behavior around \u003ccode\u003emid\u003c/code\u003e is.\nIf \u003ccode\u003enums[mid] \u0026gt; nums[mid + 1]\u003c/code\u003e, it means that there\u0026rsquo;s no point searching for the peak at \u003ccode\u003emid + 1\u003c/code\u003e or to its right, so we set \u003ccode\u003eright = mid\u003c/code\u003e.\nOtherwise, there\u0026rsquo;s no point in searching for the peak at \u003ccode\u003emid\u003c/code\u003e or to its left, so we set \u003ccode\u003eleft = mid + 1\u003c/code\u003e.\u003c/p\u003e","title":"LeetCode 162: Find Peak Element"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! And it\u0026rsquo;s very intuitive!\nSimplifying the action tree We\u0026rsquo;ll simplify the action tree in two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\]What are the initial values? If we buy on day 1, we have \\(H_1 = -S_1 - f\\). If we don\u0026rsquo;t we have \\(F_1 = 0\\). If there are \\(n\\) days, then our output will be \\(F_n\\). After all, it\u0026rsquo;s better to have sold our last stock than to still be holding it.\nFull solution and time complexity analysis The implementation is super straightforward. We simply apply the formula every day:\nclass Solution { public: int maxProfit(vector\u0026lt;int\u0026gt;\u0026amp; prices, int fee) { int holdBalance = -fee - prices[0]; // H_i int freeBalance = 0; // F_i for (size_t i = 1; i \u0026lt; prices.size(); ++i) { int newHoldBalance = max(holdBalance, freeBalance - fee - prices[i]); int newFreeBalance = max(freeBalance, holdBalance + prices[i]); holdBalance = newHoldBalance; freeBalance = newFreeBalance; } return freeBalance; } } That\u0026rsquo;s it! LeetCode says this solution takes 0 ms, beating 100% of other solutions in terms of runtime. It takes 58.98 MB memory, but this is only due to the input array and LeetCode\u0026rsquo;s overhead. We\u0026rsquo;re only using four integers after all.\nThe time complexity is \\(O (n)\\) as we only have to loop through the prices array once. The space complexity is \\(O(1)\\) as we only use four integers regardless of \\(n\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"This is the first post in a series solving problems from Fifty Challenging Problems in Probability by Frederick Mosteller (1987). The problem is paraphrased below; for reference, it is inspired by the original book.\nA drawer contains some red and black socks. Two socks are drawn at random, and the probability that both are red is \\(1/2\\).\nWhat is the minimum total number of socks? What is the minimum if the number of black socks is even? Let\u0026rsquo;s dive in!\nSetting up the basic equation We want to express the probability of drawing two red socks. Let \\(r\\) denote the number of red socks and let \\(b\\) denote the number of black socks. We consider two events:\n\\(R_1\\), the event that the first sock we draw is red. \\(R_2\\), the event that the second sock we draw is red. The probability that they are both red can be expressed as \\(p = P(R_1) P(R_2 | R_1)\\). In other words, the probability that we draw red first multiplied by the probability that we draw red second under the condition that we already drew red first.\nWe can compute the first as \\(P(R_1) = r / (r + b)\\), since we wish to draw one of \\(r\\) red socks out of a drawer containing \\(r + b\\) total socks. We can compute the second as \\(P(R_2 | R_1) = (r - 1) / (r + b - 1)\\). That\u0026rsquo;s because we are picking between \\(r-1\\) remaining red socks (remember: we already drew one) among \\(r + b - 1\\) remaining total socks.\nLet\u0026rsquo;s summarize the findings: \\[\r\\frac{r}{r+b} \\cdot \\frac{r-1}{r+b-1} = \\frac{1}{2}.\r\\]The key inequality We can observe the following: \\[\r\\frac{r}{r + b} \u003e \\frac{r - 1}{r + b - 1}.\r\\]This is the most crucial observation to solving our problem. Let\u0026rsquo;s verify it:\n$$\r\\begin{aligned}\r\\frac{r}{r+b} \u0026\u003e \\frac{r-1}{r+b-1} \\\\\rr(r+b-1) \u0026\u003e (r+b)(r-1) \\\\\rr^2 + rb - r \u0026\u003e r^2 - r + rb - b \\\\\r0 \u0026\u003e -b \\\\\rb \u0026\u003e 0.\r\\end{aligned}\r$$The final statement is true, because we\u0026rsquo;re solving a problem with a positive number of black (and red) socks.\nImplications of the inequality Several things naturally follow from our established inequality. First, we can say: \\[\r\\left(\\frac{r}{r+b}\\right)^2 \u003e \\frac{1}{2} \\quad \\textrm{and also} \\quad \\left(\\frac{r-1}{r+b-1}\\right)^2 \u003c \\frac{1}{2}.\r\\] Let\u0026rsquo;s put the two statements together: \\[\r\\left(\\frac{r}{r+b}\\right)^2 \u003e \\frac{1}{2} \u003e \\left(\\frac{r-1}{r+b-1}\\right)^2.\r\\]Solving this is cumbersome due to the squares. Let\u0026rsquo;s take the square root instead (since all terms are positive): \\[\r\\frac{r}{r+b} \u003e \\frac{1}{\\sqrt{2}} \u003e \\frac{r-1}{r+b-1}.\r\\]Bounding \\(r\\) with \\(b\\) We now have two inequalities, which we can potentially rearrange to bound the number of one type of socks with the other. Let\u0026rsquo;s try to bound \\(r\\) with \\(b\\).\nWe can rearrange the first equality for the first bound: \\[\r\\begin{aligned}\r\\frac{r}{r+b} \u0026\u003e \\frac{1}{\\sqrt{2}} \\\\\rr \u0026\u003e \\frac{r + b}{\\sqrt{2}} \\\\\rr \u0026\u003e \\frac{r}{\\sqrt{2}} + \\frac{b}{\\sqrt{2}} \\\\\rr - \\frac{r}{\\sqrt{2}} \u0026\u003e \\frac{b}{\\sqrt{2}} \\\\\r\\frac{r\\sqrt{2} - r}{\\sqrt{2}} \u0026\u003e \\frac{b}{\\sqrt{2}} \\\\\rr\\sqrt{2} - r \u0026\u003e b \\\\\rr(\\sqrt{2} - 1) \u0026\u003e b \\\\\rr \u0026\u003e \\frac{b}{\\sqrt{2} - 1}. \\\\\r\\end{aligned}\r\\]We can also rearrange the second inqeuality for the second bound: \\[\r\\begin{aligned}\r\\frac{1}{\\sqrt{2}} \u0026\u003e \\frac{r-1}{r+b-1} \\\\\r\\frac{r-1}{r+b-1} \u0026\u003c \\frac{1}{\\sqrt{2}} \\\\\rr-1 \u0026\u003c \\frac{r+b-1}{\\sqrt{2}} \\\\\rr-1 \u0026\u003c \\frac{r}{\\sqrt{2}} + \\frac{b-1}{\\sqrt{2}} \\\\\rr-\\frac{r}{\\sqrt{2}} \u0026\u003c 1 + \\frac{b-1}{\\sqrt{2}} \\\\\rr-\\frac{r}{\\sqrt{2}} \u0026\u003c \\frac{b + \\sqrt{2} - 1}{\\sqrt{2}} \\\\\r\\frac{r(\\sqrt{2} - 1)}{\\sqrt{2}} \u0026\u003c \\frac{b + \\sqrt{2} - 1}{\\sqrt{2}} \\\\\rr(\\sqrt{2} - 1) \u0026\u003c b + \\sqrt{2} - 1 \\\\\rr \u0026\u003c \\frac{b + \\sqrt{2} - 1}{\\sqrt{2} - 1} \\\\\rr \u0026\u003c \\frac{(b + (\\sqrt{2} -1))(\\sqrt{2} + 1)}{(\\sqrt{2} - 1)(\\sqrt{2} + 1)} \\\\\rr \u0026\u003c \\frac{b (\\sqrt{2} + 1) + 1}{1} \\\\\rr - 1 \u0026\u003c b (\\sqrt{2} + 1). \\\\\rr \u0026\u003c b (\\sqrt{2} + 1) + 1. \\\\\r\\end{aligned}\r\\]Now we can finally express full the bound as:\n\\[\rb (\\sqrt{2} + 1) \u003c r \u003c b (\\sqrt{2} + 1) + 1.\r\\]And since we\u0026rsquo;re looking for integer valued solutions, we can say: \\[\rr = \\left\\lceil b(\\sqrt{2} + 1) \\right\\rceil.\r\\]Finding suitable values of \\(r\\) and \\(b\\) Let\u0026rsquo;s try a few values of \\(b\\) and keep in mind that \\(\\sqrt{2} + 1 \\approx 2.41\\).\nIf \\(b = 1\\), then \\(r = 3\\) is the integer-valued solution. Let\u0026rsquo;s plug both values into the probability equation:\n\\[\r\\frac{r}{r+b} \\frac{r-1}{r+b-1} = \\frac{3}{4} \\cdot \\frac{2}{3} = \\frac{1}{2}.\r\\]So \\(r = 3, b = 1\\) is a solution! In fact, \\(b\\) can\u0026rsquo;t possibly be smaller, so this solution answers question (a): the minimum number of socks is \\( 3 + 1 = 4\\).\nLet\u0026rsquo;s try \\(b = 2\\); \\(r = 5\\) is the possible integer-valued solution. If we plug them into the probability formula, we get: \\[\r\\frac{r}{r+b} \\frac{r-1}{r+b-1} = \\frac{5}{7} \\cdot \\frac{4}{6} = \\frac{10}{21}.\r\\]Unfortunately, the probability is not equal to \\(1/2\\), so this is not a valid solution.\nWhile there is a real-valued solution for \\(r\\) in \\(\\left[b(\\sqrt{2}-1), b(\\sqrt{2}-1)+1 \\right]\\), there is no integer-valued solution. Only some values of \\(b\\) give valid values of \\(r\\). Let\u0026rsquo;s check them programatically to speed up our search. I\u0026rsquo;ve written a small Python script to do so:\nimport math c = math.sqrt(2) + 1 for b in range(1, 10000): r = int(math.ceil(b * c)) prob = r / (r + b) * (r - 1) / (r + b - 1) eps = 1e-10 if 0.5 - eps \u0026lt; prob \u0026lt; 0.5 + eps: print(f\u0026#39;r: {r}, b: {b} -\u0026gt; {prob}\u0026#39;) This script prints values of \\(r\\) and \\(b\\) when the probability is equal to 0.5 (allowing for some numerical imprecision). This will give us suitable candidates that we can check by hand. Running the script gives the following output:\nr: 3, b: 1 -\u0026gt; 0.5\rr: 15, b: 6 -\u0026gt; 0.5\rr: 85, b: 35 -\u0026gt; 0.5\rr: 493, b: 204 -\u0026gt; 0.5\rr: 2871, b: 1189 -\u0026gt; 0.5000000000000001\rr: 16731, b: 6930 -\u0026gt; 0.5 Our first solution shows up. The second solution is \\(r = 15, b = 6\\), which is the first with an even number of black socks. We can easily verify it by hand. This answers question (b): the minimum number of socks with an even number of black socks is \\(15 + 6 = 21\\). The four remaining solutions are also valid and there are more possibilities if we check greater values of \\(b\\).\nMinor optimization We can improve our solution-finding code. Instead of computing the probability, which involves division and hence some numerical errors, we can individually compute the numerator and denominator of the probability term. We can then check if the denominator is equal to two times the numerator. In fact, we can even avoid multiplication by two if we use a bit shift.\nHere\u0026rsquo;s the code.\nimport math c = math.sqrt(2) + 1 for b in range(1, 1000000): r = int(math.ceil(b * c)) p_numerator = r * (r - 1) p_denominator = (r + b) * (r + b - 1) if p_denominator == p_numerator \u0026lt;\u0026lt; 1: prob = p_numerator / p_denominator print(f\u0026#39;r: {r}, b: {b} -\u0026gt; {prob}\u0026#39;) I\u0026rsquo;ve even increased the number of iterations, since now we avoid false positives entirely. The code outputs these solutions:\nr: 3, b: 1 -\u0026gt; 0.5\rr: 15, b: 6 -\u0026gt; 0.5\rr: 85, b: 35 -\u0026gt; 0.5\rr: 493, b: 204 -\u0026gt; 0.5\rr: 2871, b: 1189 -\u0026gt; 0.5\rr: 16731, b: 6930 -\u0026gt; 0.5\rr: 97513, b: 40391 -\u0026gt; 0.5\rr: 568345, b: 235416 -\u0026gt; 0.5\rr: 3312555, b: 1372105 -\u0026gt; 0.5\rr: 19306983, b: 7997214 -\u0026gt; 0.5 Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More FCPP solutions coming soon :)\n","permalink":"http://localhost:1313/posts/fcpp_1_the_sock_drawer/","summary":"\u003cp\u003eThis is the first post in a series solving problems from \u003ca href=\"https://www.amazon.com/Challenging-Problems-Probability-Solutions-Mathematics/dp/0486653552\"\u003e\u003cem\u003eFifty Challenging Problems in Probability\u003c/em\u003e by Frederick Mosteller (1987)\u003c/a\u003e.\nThe problem is paraphrased below; for reference, it is inspired by the original book.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eA drawer contains some red and black socks. Two socks are drawn at random, and the probability that both are red is  \\(1/2\\).\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eWhat is the minimum total number of socks?\u003c/li\u003e\n\u003cli\u003eWhat is the minimum if the number of black socks is even?\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"FCPP 1: The Sock Drawer"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 2462: Total Cost to Hire K Workers. The instructions are as follows:\nYou are given a 0-indexed integer array costs where costs[i] is the cost of hiring the \\(i\\)-th worker. You are also given two integers \\(k\\) and candidates. We want to hire exactly \\(k\\) workers according to the following rules:\nYou will run \\(k\\) sessions and hire exactly one worker in each session. In each hiring session, choose the worker with the lowest cost from either the first candidates workers or the last candidates workers. Break the tie by the smallest index. For example, if costs = [3,2,7,7,1,2] and candidates = 2, then in the first hiring session, we will choose the 4th worker because they have the lowest cost [3,2,7,7,**1**,2]. In the second hiring session, we will choose 1st worker because they have the same lowest cost as 4th worker but they have the smallest index [3,**2**,7,7,2]. Please note that the indexing may be changed in the process. If there are fewer than candidates workers remaining, choose the worker with the lowest cost among them. Break the tie by the smallest index. A worker can only be chosen once. Return the total cost to hire exactly \\(k\\) workers.\nConstraints:\n1 \u0026lt;= costs.length \u0026lt;= 10^5 1 \u0026lt;= costs[i] \u0026lt;= 10^5 1 \u0026lt;= k, candidates \u0026lt;= costs.length Let\u0026rsquo;s dive in!\nStrategy Let \\(c\\) denote candidates for brevity.\nA naive strategy is to find the minimum from the first and last \\(c\\) options during each round. Each such round requires \\(2c\\) checking operations, which would give a time complexity of \\(O(kc)\\) across \\(k\\) rounds.\nWe can do better. Let\u0026rsquo;s maintain two priority queues: front and back. front will hold the first \\(c\\) unprocessed workers and back will hold the last \\(c\\) unprocessed workers. Each queue will grant access to its cheapest worker in \\(O(1)\\) time.\nDuring each round, we decide whether to choose the worker from front or back according to their cost. If we choose a worker from front, we add the next unprocessed worker from the left to front. If we choose a worker from back, we add the next unprocessed worker from the right to back. Each time we choose a worker, we increase the running cost to hire our workers.\nThere are two edge cases:\nIf there are at most \\(k\\) workers, then all workers will be accepted. If there are at most \\(2c\\) workers (i.e., \\(n \\leq 2c\\)), then we don\u0026rsquo;t need to maintain two priority queues. We can simply sort the workers by their cost in non-decreasing order and select the first \\(k\\). Implementation Let\u0026rsquo;s look at the code below. We maintain two indices: left and right. left tells us which worker we should add next to front. right tells us which worker we should add next to back. We also consider a technical edge case: if front is empty, we choose from back and vice-versa.\nclass Solution { public: long long totalCost(vector\u0026lt;int\u0026gt;\u0026amp; costs, int k, int candidates) { long long total = 0; size_t n = costs.size(); // Edge case 1 if (n \u0026lt;= k) { for (size_t i = 0; i \u0026lt; k; ++i) { total += costs[i]; } return total; } // Edge case 2 if (n \u0026lt;= 2 * candidates) { sort(costs.begin(), costs.end()); for (size_t i = 0; i \u0026lt; k; ++i) { total += costs[i]; } return total; } priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; front; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; back; for (size_t i = 0; i \u0026lt; candidates; ++i) { front.push(costs[i]); back.push(costs[n - 1 - i]); } size_t left = candidates - 1; size_t right = n - candidates; for (size_t i = 0; i \u0026lt; k; ++i) { if (front.empty() || back.top() \u0026lt; front.top()) { // Hire worker from the back total += back.top(); back.pop(); --right; if (left \u0026lt; right) { // Add new worker to the back back.push(costs[right]); } } else { // Hire worker from the front total += front.top(); front.pop(); ++left; if (left \u0026lt; right) { // Add new worker to the front front.push(costs[left]); } } } return total; } }; We break down the time complexity as follows:\nEdge case 1 requires \\(O(k)\\) time to sum the costs of all workers. This is equal to \\(O(n)\\) since this case only occurs when \\(k \\geq n\\). Edge case 2 requires \\(O(n \\log n)\\) time to sort the workers. Summing the first \\(k\\) costs takes \\(O(k)\\) time, but this is subsumed by the sorting time. The general case: We first make \\(c\\) insertions to each priority queue, with each insertion requiring \\(O(\\log c)\\) time. The time complexity for queue construction is thus \\(O(c \\log c)\\). We then make \\(k\\) iterations. In each iteration, we perform exactly one removal in \\(O(\\log c)\\) time and at most one insertion in \\(O(\\log c)\\) time. Overall, we need \\(O(k \\log c)\\) time for queue processing. The worst-case time complexity over all inputs is \\(O(n\\log n\\). However, time complexity becomes \\(O(c\\log c + k \\log c)\\) for inputs that are not edge cases.\nSince each priority queue holds at most \\(c\\) elements, the auxiliary space complexity is \\(O(c)\\).\nLeetCode indeed reports a runtime of 15 ms (beating 99.48% of other solutions) and a memory use of 74.50 MB (beating 100% of other solutions).\nMinor optimization Instead of constructing the heaps via incremental insertions into a priority_queue (which costs \\(O(c\\log c)\\) time), we can build them in linear time using make_heap (see the documentation). We construct front and back as vector objects and not priority queues. We then push the unsorted worker costs into each one in \\(O(c)\\) time. Finally, we call make_heap, which only requires \\(O(c)\\) time. We also have to modify the push and pop calls, though the high-level logic stays the same.\nLet\u0026rsquo;s look at the modified code for the general case. The actual runtime and space usage are pretty much the exact same, though this method is theoretically slightly faster, requiring \\(O(c)\\) time to construct each heap instead of the previous \\(O(c \\log c)\\).\nvector\u0026lt;int\u0026gt; front, back; front.reserve(candidates); back.reserve(candidates); for (int i = 0; i \u0026lt; candidates; ++i) { front.push_back(costs[i]); back.push_back(costs[n - 1 - i]); } // Build min-heaps make_heap(front.begin(), front.end(), greater\u0026lt;int\u0026gt;()); make_heap(back.begin(), back.end(), greater\u0026lt;int\u0026gt;()); size_t left = candidates - 1; size_t right = n - candidates; for (int i = 0; i \u0026lt; k; ++i) { if (front.empty() || (!back.empty() \u0026amp;\u0026amp; back.front() \u0026lt; front.front())) { // Take from back total += back.front(); pop_heap(back.begin(), back.end(), greater\u0026lt;int\u0026gt;()); back.pop_back(); --right; if (left \u0026lt; right) { back.push_back(costs[right]); push_heap(back.begin(), back.end(), greater\u0026lt;int\u0026gt;()); } } else { // Take from front total += front.front(); pop_heap(front.begin(), front.end(), greater\u0026lt;int\u0026gt;()); front.pop_back(); ++left; if (left \u0026lt; right) { front.push_back(costs[left]); push_heap(front.begin(), front.end(), greater\u0026lt;int\u0026gt;()); } } } Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\nSide note: with this blog post, I\u0026rsquo;ve finished the LeetCode 75 problem list! ðŸ¥³ðŸŽ‰ðŸŽ‰ðŸŽ‰\n","permalink":"http://localhost:1313/posts/leetcode_2462/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/total-cost-to-hire-k-workers/\"\u003eLeetCode problem 2462: Total Cost to Hire K Workers\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou are given a 0-indexed integer array \u003ccode\u003ecosts\u003c/code\u003e where \u003ccode\u003ecosts[i]\u003c/code\u003e is the cost of hiring the \\(i\\)-th worker.\nYou are also given two integers \\(k\\) and \u003ccode\u003ecandidates\u003c/code\u003e. We want to hire exactly \\(k\\) workers according to the following rules:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYou will run \\(k\\) sessions and hire exactly one worker in each session.\u003c/li\u003e\n\u003cli\u003eIn each hiring session, choose the worker with the lowest cost from either the first candidates workers or the last candidates workers. Break the tie by the smallest index.\n\u003cul\u003e\n\u003cli\u003eFor example, if \u003ccode\u003ecosts = [3,2,7,7,1,2]\u003c/code\u003e and \u003ccode\u003ecandidates = 2\u003c/code\u003e, then in the first hiring session, we will choose the 4th worker because they have the lowest cost \u003ccode\u003e[3,2,7,7,**1**,2]\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eIn the second hiring session, we will choose 1st worker because they have the same lowest cost as 4th worker but they have the smallest index \u003ccode\u003e[3,**2**,7,7,2]\u003c/code\u003e. Please note that the indexing may be changed in the process.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eIf there are fewer than candidates workers remaining, choose the worker with the lowest cost among them. Break the tie by the smallest index.\u003c/li\u003e\n\u003cli\u003eA worker can only be chosen once.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eReturn the total cost to hire exactly \\(k\\) workers.\u003c/p\u003e","title":"LeetCode 2462: Total Cost to Hire K Workers"},{"content":"Let\u0026rsquo;s solve LeetCode problem 88: Merge Sorted Array. This problem is quite short and straightforward.\nThe instructions are as follows:\nYou are given two integer arrays nums1 and nums2, sorted in non-decreasing order, and two integers \\(m\\) and \\(n\\), representing the number of elements in nums1 and nums2 respectively. Merge nums1 and nums2 into a single array sorted in non-decreasing order. The final sorted array should not be returned by the function, but instead be stored inside the array nums1. To accommodate this, nums1 has a length of \\(m\\) + \\(n\\), where the first \\(m\\) elements denote the elements that should be merged, and the last \\(n\\) elements are set to 0 and should be ignored. nums2 has a length of \\(n\\).\nConstraints:\nnums1.length == m + n nums2.length == n 0 \u0026lt;= m, n \u0026lt;= 200 1 \u0026lt;= m + n \u0026lt;= 200 -10^9 \u0026lt;= nums1[i], nums2[j] \u0026lt;= 10^9 Let\u0026rsquo;s dive in!\nStrategy and implementation We have to write the result to nums1. If we process the numbers from highest to lowest, we can avoid overwriting the first \\(m\\) values of nums1. Let\u0026rsquo;s create two indices i, j and initialize them to i = m - 1, j = n - 1. We will decrement these indices until they both reach 0. At each step, we do the following:\nIf nums1[i] \u0026gt; nums2[j], then we write nums1[i] to the next slot and decrement i. Otherwise, we write nums2[j] to the next slot and decrement j. The index of the next slot is simply i + j + 1.\nWhen i reaches 0, we write all the remaining values in nums2 to the start of nums1. When j reaches 0, we could write all the remaining values in nums1 to the start of nums1. However, this is already the case! Thus, we don\u0026rsquo;t need to do anything at all.\nLet\u0026rsquo;s look at the code below. I usually use size_t as the index data type, however I opted for int as decrementing past 0 causes an overflow and breaks the program.\nclass Solution { public: void merge(vector\u0026lt;int\u0026gt;\u0026amp; nums1, int m, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int n) { int i = m - 1; int j = n - 1; while (i \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026gt;= 0) { if (nums1[i] \u0026gt;= nums2[j]) { nums1[i + j + 1] = nums1[i]; i--; } else { nums1[i + j + 1] = nums2[j]; j--; } } while (j \u0026gt;= 0) { nums1[j] = nums2[j]; j--; } } }; LeetCode reports a runtime of 0 ms (beating 100% of other solutions) and memory usage of 12.17 MB (beating 95.41% of other solutions). I\u0026rsquo;m pretty sure this is effectively optimal and the memory usage is the lowest it could be.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_88/","summary":"\u003cp\u003eLet\u0026rsquo;s solve \u003ca href=\"https://leetcode.com/problems/merge-sorted-array/\"\u003eLeetCode problem 88: Merge Sorted Array\u003c/a\u003e.\nThis problem is quite short and straightforward.\u003c/p\u003e\n\u003cp\u003eThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou are given two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e, sorted in non-decreasing order, and two integers \\(m\\) and \\(n\\), representing the number of elements in \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e respectively.\nMerge \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e into a single array sorted in non-decreasing order.\nThe final sorted array should not be returned by the function, but instead be stored inside the array \u003ccode\u003enums1\u003c/code\u003e. To accommodate this, \u003ccode\u003enums1\u003c/code\u003e has a length of \\(m\\) + \\(n\\), where the first \\(m\\) elements denote the elements that should be merged, and the last \\(n\\) elements are set to 0 and should be ignored. \u003ccode\u003enums2\u003c/code\u003e has a length of \\(n\\).\u003c/p\u003e","title":"LeetCode 88: Merge Sorted Array"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 216: Combination Sum III. The instructions are as follows:\nFind all valid combinations of \\(k\\) numbers that sum up to \\(n\\) such that the following conditions are true:\nOnly numbers 1 through 9 are used. Each number is used at most once. Return a list of all possible valid combinations. The list must not contain the same combination twice, and the combinations may be returned in any order.\nConstraints:\n2 \u0026lt;= k \u0026lt;= 9 1 \u0026lt;= n \u0026lt;= 60 Let\u0026rsquo;s dive in!\nStrategy and implementation We can approach this problem by trying to fill up an empty vector v to size \\(k\\). Once v has length \\(k\\) and sums to \\(n\\), we add it to the vector of results. If it has length \\(k\\), but does not sum to \\(n\\), then we replace some elements in it.\nA systematic way of doing this is via backtracking. We create a recursive function void solve(size_t total), where total is the current sum of v. The function solve also has access to a global vector v, a global vector of vectors results, a target vector length variable, and a target sum variable.\nDuring each recursive call, we apply one of these three rules:\nIf v has length \\(k\\) and total equals \\(n\\), then we add v to results. If v is shorter than \\(k\\) and total \u0026lt; n, then we add recursively call solve several times. Before each call, we add a new number j to the end of the vector (j has to be bigger than the last element of v, but at most 9). We then call the function with solve(total + j) to indicate the change in the vector sum. During this call, solutions may be added to results. After the call finishes, we pop the last element of v and apply the procedure for the next value of j. If neither of the two rules above applies, we do nothing. Rule 1 and rule 3 are base cases for recursion. If rule 1 applies, we\u0026rsquo;ve identified v as one possible solution. If rule 3 applies, we did not. Rule 2 is the general case, during which we try to recursively construct solution vectors. In rule 2, backtracking occurs when we pop the last element of v.\nLet\u0026rsquo;s look at the code below. In combinationSum3, we set up two global variables and call solve with an empty vector v that has sum 0. Rule 2 is the most interesting part of solve. We start adding digits from j0 onward. If v is empty, we set j0 to 1, as that\u0026rsquo;s the smallest permissible number. If not, we set j0 to be one bigger than the last element of v. Then we add digits j from j0 to 9 inclusive. We apply the recursive call to solve and backtrack after the call finishes.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; results; vector\u0026lt;int\u0026gt; v; size_t targetLength; size_t targetSum; void solve(size_t total) { // Rule 1 if (v.size() == targetLength \u0026amp;\u0026amp; total == targetSum) { results.push_back(v); return; } // Rule 2 if (v.size() \u0026lt; targetLength \u0026amp;\u0026amp; total \u0026lt; targetSum) { size_t j0; if (v.size() == 0) { j0 = 1; } else { j0 = v.back() + 1; } for (size_t j = j0; j \u0026lt;= 9; j++) { v.push_back(j); solve(total + j); v.pop_back(); } return; } // Rule 3: nothing } vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; combinationSum3(int k, int n) { targetLength = k; targetSum = n; solve(0); return results; } }; We can bound the number of solutions to check with \\(9^k\\). A tighter bound is the number of strictly increasing sequences of length \\(k\\) with elements from \\(\\{1, \\dots, 9\\}\\). There are \\(\\binom{9}{k} = 9! / ((9-k)!k!)\\) such sequences. The maximal number of sequences is 126 and occurs at \\(k = 4\\) or \\(k = 5\\). The total number of candidates explored (including those shorter than \\(k\\)) is bounded by \\(\\sum_{i=0}^k \\binom{9}{i}\\), which is maximized when \\(k = 9\\) and equals 512.\nThe space complexity is \\(O(mk)\\) where \\(m\\) is the number of solutions. We can again say \\(m \\leq 126 \\) per the discussion above. Since \\(k \\leq 9\\), we need to store at most \\(9 \\cdot 126 = 1134 \\) digits, which is tiny.\nThe total runtime is effectively constant. LeetCode indeed reports a runtime of 0 ms (beating 100% of other solutions) and a memory use of 8.68 MB (beating 78.86% of other solutions).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_216/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/combination-sum-iii\"\u003eLeetCode problem 216: Combination Sum III\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eFind all valid combinations of \\(k\\) numbers that sum up to \\(n\\) such that the following conditions are true:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eOnly numbers 1 through 9 are used.\u003c/li\u003e\n\u003cli\u003eEach number is used at most once.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eReturn a list of all possible valid combinations. The list must not contain the same combination twice, and the combinations may be returned in any order.\u003c/p\u003e","title":"LeetCode 216: Combination Sum III"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 790: Domino and Tromino Tiling. The instructions are as follows:\nYou have two types of tiles: a 2 x 1 domino shape and a tromino shape. You may rotate these shapes. Given an integer \\(n\\), return the number of ways to tile an 2 x n board. Since the answer may be very large, return it modulo 10^9 + 7. In a tiling, every square must be covered by a tile. Two tilings are different if and only if there are two 4-directionally adjacent cells on the board such that exactly one of the tilings has both squares occupied by a tile.\nLet\u0026rsquo;s dive in!\nCounting the possible tilings Let\u0026rsquo;s look at all possible tilings for a few values of \\(n\\) in the image below. Unique new tilings We notice that each \\(n\\) has a few unique tilings that don\u0026rsquo;t show up before it:\nFor \\(n = 1\\), the last tiling is a unique new vertical domino. For \\(n = 2\\), the last tiling is a unique new pair of horizontal dominos. For \\(n = 3\\), the final two tilings are new and made up of two trominos. For \\(n = 4\\), the final two tilings are new and made up of two trominos and a domino. I\u0026rsquo;ve marked these in the image below. In fact, each new \\(n\\) introduces new unique tilings. Let\u0026rsquo;s look at these for \\(n \\leq 7\\). Clearly, there are always 2 new unique tilings for each \\(n \\geq 3\\).\nHow are the tilings constructed? Aside from these new and unique tilings, we can also notice a pattern in how the other tilings are constructed. Let\u0026rsquo;s consider \\(n = 4\\). I\u0026rsquo;ve purposely arranged the tilings to clearly see the pattern in the image below. The tilings are constructed as follows:\nTake all tilings for \\(n = 3\\) and append the unique tiling from \\(n = 1\\). Take all tilings for \\(n = 2\\) and append the unique tiling from \\(n = 2\\). Take all tilings for \\(n = 1\\) and append the unique tilings from \\(n = 3\\). We cover the edge case of new tilings by taking all the tilings for \\(n = 0\\) (i.e., nothing) and appending the unique tilings from \\(n = 4\\). The number of tilings for \\(n\\) are thus:\n\\[\rt(n) = t(n - 1) + t(n - 2) + \\sum_{i = 0}^{n - 3} 2 t(i).\r\\]The term \\(t(n - 1)\\) corresponds to tilings from \\(n - 1\\) and adding a vertical domino. The term \\(t(n - 2)\\) corresponds to tilings from \\(n - 2\\) and adding a horizontal domino pair. The remaining terms \\(t(i)\\) corresponds to tilings from \\(i\\) and adding two unique tilings (since we know each \\(n \\geq 3\\) has two new unique tilings), which is why each term is multiplied by \\(2\\).\nThis is the dynamic programming recurrence relation.\nSimplifying the recurrence relation We can simplify the equation above with some clever math. First, let\u0026rsquo;s construct a helper term with \\(t(n - 1)\\):\n\\[\rt(n - 1) = t(n - 2) + t(n - 3) + \\sum_{i = 0}^{n - 4} 2 t(i), \\;\\mathrm{therefore} \\\\\rt(n - 2) + t(n - 3) = t(n - 1) - \\sum_{i = 0}^{n - 4} 2 t(i).\r\\]We will use this term as a replacement inside the square brackets in the derivation below:\n\\[\rt(n) = t(n - 1) + t(n - 2) + \\sum_{i = 0}^{n - 3} 2 t(i) \\\\\r= t(n - 1) + t(n - 2) + 2 t(n - 3) + \\sum_{i = 0}^{n - 4} 2 t(i) \\\\\r= t(n - 1) + [t(n - 2) + t(n - 3)] + t(n - 3) + \\sum_{i = 0}^{n - 4} 2 t(i) \\\\\r= t(n - 1) + [t(n - 1) - \\sum_{i = 0}^{n - 4} 2 t(i)] + t(n - 3) + \\sum_{i = 0}^{n - 4} 2 t(i) \\\\\r= 2t(n - 1) + t(n - 3) \\\\\r\\]Full implementation The solution becomes trivial to implement using the simplified formula. We use a, b, c to hold \\(t(i - 3), t(i - 2),\\) and \\(t(i - 1)\\) respectively. We store \\(t(i)\\) inside variable d at each step. We iterate from \\(i = 4\\) to \\(i = n\\). After the loop, the final value \\(t(n)\\) is stored inside d (and c, because of the variable swap). We apply modulo according to the instructions to avoid overflows.\nclass Solution { public: int numTilings(int n) { if (n == 1) { return 1; } else if (n == 2) { return 2; } else if (n == 3) { return 5; } size_t a = 1; size_t b = 2; size_t c = 5; size_t d; for (size_t i = 4; i \u0026lt;= n; ++i) { d = (2 * c + a) % 1000000007; a = b; b = c; c = d; } return d; } }; This solution requires \\(O(n)\\) time and \\(O(1)\\) space. LeetCode reports a runtime of 0 ms (beating 100% of other solutions) and a memory use of 7.78 MB (beating 95.07% of other solutions). Super efficient!\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_790/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/domino-and-tromino-tiling\"\u003eLeetCode problem 790: Domino and Tromino Tiling\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou have two types of tiles: a \u003ccode\u003e2 x 1\u003c/code\u003e domino shape and a tromino shape. You may rotate these shapes.\nGiven an integer \\(n\\), return the number of ways to tile an \u003ccode\u003e2 x n\u003c/code\u003e board. Since the answer may be very large, return it modulo \u003ccode\u003e10^9 + 7\u003c/code\u003e.\nIn a tiling, every square must be covered by a tile. Two tilings are different if and only if there are two 4-directionally adjacent cells on the board such that exactly one of the tilings has both squares occupied by a tile.\u003c/p\u003e","title":"LeetCode 790: Domino and Tromino Tiling"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 875: Koko Eating Bananas. The instructions are as follows:\nKoko loves to eat bananas. There are n piles of bananas, the \\(i\\)-th pile has piles[i] bananas. The guards have gone and will come back in h hours. Koko can decide her bananas-per-hour eating speed of k. Each hour, she chooses some pile of bananas and eats k bananas from that pile. If the pile has less than k bananas, she eats all of them instead and will not eat any more bananas during this hour. Koko likes to eat slowly but still wants to finish eating all the bananas before the guards return. Return the minimum integer k such that she can eat all the bananas within h hours.\nConstraints:\n1 \u0026lt;= piles.length \u0026lt;= 10^4 piles.length \u0026lt;= h \u0026lt;= 10^9 1 \u0026lt;= piles[i] \u0026lt;= 10^9 Let\u0026rsquo;s dive in!\nChecking if a given rate is valid To check if a rate k is valid, we have to first compute the total time spent eating bananas across all piles with rate k and then ensure that this time is at most h. Let\u0026rsquo;s write this as helper function:\nint ceilDivision(int a, int b) { // return ceil(a / b) where a and b are integers return (a + b - 1) / b; } bool validRate(vector\u0026lt;int\u0026gt; *piles, int h, int k) { int total = 0; for (int i = 0; i \u0026lt; piles-\u0026gt;size(); ++i) { total += ceilDivision(piles-\u0026gt;at(i), k); } return total \u0026lt;= h; } If ceilDivision appears too complicated, think about this: the time spent eating pile \\(i\\) is equal to piles[i] / k if k evenly divides piles[i]. If it doesn\u0026rsquo;t, then there are still some bananas leftover and Koko has to spend an hour eating them. We can use the one-liner below.\ntotal += piles-\u0026gt;at(i) / k + (piles-\u0026gt;at(i) % k \u0026gt; 0); This is equivalent to our ceilDivision(piles-\u0026gt;at(i), k) function. More on the function in this StackOverflow discussion.\nBinary search strategy We\u0026rsquo;re trying to find the minimum integer rate k such that Koko can still eat all of the bananas in time h. The maximum possible rate is \\(m\\); the number of bananas on the biggest pile. Since h is at least the number of piles, using rate \\(m\\) means spending one hour for each pile. The minimum possible rate is \\(1\\).\nWe can simply apply binary search on the set \\(\\{1, 2, \\dots, m - 1, m\\}\\). For a candidate rate in the middle between the minimum and maximum rate, we check if it\u0026rsquo;s valid with the validRate function. If the rate is valid, we shift the maximum rate to the candidate rate (since the rate can\u0026rsquo;t be bigger). If it\u0026rsquo;s invalid, we shift the minimum rate to the candidate rate and add \\(1\\) (that\u0026rsquo;s the first rate that could possibly be valid).\nThe implementation is straightforward. Below is the full code.\nclass Solution { public: int ceilDivision(int a, int b) { // return ceil(a / b) where a and b are integers return (a + b - 1) / b; } bool validRate(vector\u0026lt;int\u0026gt; *piles, int h, int k) { int total = 0; for (int i = 0; i \u0026lt; piles-\u0026gt;size(); ++i) { total += ceilDivision(piles-\u0026gt;at(i), k); } return total \u0026lt;= h; } int minEatingSpeed(vector\u0026lt;int\u0026gt;\u0026amp; piles, int h) { int minRate = 1; int maxRate = *max_element(piles.begin(), piles.end()); while (minRate \u0026lt; maxRate) { int midRate = (minRate + maxRate) / 2; if (validRate(\u0026amp;piles, h, midRate)) { maxRate = midRate; } else { minRate = midRate + 1; } } return minRate; } }; This solution requires \\(O(n \\log m)\\) time and \\(O(1)\\) extra space. The time complexity derives from using \\(O(\\log m)\\) binary search steps, each requiring us to check \\(n\\) piles. LeetCode reports a runtime of 11 ms and a memory use of 22.83 MB (beating 76.17% of other solutions).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_875/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/koko-eating-bananas\"\u003eLeetCode problem 875: Koko Eating Bananas\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eKoko loves to eat bananas. There are \u003ccode\u003en\u003c/code\u003e piles of bananas, the \\(i\\)-th pile has \u003ccode\u003epiles[i]\u003c/code\u003e bananas.\nThe guards have gone and will come back in \u003ccode\u003eh\u003c/code\u003e hours.\nKoko can decide her bananas-per-hour eating speed of \u003ccode\u003ek\u003c/code\u003e.\nEach hour, she chooses some pile of bananas and eats \u003ccode\u003ek\u003c/code\u003e bananas from that pile.\nIf the pile has less than \u003ccode\u003ek\u003c/code\u003e bananas, she eats all of them instead and will not eat any more bananas during this hour.\nKoko likes to eat slowly but still wants to finish eating all the bananas before the guards return.\nReturn the minimum integer \u003ccode\u003ek\u003c/code\u003e such that she can eat all the bananas within \u003ccode\u003eh\u003c/code\u003e hours.\u003c/p\u003e","title":"LeetCode 875: Koko Eating Bananas"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 72: Edit distance. The instructions are as follows:\nGiven two strings word1 and word2, return the minimum number of operations required to convert word1 to word2. You have the following three operations permitted on a word:\nInsert a character Delete a character Replace a character Let\u0026rsquo;s dive in!\nThe Wagner-Fischer algorithm There are several types of edit distance. This LeetCode problem defines it as the Levenshtein distance. The most common algorithm to compute it is the Wagner-Fischer algorithm.\nSuppose word1 has length \\(m\\) and word2 has length \\(n\\). The Wagner-Fischer computes a matrix \\(D\\) of size \\((m+1) \\times (n+1)\\) that holds the edit distances between all prefixes of word1 and all prefixes of word2. Computing each edit distance reuses the adjacent edit distances in the matrix, making this a dynamic programming algorithm.\nSuppose word1[:i] is the length-\\(i\\) prefix of word1 and word2[:j] is the length-\\(j\\) prefix of word2. Then \\(D_{i,j}\\) holds the edit distance between word1[:i] and word2[:j].\nWe initialize the first row with values from 0 to \\(n\\) and the first column with values from 0 to \\(m\\). That\u0026rsquo;s because converting an empty string to word2[:j] requires \\(j\\) insertions. Similarly, converting word1[:i] to an empty string requires \\(i\\) deletions.\nHere\u0026rsquo;s the key rule to compute the edit distance:\n\\[\rD_{i,j} = \\min (D_{i-1, j} + 1, D_{i, j - 1} + 1, D_{i-1, j-1} + s),\r\\] where \\(s = 0\\) if word1[i - 1] == word2[j - 1] and \\(s = 1\\) otherwise.\nThe three terms in the minimum respectively correspond to deletion, insertion, and substitution. If we are in cell \\(D_{i,j}\\), then:\n\\(D_{i-1, j} + 1\\) corresponds to deleting word1[i - 1] from word1, \\(D_{i, j - 1} + 1\\) corresponds to inserting word2[j - 1] into word1 to match the longer prefix of word2, \\(D_{i - 1, j - 1} + s\\) corresponds to substituting word1[i - 1] with word2[j - 1] (or doing nothing if they are equal). After filling the matrix in this way, the final edit distance is \\(D_{m,n}\\).\nHere\u0026rsquo;s an example for word1 = \u0026quot;kitten\u0026quot; and word2 = \u0026quot;sitting\u0026quot;. The true edit distance is three: substitute \u0026quot;k\u0026quot; with \u0026quot;s\u0026quot;, substitute \u0026quot;e\u0026quot; with \u0026quot;i\u0026quot;, add \u0026quot;g\u0026quot; to the end.\nk i t t e n 0 1 2 3 4 5 6 s 1 1 1 2 3 4 5 i 2 2 1 2 3 4 5 t 3 3 2 1 2 3 4 t 4 4 3 2 1 2 3 i 5 5 4 3 2 2 3 n 6 6 5 4 3 3 2 g 7 7 6 5 4 4 3 The bottom right value in the matrix is indeed the true distance: 3.\nThe full code is shown below. Before running the Wagner-Fischer algorithm, we check if the two words are equal, which only takes \\(O(\\max(m, n))\\) time. The full algorithm takes \\(O(mn)\\) time and space.\nclass Solution { public: int minDistance(string word1, string word2) { if (word1 == word2) { return 0; } // Wagner-Fischer algorithm size_t m = word1.size(); size_t n = word2.size(); vector\u0026lt;vector\u0026lt;size_t\u0026gt;\u0026gt; d(m + 1, vector\u0026lt;size_t\u0026gt;(n + 1, 0)); for (size_t i = 1; i \u0026lt;= m; ++i) { d[i][0] = i; } for (size_t j = 1; j \u0026lt;= n; ++j) { d[0][j] = j; } for (size_t j = 1; j \u0026lt;= n; ++j) { for (size_t i = 1; i \u0026lt;= m; ++i) { bool substituted = (word1[i - 1] != word2[j - 1]); d[i][j] = min( d[i - 1][j] + 1, // deletion min( d[i][j - 1] + 1, // insertion d[i - 1][j - 1] + substituted // substitution ) ); } } return d[m][n]; } }; Running the code takes 4 ms (beating 81.58% of other solutions) and needs 15 MB of memory (beating 12.96% of other solutions).\nOptimized version with reduced space complexity The Wagner-Fischer algorithm can be optimized to use less space. The code above has to fill the matrix column-by-column. However, filling each cell only needs the values of the cells to the left, above, and to the top-left. This means we only need to keep:\nthe current column (namely the values above the current cell), and the column to the left of the current one. Now the space complexity will only be \\(O(m)\\), substantially less than \\(O(nm)\\). The time complexity remains the same.\nIt\u0026rsquo;s equivalent to keep two rows instead of two columns, as it\u0026rsquo;s essentially working with a transposed matrix \\(D\\). We\u0026rsquo;ll use the rows strategy so we can easily keep track of rows with the swap function. We\u0026rsquo;ll have a top row and a bottom row. Each row will have \\(n + 1\\) elements. After processing all characters in both words, we will implicitly have filled up all rows in the matrix. The result is stored in the last element of the bottom row.\nLet\u0026rsquo;s look at the code below. There\u0026rsquo;s a small optimization: if word1 with length \\(m\\) is shorter than word2 with length \\(n\\), we swap them. This brings down the space complexity to \\(O(\\min (m, n))\\) because \\(m \u003c n\\) and we now only have \\(m+1\\) elements in each row.\nclass Solution { public: int minDistance(string word1, string word2) { if (word1 == word2) { return 0; } if (word1.size() \u0026lt; word2.size()) { swap(word1, word2); } // Wagner-Fischer algorithm size_t m = word1.size(); size_t n = word2.size(); // Only store two rows vector\u0026lt;size_t\u0026gt; top(n + 1, 0); vector\u0026lt;size_t\u0026gt; bottom(n + 1, 0); for (size_t j = 1; j \u0026lt;= n; ++j) { top[j] = j; } for (size_t i = 1; i \u0026lt;= m; ++i) { bottom[0] = i; for (size_t j = 1; j \u0026lt;= n; ++j) { bool substituted = (word1[i - 1] != word2[j - 1]); bottom[j] = min( min( top[j] + 1, // deletion bottom[j - 1] + 1 // insertion ), top[j - 1] + substituted // substitution ); } swap(top, bottom); } return top[n]; // because of the swap } }; Running the code now takes 0 ms (beating 100% of other solutions) and needs 10.4 MB of memory (beating 98.46% of other solutions). The used space in the optimized version is about 2/3 of the space in the basic version of the algorithm.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_72/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/edit-distance\"\u003eLeetCode problem 72: Edit distance\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eGiven two strings \u003ccode\u003eword1\u003c/code\u003e and \u003ccode\u003eword2\u003c/code\u003e, return the minimum number of operations required to convert \u003ccode\u003eword1\u003c/code\u003e to \u003ccode\u003eword2\u003c/code\u003e. You have the following three operations permitted on a word:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eInsert a character\u003c/li\u003e\n\u003cli\u003eDelete a character\u003c/li\u003e\n\u003cli\u003eReplace a character\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLet\u0026rsquo;s dive in!\u003c/p\u003e\n\u003ch2 id=\"the-wagner-fischer-algorithm\"\u003eThe Wagner-Fischer algorithm\u003c/h2\u003e\n\u003cp\u003eThere are several types of \u003ca href=\"https://en.wikipedia.org/wiki/Edit_distance\"\u003eedit distance\u003c/a\u003e.\nThis LeetCode problem defines it as the \u003ca href=\"https://en.wikipedia.org/wiki/Levenshtein_distance\"\u003eLevenshtein distance\u003c/a\u003e.\nThe most common algorithm to compute it is the \u003ca href=\"https://en.wikipedia.org/wiki/Wagner%E2%80%93Fischer_algorithm\"\u003eWagner-Fischer algorithm\u003c/a\u003e.\u003c/p\u003e","title":"LeetCode 72: Edit distance"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 746: Min Cost Climbing Stairs. The instructions are as follows:\nYou are given an integer array cost where cost[i] is the cost of \\(i\\)-th step on a staircase. Once you pay the cost, you can either climb one or two steps. You can either start from the step with index 0, or the step with index 1. Return the minimum cost to reach the top of the floor.\nLet\u0026rsquo;s dive in!\nStrategy and solution Let\u0026rsquo;s think about the minimum cost required to reach stair \\(i\\). We could have arrived there from:\nstair \\(i-2\\), costing cost[i - 2] plus the minimum cost to arrive at stair \\(i - 2\\), or stair \\(i-1\\), costing cost[i - 1] plus the minimum cost to arrive at stair \\(i - 1\\). The cheapest path means taking the stair with the lower cost. If \\(m_i\\) is the minimum cost to arrive at stair \\(i\\) and \\(c_i\\) is cost[i], we can write the recurrence as:\n\\[\rm_i = \\min(c_{i - 2} + m_{i - 2}, c_{i - 1} + m_{i - 1}).\r\\]Since we can start at either stair 0 or stair 1, arriving there costs nothing. Therefore \\(m_0 = m_1 = 0\\). We could program this recursively and memoize the results to avoid recomputation. However, it\u0026rsquo;s much easier to simply use an iterative approach.\nLet\u0026rsquo;s look at the code below. We use minCost1 to hold \\(m_{i-2}\\) and minCost2 to hold \\(m_{i-1}\\). We store \\(m_i\\) inside minCost3. After each iteration, we set minCost1 to minCost2 and minCost2 to minCost3. The final result is in minCost2. This is similar to iteratively computing a number from the Fibonacci sequence.\nclass Solution { public: int minCostClimbingStairs(vector\u0026lt;int\u0026gt;\u0026amp; cost) { size_t minCost1 = 0; // cost to reach first stair size_t minCost2 = 0; // cost to reach second stair size_t minCost3; for (size_t i = 2; i \u0026lt;= cost.size(); ++i) { minCost3 = min( minCost1 + cost[i - 2], minCost2 + cost[i - 1] ); minCost1 = minCost2; minCost2 = minCost3; } return minCost2; } }; Given \\(n\\) stairs, the code requires \\(O(n)\\) time and \\(O(1)\\) space, which looks to be optimal. LeetCode reports a runtime of 0 ms (beating 100% of other solutions) and memory use of 17.56 MB, which is effectively just from the input data. Our actual code only uses a few integers. A very efficient solution!\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_746/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/min-cost-climbing-stairs\"\u003eLeetCode problem 746: Min Cost Climbing Stairs\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou are given an integer array \u003ccode\u003ecost\u003c/code\u003e where \u003ccode\u003ecost[i]\u003c/code\u003e is the cost of \\(i\\)-th step on a staircase. Once you pay the cost, you can either climb one or two steps.\nYou can either start from the step with index 0, or the step with index 1.\nReturn the minimum cost to reach the top of the floor.\u003c/p\u003e","title":"LeetCode 746: Min Cost Climbing Stairs"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 435: Non-overlapping intervals. The instructions are as follows:\nGiven an array of intervals intervals where intervals[i] = [start_i, end_i], return the minimum number of intervals you need to remove to make the rest of the intervals non-overlapping. Note that intervals which only touch at a point are non-overlapping. For example, [1, 2] and [2, 3] are non-overlapping.\nLet\u0026rsquo;s dive in!\nInterval scheduling reformulation Interval scheduling is a class of problems that involve a set of tasks, represented by their start and end times. The interval scheduling maximization problem (ISMP) is about finding the largest set of non-overlapping tasks. This is highly related to our interval removal problem. In fact, the following statements are equivalent:\nn is the total number of tasks and k is the maximum number of non-overlapping tasks that can be executed; the minimum number of intervals to make the rest non-overlapping is n - k. Let\u0026rsquo;s solve a variant of the well-known ISMP and use the result to answer the removal question. This is the single-interval scheduling problem (SISP), where we create an interval schedule in which no intervals overlap. A greedy algorithm called Earliest deadline first (EDF) finds the optimal solution to SISP. It\u0026rsquo;s described as follows:\nSelect the interval x with the earliest finishing time. Remove x and all intervals intersecting it from the set of candidate intervals. Repeat until there are no more candidate intervals. EDF starts by sorting the intervals by their end time in non-decreasing order. It then processes intervals from first to last.\nThis problem is also related to a similar interview question: maximum number of meetings in one room.\nSolving the counting problem Since we only need to count the number of compatible intervals, we don\u0026rsquo;t need to actually perform any removals. Instead, we start by sorting the intervals according to their end times. We initialize a counter k = 1 that counts the number of non-overlapping intervals. The first non-overlapping interval is simply the first one in the sorted list, i.e., the interval at index 0. We store its index in a variable prev = 0. Then loop over the rest of the intervals, starting at index i = 1. At each index, we check if interval at index i overlaps with the previously executed one. If so, we increment k and set prev = i. Otherwise, we simply move forward, as the interval at index i was caught in an overlap. We finally return n - k.\nLet\u0026rsquo;s look at the full code below.\nclass Solution { public: int eraseOverlapIntervals(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; intervals) { // Sort by end times sort( intervals.begin(), intervals.end(), [](const vector\u0026lt;int\u0026gt;\u0026amp; left, const vector\u0026lt;int\u0026gt;\u0026amp; right) { return left[1] \u0026lt; right[1]; } ); // Apply *Earliest deadline first* (EDF) size_t prev = 0; size_t k = 1; for (size_t i = 1; i \u0026lt; intervals.size(); ++i) { if (intervals[i][0] \u0026gt;= intervals[prev][1]) { k++; prev = i; } } // Return the number of intervals to remove return intervals.size() - k; } }; Complexity and empirical performance Our counting variant of EDF takes \\(O(n \\log n)\\) time to sort the intervals and \\(O(n)\\) to count the number of compatible intervals, so the total time complexity is \\(O(n \\log n)\\). Ignoring the input data, the space complexity is \\(O(1)\\) as we only need to use two integers: prev and k. LeetCode reports a runtime of 35 ms, which beats 95.23% of all solutions, as well as memory usage of 93.79 MB, which beats 98.60% of all solutions.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_435/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/non-overlapping-intervals\"\u003eLeetCode problem 435: Non-overlapping intervals\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eGiven an array of intervals intervals where \u003ccode\u003eintervals[i] = [start_i, end_i]\u003c/code\u003e, return the minimum number of intervals you need to remove to make the rest of the intervals non-overlapping.\nNote that intervals which only touch at a point are non-overlapping. For example, \u003ccode\u003e[1, 2]\u003c/code\u003e and \u003ccode\u003e[2, 3]\u003c/code\u003e are non-overlapping.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLet\u0026rsquo;s dive in!\u003c/p\u003e\n\u003ch2 id=\"interval-scheduling-reformulation\"\u003eInterval scheduling reformulation\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Interval_scheduling\"\u003eInterval scheduling\u003c/a\u003e is a class of problems that involve a set of tasks, represented by their start and end times.\nThe \u003cem\u003einterval scheduling maximization problem\u003c/em\u003e (ISMP) is about finding the largest set of non-overlapping tasks.\nThis is highly related to our interval removal problem.\nIn fact, the following statements are equivalent:\u003c/p\u003e","title":"LeetCode 435: Non-overlapping Intervals"},{"content":"Hi, everyone! Today, we\u0026rsquo;ll be looking at LeetCode problem 399. In this problem, we are given a bunch of reference equations of the form \\(a_i / b_i = c_i\\) for \\(i = 1 , \\dots, n\\). The symbols \\(a_i, b_i\\) are given as strings, while \\(c_i\\) are given as floating point numbers. We\u0026rsquo;re then asked to compute the value of a query equation \\(q_1 / q_2\\).\nIf \\(q_1 / q_2\\) is one of the reference equations, we can return that value. Otherwise, we can follow a kind of chain-rule strategy. Suppose we are given \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot; with value 2.0 and \u0026quot;b\u0026quot; / \u0026quot;c\u0026quot; with value 3.0, then we can compute \u0026quot;a\u0026quot; / \u0026quot;c\u0026quot; by the product: \u0026quot;a\u0026quot; / \u0026quot;c\u0026quot; = \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot; * \u0026quot;b\u0026quot; / \u0026quot;c\u0026quot;, which is equal to 2.0 * 3.0 = 6.0. If there\u0026rsquo;s no way to find a solution, we return -1.\nWe\u0026rsquo;ll approach this as a graph problem and use breadth-first search (BFS). Let\u0026rsquo;s dive in!\nConstructing a graph of symbols We approach this problem by first constructing a graph. Each node represents a symbol as given in the reference equations. If there is an edge going from node \u0026quot;a\u0026quot; to node \u0026quot;b\u0026quot;, its value is the reference value \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot;.\nLet\u0026rsquo;s consider an example where the reference equations are [[\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;], [\u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;]] and the reference values are [2.0, 3.0].\nTo find the value of \u0026quot;a\u0026quot; / \u0026quot;c\u0026quot;, we start in node \u0026quot;a\u0026quot;, then traverse past node \u0026quot;b\u0026quot; and arrive at node \u0026quot;c\u0026quot;. We multiply the values of all edges along the way and obtain 6.0.\nIt\u0026rsquo;s possible that an edge might exist from one variable to the other, but we need to traverse the path in the opposite direction. To handle this, we can add another edge whose value is the reciprocal of the reference equation value. For example, if the given equation is \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot; = 2.0, we add edges \u0026quot;a\u0026quot; -\u0026gt; \u0026quot;b\u0026quot; with value 2.0 and \u0026quot;b\u0026quot; -\u0026gt; \u0026quot;a\u0026quot; with value 1 / 2.0.\nEach symbol can be represented as a struct with incoming and outgoing connections. Each connection is a pair containing the other symbol and the edge value.\nstruct Symbol { vector\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; incoming; vector\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; outgoing; }; Let\u0026rsquo;s look at how to construct the graph. We store symbol objects in an unordered map, accessed by string keys. As we traverse the equations, we add new symbols to the map if they don\u0026rsquo;t yet exist. At every step, we also update the incoming and outgoing edges of each symbol with the appropriate equation value.\nvector\u0026lt;double\u0026gt; calcEquation(vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt;\u0026amp; equations, vector\u0026lt;double\u0026gt;\u0026amp; values, vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt;\u0026amp; queries) { unordered_map\u0026lt;string, Symbol*\u0026gt; symbols; for (size_t i = 0; i \u0026lt; equations.size(); ++i) { vector\u0026lt;string\u0026gt; eq = equations[i]; double value = values[i]; string s1 = eq[0]; string s2 = eq[1]; if (!symbols.contains(s1)) { symbols[s1] = new Symbol; } if (!symbols.contains(s2)) { symbols[s2] = new Symbol; } symbols[s1]-\u0026gt;outgoing.push_back({symbols[s2], value}); symbols[s2]-\u0026gt;incoming.push_back({symbols[s1], 1 / value}); } ... // we\u0026#39;ll implement the rest later } Evaluating an equation with BFS We\u0026rsquo;ll evaluate the equation by traversing the graph. However, cycles in the graph might cause us to loop indefinitely. We can avoid this by keeping track of already visited states in a set. We can avoid going to deep into the graph by using BFS instead of depth-first search (DFS), but a DFS solution is possible as well.\nWhen given a query \\(q_1 / q_2\\), we will construct a queue that contains with \\(q_1\\) and the corresponding initial path product 1.0. While the queue is not empty, we will pop its front element and add all its connected nodes to the back of the queue. If the popped element corresponds to \\(q_2\\), we will return the corresponding path product.\nLet\u0026rsquo;s look at the code. We first initialize the set of visited states and a queue containing the symbols and equation values. We then execute the queue loop as outlined above.\ndouble evaluate(Symbol *src, Symbol *dst) { set\u0026lt;Symbol*\u0026gt; visited; queue\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; q; q.push({src, 1.0}); while (!q.empty()) { pair\u0026lt;Symbol*, double\u0026gt; p = q.front(); q.pop(); // If we have not yet visited this symbol if (visited.find(p.first) == visited.end()) { // Have we arrived at the destination? if (p.first == dst) { return p.second; } // Add connecting symbols into ther queue for (auto pNext: p.first-\u0026gt;outgoing) { q.push({pNext.first, pNext.second * p.second}); } for (auto pNext: p.first-\u0026gt;incoming) { q.push({pNext.first, pNext.second * p.second}); } // Mark this symbol as visited visited.insert(p.first); } } // If no solution was found in the loop, return -1 return -1; } Full solution and complexity Below is the full solution code. The only practical addition is constructing an output vector and processing each query equation one-by-one.\nclass Solution { public: struct Symbol { vector\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; incoming; vector\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; outgoing; }; double evaluate(Symbol *src, Symbol *dst) { set\u0026lt;Symbol*\u0026gt; visited; queue\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; q; q.push({src, 1.0}); while (!q.empty()) { pair\u0026lt;Symbol*, double\u0026gt; p = q.front(); q.pop(); if (visited.find(p.first) == visited.end()) { if (p.first == dst) { return p.second; } for (auto pNext: p.first-\u0026gt;outgoing) { q.push({pNext.first, pNext.second * p.second}); } for (auto pNext: p.first-\u0026gt;incoming) { q.push({pNext.first, pNext.second * p.second}); } visited.insert(p.first); } } return -1; } vector\u0026lt;double\u0026gt; calcEquation(vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt;\u0026amp; equations, vector\u0026lt;double\u0026gt;\u0026amp; values, vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt;\u0026amp; queries) { unordered_map\u0026lt;string, Symbol*\u0026gt; symbols; for (size_t i = 0; i \u0026lt; equations.size(); ++i) { vector\u0026lt;string\u0026gt; eq = equations[i]; double value = values[i]; string s1 = eq[0]; string s2 = eq[1]; if (!symbols.contains(s1)) { symbols[s1] = new Symbol; } if (!symbols.contains(s2)) { symbols[s2] = new Symbol; } symbols[s1]-\u0026gt;outgoing.push_back({symbols[s2], value}); symbols[s2]-\u0026gt;incoming.push_back({symbols[s1], 1 / value}); } vector\u0026lt;double\u0026gt; out; for (size_t i = 0; i \u0026lt; queries.size(); ++i) { vector\u0026lt;string\u0026gt; eq = queries[i]; string s1 = eq[0]; string s2 = eq[1]; if (!symbols.contains(s1) || !symbols.contains(s2)) { out.push_back(-1.0); } else { out.push_back(evaluate(symbols[s1], symbols[s2])); } } return out; } }; Suppose there are \\(m\\) symbols in the \\(n\\) referenced equations. To evaluate a new query with BFS, we have to traverse at most \\(m\\) symbols. We can check whether a symbol is in symbol set or not in \\(O(1)\\) time, as the unordered set is implemented as a hash table with constant-time lookup. Given \\(k\\) queries, the worst-case time complexity is thus \\(O(km)\\).\nWe also need to store \\(m\\) symbols, at most \\(n\\) outgoing edges, and at most \\(n\\) incoming edges. Within each evaluation call, the constructed queue contains a variable amount of elements, potentially more than \\(m\\) depending on the input graph. However, never more than \\(m^2\\). The practical space complexity is \\(O(m+n)\\) to hold the graph and \\(O(m)\\) for the queue, although it can be dominated by \\(O(m^2)\\) for complicated input graphs. Let\u0026rsquo;s say \\(O(n+m)\\) for practical cases.\nLeetCode reports that this algorithm runs in 0ms, beating 100% of solution in runtime. It takes 11.75 MB memory, beating 80.54% in space utilization. That\u0026rsquo;s quite good!\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_399/","summary":"\u003cp\u003eHi, everyone! Today, we\u0026rsquo;ll be looking at \u003ca href=\"https://leetcode.com/problems/evaluate-division/?envType=study-plan-v2\u0026amp;envId=leetcode-75\"\u003eLeetCode problem 399\u003c/a\u003e.\nIn this problem, we are given a bunch of reference equations of the form \\(a_i / b_i = c_i\\) for \\(i = 1 , \\dots, n\\).\nThe symbols \\(a_i, b_i\\) are given as strings, while \\(c_i\\) are given as floating point numbers.\nWe\u0026rsquo;re then asked to compute the value of a \u003cem\u003equery\u003c/em\u003e equation \\(q_1 / q_2\\).\u003c/p\u003e\n\u003cp\u003eIf \\(q_1 / q_2\\) is one of the reference equations, we can return that value.\nOtherwise, we can follow a kind of \u003cem\u003echain-rule\u003c/em\u003e strategy.\nSuppose we are given \u003ccode\u003e\u0026quot;a\u0026quot; / \u0026quot;b\u0026quot;\u003c/code\u003e with value \u003ccode\u003e2.0\u003c/code\u003e and \u003ccode\u003e\u0026quot;b\u0026quot; / \u0026quot;c\u0026quot;\u003c/code\u003e with value \u003ccode\u003e3.0\u003c/code\u003e, then we can compute \u003ccode\u003e\u0026quot;a\u0026quot; / \u0026quot;c\u0026quot;\u003c/code\u003e by the product:\n\u003ccode\u003e\u0026quot;a\u0026quot; / \u0026quot;c\u0026quot; = \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot; * \u0026quot;b\u0026quot; / \u0026quot;c\u0026quot;\u003c/code\u003e, which is equal to \u003ccode\u003e2.0 * 3.0 = 6.0\u003c/code\u003e.\nIf there\u0026rsquo;s no way to find a solution, we return \u003ccode\u003e-1\u003c/code\u003e.\u003c/p\u003e","title":"LeetCode 399: Evaluate Division"},{"content":"Very quick post about finding the peak element in an array. This is LeetCode problem 162. We have an array nums with \\(n\\) integers and want to find the index of one of its peaks in \\(O(\\log n)\\) time. The important detail is this: no two neighboring elements have the same value.\nLet\u0026rsquo;s dive in!\nSolution To solve this in logarithmic time, we will use binary search. We start with a left index and a right index. We then compute a mid point mid = (left + right) / 2. Now we investigate what the local behavior around mid is. If nums[mid] \u0026gt; nums[mid + 1], it means that there\u0026rsquo;s no point searching for the peak at mid + 1 or to its right, so we set right = mid. Otherwise, there\u0026rsquo;s no point in searching for the peak at mid or to its left, so we set left = mid + 1.\nWe keep repeating this until left is greater or equal to right. Here\u0026rsquo;s the code:\nclass Solution { public: int findPeakElement(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int left = 0; int right = nums.size() - 1; int mid; while (left \u0026lt; right) { int mid = (left + right) / 2; if (nums[mid] \u0026gt; nums[mid + 1]) { right = mid; } else { left = mid + 1; } } return left; } }; The code beats 100% of other solutions in terms of runtime. The time complexity is \\(O(\\log n)\\), because we narrow down the search to half of the array in each loop iteration. Even more precisely, the number of iterations is at most \\(\\lceil \\log_2 n \\rceil\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_162/","summary":"\u003cp\u003eVery quick post about finding the peak element in an array.\nThis is \u003ca href=\"https://leetcode.com/problems/find-peak-element\"\u003eLeetCode problem 162\u003c/a\u003e.\nWe have an array \u003ccode\u003enums\u003c/code\u003e with \\(n\\) integers and want to find the index of one of its peaks in \\(O(\\log n)\\) time.\nThe important detail is this: no two neighboring elements have the same value.\u003c/p\u003e\n\u003cp\u003eLet\u0026rsquo;s dive in!\u003c/p\u003e\n\u003ch2 id=\"solution\"\u003eSolution\u003c/h2\u003e\n\u003cp\u003eTo solve this in logarithmic time, we will use binary search.\nWe start with a \u003ccode\u003eleft\u003c/code\u003e index and a \u003ccode\u003eright\u003c/code\u003e index.\nWe then compute a mid point \u003ccode\u003emid = (left + right) / 2\u003c/code\u003e.\nNow we investigate what the local behavior around \u003ccode\u003emid\u003c/code\u003e is.\nIf \u003ccode\u003enums[mid] \u0026gt; nums[mid + 1]\u003c/code\u003e, it means that there\u0026rsquo;s no point searching for the peak at \u003ccode\u003emid + 1\u003c/code\u003e or to its right, so we set \u003ccode\u003eright = mid\u003c/code\u003e.\nOtherwise, there\u0026rsquo;s no point in searching for the peak at \u003ccode\u003emid\u003c/code\u003e or to its left, so we set \u003ccode\u003eleft = mid + 1\u003c/code\u003e.\u003c/p\u003e","title":"LeetCode 162: Find Peak Element"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! And it\u0026rsquo;s very intuitive!\nSimplifying the action tree We\u0026rsquo;ll simplify the action tree in two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\]What are the initial values? If we buy on day 1, we have \\(H_1 = -S_1 - f\\). If we don\u0026rsquo;t we have \\(F_1 = 0\\). If there are \\(n\\) days, then our output will be \\(F_n\\). After all, it\u0026rsquo;s better to have sold our last stock than to still be holding it.\nFull solution and time complexity analysis The implementation is super straightforward. We simply apply the formula every day:\nclass Solution { public: int maxProfit(vector\u0026lt;int\u0026gt;\u0026amp; prices, int fee) { int holdBalance = -fee - prices[0]; // H_i int freeBalance = 0; // F_i for (size_t i = 1; i \u0026lt; prices.size(); ++i) { int newHoldBalance = max(holdBalance, freeBalance - fee - prices[i]); int newFreeBalance = max(freeBalance, holdBalance + prices[i]); holdBalance = newHoldBalance; freeBalance = newFreeBalance; } return freeBalance; } } That\u0026rsquo;s it! LeetCode says this solution takes 0 ms, beating 100% of other solutions in terms of runtime. It takes 58.98 MB memory, but this is only due to the input array and LeetCode\u0026rsquo;s overhead. We\u0026rsquo;re only using four integers after all.\nThe time complexity is \\(O (n)\\) as we only have to loop through the prices array once. The space complexity is \\(O(1)\\) as we only use four integers regardless of \\(n\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"This is the first post in a series solving problems from Fifty Challenging Problems in Probability by Frederick Mosteller (1987). The problem is paraphrased below; for reference, it is inspired by the original book.\nA drawer contains some red and black socks. Two socks are drawn at random, and the probability that both are red is \\(1/2\\).\nWhat is the minimum total number of socks? What is the minimum if the number of black socks is even? Let\u0026rsquo;s dive in!\nSetting up the basic equation We want to express the probability of drawing two red socks. Let \\(r\\) denote the number of red socks and let \\(b\\) denote the number of black socks. We consider two events:\n\\(R_1\\), the event that the first sock we draw is red. \\(R_2\\), the event that the second sock we draw is red. The probability that they are both red can be expressed as \\(p = P(R_1) P(R_2 | R_1)\\). In other words, the probability that we draw red first multiplied by the probability that we draw red second under the condition that we already drew red first.\nWe can compute the first as \\(P(R_1) = r / (r + b)\\), since we wish to draw one of \\(r\\) red socks out of a drawer containing \\(r + b\\) total socks. We can compute the second as \\(P(R_2 | R_1) = (r - 1) / (r + b - 1)\\). That\u0026rsquo;s because we are picking between \\(r-1\\) remaining red socks (remember: we already drew one) among \\(r + b - 1\\) remaining total socks.\nLet\u0026rsquo;s summarize the findings: \\[\r\\frac{r}{r+b} \\cdot \\frac{r-1}{r+b-1} = \\frac{1}{2}.\r\\]The key inequality We can observe the following: \\[\r\\frac{r}{r + b} \u003e \\frac{r - 1}{r + b - 1}.\r\\]This is the most crucial observation to solving our problem. Let\u0026rsquo;s verify it:\n$$\r\\begin{aligned}\r\\frac{r}{r+b} \u0026\u003e \\frac{r-1}{r+b-1} \\\\\rr(r+b-1) \u0026\u003e (r+b)(r-1) \\\\\rr^2 + rb - r \u0026\u003e r^2 - r + rb - b \\\\\r0 \u0026\u003e -b \\\\\rb \u0026\u003e 0.\r\\end{aligned}\r$$The final statement is true, because we\u0026rsquo;re solving a problem with a positive number of black (and red) socks.\nImplications of the inequality Several things naturally follow from our established inequality. First, we can say: \\[\r\\left(\\frac{r}{r+b}\\right)^2 \u003e \\frac{1}{2} \\quad \\textrm{and also} \\quad \\left(\\frac{r-1}{r+b-1}\\right)^2 \u003c \\frac{1}{2}.\r\\] Let\u0026rsquo;s put the two statements together: \\[\r\\left(\\frac{r}{r+b}\\right)^2 \u003e \\frac{1}{2} \u003e \\left(\\frac{r-1}{r+b-1}\\right)^2.\r\\]Solving this is cumbersome due to the squares. Let\u0026rsquo;s take the square root instead (since all terms are positive): \\[\r\\frac{r}{r+b} \u003e \\frac{1}{\\sqrt{2}} \u003e \\frac{r-1}{r+b-1}.\r\\]Bounding \\(r\\) with \\(b\\) We now have two inequalities, which we can potentially rearrange to bound the number of one type of socks with the other. Let\u0026rsquo;s try to bound \\(r\\) with \\(b\\).\nWe can rearrange the first equality for the first bound: \\[\r\\begin{aligned}\r\\frac{r}{r+b} \u0026\u003e \\frac{1}{\\sqrt{2}} \\\\\rr \u0026\u003e \\frac{r + b}{\\sqrt{2}} \\\\\rr \u0026\u003e \\frac{r}{\\sqrt{2}} + \\frac{b}{\\sqrt{2}} \\\\\rr - \\frac{r}{\\sqrt{2}} \u0026\u003e \\frac{b}{\\sqrt{2}} \\\\\r\\frac{r\\sqrt{2} - r}{\\sqrt{2}} \u0026\u003e \\frac{b}{\\sqrt{2}} \\\\\rr\\sqrt{2} - r \u0026\u003e b \\\\\rr(\\sqrt{2} - 1) \u0026\u003e b \\\\\rr \u0026\u003e \\frac{b}{\\sqrt{2} - 1}. \\\\\r\\end{aligned}\r\\]We can also rearrange the second inqeuality for the second bound: \\[\r\\begin{aligned}\r\\frac{1}{\\sqrt{2}} \u0026\u003e \\frac{r-1}{r+b-1} \\\\\r\\frac{r-1}{r+b-1} \u0026\u003c \\frac{1}{\\sqrt{2}} \\\\\rr-1 \u0026\u003c \\frac{r+b-1}{\\sqrt{2}} \\\\\rr-1 \u0026\u003c \\frac{r}{\\sqrt{2}} + \\frac{b-1}{\\sqrt{2}} \\\\\rr-\\frac{r}{\\sqrt{2}} \u0026\u003c 1 + \\frac{b-1}{\\sqrt{2}} \\\\\rr-\\frac{r}{\\sqrt{2}} \u0026\u003c \\frac{b + \\sqrt{2} - 1}{\\sqrt{2}} \\\\\r\\frac{r(\\sqrt{2} - 1)}{\\sqrt{2}} \u0026\u003c \\frac{b + \\sqrt{2} - 1}{\\sqrt{2}} \\\\\rr(\\sqrt{2} - 1) \u0026\u003c b + \\sqrt{2} - 1 \\\\\rr \u0026\u003c \\frac{b + \\sqrt{2} - 1}{\\sqrt{2} - 1} \\\\\rr \u0026\u003c \\frac{(b + (\\sqrt{2} -1))(\\sqrt{2} + 1)}{(\\sqrt{2} - 1)(\\sqrt{2} + 1)} \\\\\rr \u0026\u003c \\frac{b (\\sqrt{2} + 1) + 1}{1} \\\\\rr - 1 \u0026\u003c b (\\sqrt{2} + 1). \\\\\rr \u0026\u003c b (\\sqrt{2} + 1) + 1. \\\\\r\\end{aligned}\r\\]Now we can finally express full the bound as:\n\\[\rb (\\sqrt{2} + 1) \u003c r \u003c b (\\sqrt{2} + 1) + 1.\r\\]And since we\u0026rsquo;re looking for integer valued solutions, we can say: \\[\rr = \\left\\lceil b(\\sqrt{2} + 1) \\right\\rceil.\r\\]Finding suitable values of \\(r\\) and \\(b\\) Let\u0026rsquo;s try a few values of \\(b\\) and keep in mind that \\(\\sqrt{2} + 1 \\approx 2.41\\).\nIf \\(b = 1\\), then \\(r = 3\\) is the integer-valued solution. Let\u0026rsquo;s plug both values into the probability equation:\n\\[\r\\frac{r}{r+b} \\frac{r-1}{r+b-1} = \\frac{3}{4} \\cdot \\frac{2}{3} = \\frac{1}{2}.\r\\]So \\(r = 3, b = 1\\) is a solution! In fact, \\(b\\) can\u0026rsquo;t possibly be smaller, so this solution answers question (a): the minimum number of socks is \\( 3 + 1 = 4\\).\nLet\u0026rsquo;s try \\(b = 2\\); \\(r = 5\\) is the possible integer-valued solution. If we plug them into the probability formula, we get: \\[\r\\frac{r}{r+b} \\frac{r-1}{r+b-1} = \\frac{5}{7} \\cdot \\frac{4}{6} = \\frac{10}{21}.\r\\]Unfortunately, the probability is not equal to \\(1/2\\), so this is not a valid solution.\nWhile there is a real-valued solution for \\(r\\) in \\(\\left[b(\\sqrt{2}-1), b(\\sqrt{2}-1)+1 \\right]\\), there is no integer-valued solution. Only some values of \\(b\\) give valid values of \\(r\\). Let\u0026rsquo;s check them programatically to speed up our search. I\u0026rsquo;ve written a small Python script to do so:\nimport math c = math.sqrt(2) + 1 for b in range(1, 10000): r = int(math.ceil(b * c)) prob = r / (r + b) * (r - 1) / (r + b - 1) eps = 1e-10 if 0.5 - eps \u0026lt; prob \u0026lt; 0.5 + eps: print(f\u0026#39;r: {r}, b: {b} -\u0026gt; {prob}\u0026#39;) This script prints values of \\(r\\) and \\(b\\) when the probability is equal to 0.5 (allowing for some numerical imprecision). This will give us suitable candidates that we can check by hand. Running the script gives the following output:\nr: 3, b: 1 -\u0026gt; 0.5\rr: 15, b: 6 -\u0026gt; 0.5\rr: 85, b: 35 -\u0026gt; 0.5\rr: 493, b: 204 -\u0026gt; 0.5\rr: 2871, b: 1189 -\u0026gt; 0.5000000000000001\rr: 16731, b: 6930 -\u0026gt; 0.5 Our first solution shows up. The second solution is \\(r = 15, b = 6\\), which is the first with an even number of black socks. We can easily verify it by hand. This answers question (b): the minimum number of socks with an even number of black socks is \\(15 + 6 = 21\\). The four remaining solutions are also valid and there are more possibilities if we check greater values of \\(b\\).\nMinor optimization We can improve our solution-finding code. Instead of computing the probability, which involves division and hence some numerical errors, we can individually compute the numerator and denominator of the probability term. We can then check if the denominator is equal to two times the numerator. In fact, we can even avoid multiplication by two if we use a bit shift.\nHere\u0026rsquo;s the code.\nimport math c = math.sqrt(2) + 1 for b in range(1, 1000000): r = int(math.ceil(b * c)) p_numerator = r * (r - 1) p_denominator = (r + b) * (r + b - 1) if p_denominator == p_numerator \u0026lt;\u0026lt; 1: print(f\u0026#39;r: {r}, b: {b} -\u0026gt; {prob}\u0026#39;) I\u0026rsquo;ve even increased the number of iterations, since now we avoid false positives entirely. The code outputs these solutions:\nr: 3, b: 1 -\u0026gt; 0.5\rr: 15, b: 6 -\u0026gt; 0.5\rr: 85, b: 35 -\u0026gt; 0.5\rr: 493, b: 204 -\u0026gt; 0.5\rr: 2871, b: 1189 -\u0026gt; 0.5\rr: 16731, b: 6930 -\u0026gt; 0.5\rr: 97513, b: 40391 -\u0026gt; 0.5\rr: 568345, b: 235416 -\u0026gt; 0.5\rr: 3312555, b: 1372105 -\u0026gt; 0.5\rr: 19306983, b: 7997214 -\u0026gt; 0.5 Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More FCPP solutions coming soon :)\n","permalink":"http://localhost:1313/posts/fcpp_1_the_sock_drawer/","summary":"\u003cp\u003eThis is the first post in a series solving problems from \u003ca href=\"https://www.amazon.com/Challenging-Problems-Probability-Solutions-Mathematics/dp/0486653552\"\u003e\u003cem\u003eFifty Challenging Problems in Probability\u003c/em\u003e by Frederick Mosteller (1987)\u003c/a\u003e.\nThe problem is paraphrased below; for reference, it is inspired by the original book.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eA drawer contains some red and black socks. Two socks are drawn at random, and the probability that both are red is  \\(1/2\\).\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eWhat is the minimum total number of socks?\u003c/li\u003e\n\u003cli\u003eWhat is the minimum if the number of black socks is even?\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"FCPP 1: The Sock Drawer"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 2462: Total Cost to Hire K Workers. The instructions are as follows:\nYou are given a 0-indexed integer array costs where costs[i] is the cost of hiring the \\(i\\)-th worker. You are also given two integers \\(k\\) and candidates. We want to hire exactly \\(k\\) workers according to the following rules:\nYou will run \\(k\\) sessions and hire exactly one worker in each session. In each hiring session, choose the worker with the lowest cost from either the first candidates workers or the last candidates workers. Break the tie by the smallest index. For example, if costs = [3,2,7,7,1,2] and candidates = 2, then in the first hiring session, we will choose the 4th worker because they have the lowest cost [3,2,7,7,**1**,2]. In the second hiring session, we will choose 1st worker because they have the same lowest cost as 4th worker but they have the smallest index [3,**2**,7,7,2]. Please note that the indexing may be changed in the process. If there are fewer than candidates workers remaining, choose the worker with the lowest cost among them. Break the tie by the smallest index. A worker can only be chosen once. Return the total cost to hire exactly \\(k\\) workers.\nConstraints:\n1 \u0026lt;= costs.length \u0026lt;= 10^5 1 \u0026lt;= costs[i] \u0026lt;= 10^5 1 \u0026lt;= k, candidates \u0026lt;= costs.length Let\u0026rsquo;s dive in!\nStrategy Let \\(c\\) denote candidates for brevity.\nA naive strategy is to find the minimum from the first and last \\(c\\) options during each round. Each such round requires \\(2c\\) checking operations, which would give a time complexity of \\(O(kc)\\) across \\(k\\) rounds.\nWe can do better. Let\u0026rsquo;s maintain two priority queues: front and back. front will hold the first \\(c\\) unprocessed workers and back will hold the last \\(c\\) unprocessed workers. Each queue will grant access to its cheapest worker in \\(O(1)\\) time.\nDuring each round, we decide whether to choose the worker from front or back according to their cost. If we choose a worker from front, we add the next unprocessed worker from the left to front. If we choose a worker from back, we add the next unprocessed worker from the right to back. Each time we choose a worker, we increase the running cost to hire our workers.\nThere are two edge cases:\nIf there are at most \\(k\\) workers, then all workers will be accepted. If there are at most \\(2c\\) workers (i.e., \\(n \\leq 2c\\)), then we don\u0026rsquo;t need to maintain two priority queues. We can simply sort the workers by their cost in non-decreasing order and select the first \\(k\\). Implementation Let\u0026rsquo;s look at the code below. We maintain two indices: left and right. left tells us which worker we should add next to front. right tells us which worker we should add next to back. We also consider a technical edge case: if front is empty, we choose from back and vice-versa.\nclass Solution { public: long long totalCost(vector\u0026lt;int\u0026gt;\u0026amp; costs, int k, int candidates) { long long total = 0; size_t n = costs.size(); // Edge case 1 if (n \u0026lt;= k) { for (size_t i = 0; i \u0026lt; k; ++i) { total += costs[i]; } return total; } // Edge case 2 if (n \u0026lt;= 2 * candidates) { sort(costs.begin(), costs.end()); for (size_t i = 0; i \u0026lt; k; ++i) { total += costs[i]; } return total; } priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; front; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; back; for (size_t i = 0; i \u0026lt; candidates; ++i) { front.push(costs[i]); back.push(costs[n - 1 - i]); } size_t left = candidates - 1; size_t right = n - candidates; for (size_t i = 0; i \u0026lt; k; ++i) { if (front.empty() || back.top() \u0026lt; front.top()) { // Hire worker from the back total += back.top(); back.pop(); --right; if (left \u0026lt; right) { // Add new worker to the back back.push(costs[right]); } } else { // Hire worker from the front total += front.top(); front.pop(); ++left; if (left \u0026lt; right) { // Add new worker to the front front.push(costs[left]); } } } return total; } }; We break down the time complexity as follows:\nEdge case 1 requires \\(O(k)\\) time to sum the costs of all workers. This is equal to \\(O(n)\\) since this case only occurs when \\(k \\geq n\\). Edge case 2 requires \\(O(n \\log n)\\) time to sort the workers. Summing the first \\(k\\) costs takes \\(O(k)\\) time, but this is subsumed by the sorting time. The general case: We first make \\(c\\) insertions to each priority queue, with each insertion requiring \\(O(\\log c)\\) time. The time complexity for queue construction is thus \\(O(c \\log c)\\). We then make \\(k\\) iterations. In each iteration, we perform exactly one removal in \\(O(\\log c)\\) time and at most one insertion in \\(O(\\log c)\\) time. Overall, we need \\(O(k \\log c)\\) time for queue processing. The worst-case time complexity over all inputs is \\(O(n\\log n\\). However, time complexity becomes \\(O(c\\log c + k \\log c)\\) for inputs that are not edge cases.\nSince each priority queue holds at most \\(c\\) elements, the auxiliary space complexity is \\(O(c)\\).\nLeetCode indeed reports a runtime of 15 ms (beating 99.48% of other solutions) and a memory use of 74.50 MB (beating 100% of other solutions).\nMinor optimization Instead of constructing the heaps via incremental insertions into a priority_queue (which costs \\(O(c\\log c)\\) time), we can build them in linear time using make_heap (see the documentation). We construct front and back as vector objects and not priority queues. We then push the unsorted worker costs into each one in \\(O(c)\\) time. Finally, we call make_heap, which only requires \\(O(c)\\) time. We also have to modify the push and pop calls, though the high-level logic stays the same.\nLet\u0026rsquo;s look at the modified code for the general case. The actual runtime and space usage are pretty much the exact same, though this method is theoretically slightly faster, requiring \\(O(c)\\) time to construct each heap instead of the previous \\(O(c \\log c)\\).\nvector\u0026lt;int\u0026gt; front, back; front.reserve(candidates); back.reserve(candidates); for (int i = 0; i \u0026lt; candidates; ++i) { front.push_back(costs[i]); back.push_back(costs[n - 1 - i]); } // Build min-heaps make_heap(front.begin(), front.end(), greater\u0026lt;int\u0026gt;()); make_heap(back.begin(), back.end(), greater\u0026lt;int\u0026gt;()); size_t left = candidates - 1; size_t right = n - candidates; for (int i = 0; i \u0026lt; k; ++i) { if (front.empty() || (!back.empty() \u0026amp;\u0026amp; back.front() \u0026lt; front.front())) { // Take from back total += back.front(); pop_heap(back.begin(), back.end(), greater\u0026lt;int\u0026gt;()); back.pop_back(); --right; if (left \u0026lt; right) { back.push_back(costs[right]); push_heap(back.begin(), back.end(), greater\u0026lt;int\u0026gt;()); } } else { // Take from front total += front.front(); pop_heap(front.begin(), front.end(), greater\u0026lt;int\u0026gt;()); front.pop_back(); ++left; if (left \u0026lt; right) { front.push_back(costs[left]); push_heap(front.begin(), front.end(), greater\u0026lt;int\u0026gt;()); } } } Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\nSide note: with this blog post, I\u0026rsquo;ve finished the LeetCode 75 problem list! ðŸ¥³ðŸŽ‰ðŸŽ‰ðŸŽ‰\n","permalink":"http://localhost:1313/posts/leetcode_2462/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/total-cost-to-hire-k-workers/\"\u003eLeetCode problem 2462: Total Cost to Hire K Workers\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou are given a 0-indexed integer array \u003ccode\u003ecosts\u003c/code\u003e where \u003ccode\u003ecosts[i]\u003c/code\u003e is the cost of hiring the \\(i\\)-th worker.\nYou are also given two integers \\(k\\) and \u003ccode\u003ecandidates\u003c/code\u003e. We want to hire exactly \\(k\\) workers according to the following rules:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYou will run \\(k\\) sessions and hire exactly one worker in each session.\u003c/li\u003e\n\u003cli\u003eIn each hiring session, choose the worker with the lowest cost from either the first candidates workers or the last candidates workers. Break the tie by the smallest index.\n\u003cul\u003e\n\u003cli\u003eFor example, if \u003ccode\u003ecosts = [3,2,7,7,1,2]\u003c/code\u003e and \u003ccode\u003ecandidates = 2\u003c/code\u003e, then in the first hiring session, we will choose the 4th worker because they have the lowest cost \u003ccode\u003e[3,2,7,7,**1**,2]\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eIn the second hiring session, we will choose 1st worker because they have the same lowest cost as 4th worker but they have the smallest index \u003ccode\u003e[3,**2**,7,7,2]\u003c/code\u003e. Please note that the indexing may be changed in the process.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eIf there are fewer than candidates workers remaining, choose the worker with the lowest cost among them. Break the tie by the smallest index.\u003c/li\u003e\n\u003cli\u003eA worker can only be chosen once.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eReturn the total cost to hire exactly \\(k\\) workers.\u003c/p\u003e","title":"LeetCode 2462: Total Cost to Hire K Workers"},{"content":"Let\u0026rsquo;s solve LeetCode problem 88: Merge Sorted Array. This problem is quite short and straightforward.\nThe instructions are as follows:\nYou are given two integer arrays nums1 and nums2, sorted in non-decreasing order, and two integers \\(m\\) and \\(n\\), representing the number of elements in nums1 and nums2 respectively. Merge nums1 and nums2 into a single array sorted in non-decreasing order. The final sorted array should not be returned by the function, but instead be stored inside the array nums1. To accommodate this, nums1 has a length of \\(m\\) + \\(n\\), where the first \\(m\\) elements denote the elements that should be merged, and the last \\(n\\) elements are set to 0 and should be ignored. nums2 has a length of \\(n\\).\nConstraints:\nnums1.length == m + n nums2.length == n 0 \u0026lt;= m, n \u0026lt;= 200 1 \u0026lt;= m + n \u0026lt;= 200 -10^9 \u0026lt;= nums1[i], nums2[j] \u0026lt;= 10^9 Let\u0026rsquo;s dive in!\nStrategy and implementation We have to write the result to nums1. If we process the numbers from highest to lowest, we can avoid overwriting the first \\(m\\) values of nums1. Let\u0026rsquo;s create two indices i, j and initialize them to i = m - 1, j = n - 1. We will decrement these indices until they both reach 0. At each step, we do the following:\nIf nums1[i] \u0026gt; nums2[j], then we write nums1[i] to the next slot and decrement i. Otherwise, we write nums2[j] to the next slot and decrement j. The index of the next slot is simply i + j + 1.\nWhen i reaches 0, we write all the remaining values in nums2 to the start of nums1. When j reaches 0, we could write all the remaining values in nums1 to the start of nums1. However, this is already the case! Thus, we don\u0026rsquo;t need to do anything at all.\nLet\u0026rsquo;s look at the code below. I usually use size_t as the index data type, however I opted for int as decrementing past 0 causes an overflow and breaks the program.\nclass Solution { public: void merge(vector\u0026lt;int\u0026gt;\u0026amp; nums1, int m, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int n) { int i = m - 1; int j = n - 1; while (i \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026gt;= 0) { if (nums1[i] \u0026gt;= nums2[j]) { nums1[i + j + 1] = nums1[i]; i--; } else { nums1[i + j + 1] = nums2[j]; j--; } } while (j \u0026gt;= 0) { nums1[j] = nums2[j]; j--; } } }; LeetCode reports a runtime of 0 ms (beating 100% of other solutions) and memory usage of 12.17 MB (beating 95.41% of other solutions). I\u0026rsquo;m pretty sure this is effectively optimal and the memory usage is the lowest it could be.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_88/","summary":"\u003cp\u003eLet\u0026rsquo;s solve \u003ca href=\"https://leetcode.com/problems/merge-sorted-array/\"\u003eLeetCode problem 88: Merge Sorted Array\u003c/a\u003e.\nThis problem is quite short and straightforward.\u003c/p\u003e\n\u003cp\u003eThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou are given two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e, sorted in non-decreasing order, and two integers \\(m\\) and \\(n\\), representing the number of elements in \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e respectively.\nMerge \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e into a single array sorted in non-decreasing order.\nThe final sorted array should not be returned by the function, but instead be stored inside the array \u003ccode\u003enums1\u003c/code\u003e. To accommodate this, \u003ccode\u003enums1\u003c/code\u003e has a length of \\(m\\) + \\(n\\), where the first \\(m\\) elements denote the elements that should be merged, and the last \\(n\\) elements are set to 0 and should be ignored. \u003ccode\u003enums2\u003c/code\u003e has a length of \\(n\\).\u003c/p\u003e","title":"LeetCode 88: Merge Sorted Array"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 216: Combination Sum III. The instructions are as follows:\nFind all valid combinations of \\(k\\) numbers that sum up to \\(n\\) such that the following conditions are true:\nOnly numbers 1 through 9 are used. Each number is used at most once. Return a list of all possible valid combinations. The list must not contain the same combination twice, and the combinations may be returned in any order.\nConstraints:\n2 \u0026lt;= k \u0026lt;= 9 1 \u0026lt;= n \u0026lt;= 60 Let\u0026rsquo;s dive in!\nStrategy and implementation We can approach this problem by trying to fill up an empty vector v to size \\(k\\). Once v has length \\(k\\) and sums to \\(n\\), we add it to the vector of results. If it has length \\(k\\), but does not sum to \\(n\\), then we replace some elements in it.\nA systematic way of doing this is via backtracking. We create a recursive function void solve(size_t total), where total is the current sum of v. The function solve also has access to a global vector v, a global vector of vectors results, a target vector length variable, and a target sum variable.\nDuring each recursive call, we apply one of these three rules:\nIf v has length \\(k\\) and total equals \\(n\\), then we add v to results. If v is shorter than \\(k\\) and total \u0026lt; n, then we add recursively call solve several times. Before each call, we add a new number j to the end of the vector (j has to be bigger than the last element of v, but at most 9). We then call the function with solve(total + j) to indicate the change in the vector sum. During this call, solutions may be added to results. After the call finishes, we pop the last element of v and apply the procedure for the next value of j. If neither of the two rules above applies, we do nothing. Rule 1 and rule 3 are base cases for recursion. If rule 1 applies, we\u0026rsquo;ve identified v as one possible solution. If rule 3 applies, we did not. Rule 2 is the general case, during which we try to recursively construct solution vectors. In rule 2, backtracking occurs when we pop the last element of v.\nLet\u0026rsquo;s look at the code below. In combinationSum3, we set up two global variables and call solve with an empty vector v that has sum 0. Rule 2 is the most interesting part of solve. We start adding digits from j0 onward. If v is empty, we set j0 to 1, as that\u0026rsquo;s the smallest permissible number. If not, we set j0 to be one bigger than the last element of v. Then we add digits j from j0 to 9 inclusive. We apply the recursive call to solve and backtrack after the call finishes.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; results; vector\u0026lt;int\u0026gt; v; size_t targetLength; size_t targetSum; void solve(size_t total) { // Rule 1 if (v.size() == targetLength \u0026amp;\u0026amp; total == targetSum) { results.push_back(v); return; } // Rule 2 if (v.size() \u0026lt; targetLength \u0026amp;\u0026amp; total \u0026lt; targetSum) { size_t j0; if (v.size() == 0) { j0 = 1; } else { j0 = v.back() + 1; } for (size_t j = j0; j \u0026lt;= 9; j++) { v.push_back(j); solve(total + j); v.pop_back(); } return; } // Rule 3: nothing } vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; combinationSum3(int k, int n) { targetLength = k; targetSum = n; solve(0); return results; } }; We can bound the number of solutions to check with \\(9^k\\). A tighter bound is the number of strictly increasing sequences of length \\(k\\) with elements from \\(\\{1, \\dots, 9\\}\\). There are \\(\\binom{9}{k} = 9! / ((9-k)!k!)\\) such sequences. The maximal number of sequences is 126 and occurs at \\(k = 4\\) or \\(k = 5\\). The total number of candidates explored (including those shorter than \\(k\\)) is bounded by \\(\\sum_{i=0}^k \\binom{9}{i}\\), which is maximized when \\(k = 9\\) and equals 512.\nThe space complexity is \\(O(mk)\\) where \\(m\\) is the number of solutions. We can again say \\(m \\leq 126 \\) per the discussion above. Since \\(k \\leq 9\\), we need to store at most \\(9 \\cdot 126 = 1134 \\) digits, which is tiny.\nThe total runtime is effectively constant. LeetCode indeed reports a runtime of 0 ms (beating 100% of other solutions) and a memory use of 8.68 MB (beating 78.86% of other solutions).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_216/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/combination-sum-iii\"\u003eLeetCode problem 216: Combination Sum III\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eFind all valid combinations of \\(k\\) numbers that sum up to \\(n\\) such that the following conditions are true:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eOnly numbers 1 through 9 are used.\u003c/li\u003e\n\u003cli\u003eEach number is used at most once.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eReturn a list of all possible valid combinations. The list must not contain the same combination twice, and the combinations may be returned in any order.\u003c/p\u003e","title":"LeetCode 216: Combination Sum III"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 790: Domino and Tromino Tiling. The instructions are as follows:\nYou have two types of tiles: a 2 x 1 domino shape and a tromino shape. You may rotate these shapes. Given an integer \\(n\\), return the number of ways to tile an 2 x n board. Since the answer may be very large, return it modulo 10^9 + 7. In a tiling, every square must be covered by a tile. Two tilings are different if and only if there are two 4-directionally adjacent cells on the board such that exactly one of the tilings has both squares occupied by a tile.\nLet\u0026rsquo;s dive in!\nCounting the possible tilings Let\u0026rsquo;s look at all possible tilings for a few values of \\(n\\) in the image below. Unique new tilings We notice that each \\(n\\) has a few unique tilings that don\u0026rsquo;t show up before it:\nFor \\(n = 1\\), the last tiling is a unique new vertical domino. For \\(n = 2\\), the last tiling is a unique new pair of horizontal dominos. For \\(n = 3\\), the final two tilings are new and made up of two trominos. For \\(n = 4\\), the final two tilings are new and made up of two trominos and a domino. I\u0026rsquo;ve marked these in the image below. In fact, each new \\(n\\) introduces new unique tilings. Let\u0026rsquo;s look at these for \\(n \\leq 7\\). Clearly, there are always 2 new unique tilings for each \\(n \\geq 3\\).\nHow are the tilings constructed? Aside from these new and unique tilings, we can also notice a pattern in how the other tilings are constructed. Let\u0026rsquo;s consider \\(n = 4\\). I\u0026rsquo;ve purposely arranged the tilings to clearly see the pattern in the image below. The tilings are constructed as follows:\nTake all tilings for \\(n = 3\\) and append the unique tiling from \\(n = 1\\). Take all tilings for \\(n = 2\\) and append the unique tiling from \\(n = 2\\). Take all tilings for \\(n = 1\\) and append the unique tilings from \\(n = 3\\). We cover the edge case of new tilings by taking all the tilings for \\(n = 0\\) (i.e., nothing) and appending the unique tilings from \\(n = 4\\). The number of tilings for \\(n\\) are thus:\n\\[\rt(n) = t(n - 1) + t(n - 2) + \\sum_{i = 0}^{n - 3} 2 t(i).\r\\]The term \\(t(n - 1)\\) corresponds to tilings from \\(n - 1\\) and adding a vertical domino. The term \\(t(n - 2)\\) corresponds to tilings from \\(n - 2\\) and adding a horizontal domino pair. The remaining terms \\(t(i)\\) corresponds to tilings from \\(i\\) and adding two unique tilings (since we know each \\(n \\geq 3\\) has two new unique tilings), which is why each term is multiplied by \\(2\\).\nThis is the dynamic programming recurrence relation.\nSimplifying the recurrence relation We can simplify the equation above with some clever math. First, let\u0026rsquo;s construct a helper term with \\(t(n - 1)\\):\n\\[\rt(n - 1) = t(n - 2) + t(n - 3) + \\sum_{i = 0}^{n - 4} 2 t(i), \\;\\mathrm{therefore} \\\\\rt(n - 2) + t(n - 3) = t(n - 1) - \\sum_{i = 0}^{n - 4} 2 t(i).\r\\]We will use this term as a replacement inside the square brackets in the derivation below:\n\\[\rt(n) = t(n - 1) + t(n - 2) + \\sum_{i = 0}^{n - 3} 2 t(i) \\\\\r= t(n - 1) + t(n - 2) + 2 t(n - 3) + \\sum_{i = 0}^{n - 4} 2 t(i) \\\\\r= t(n - 1) + [t(n - 2) + t(n - 3)] + t(n - 3) + \\sum_{i = 0}^{n - 4} 2 t(i) \\\\\r= t(n - 1) + [t(n - 1) - \\sum_{i = 0}^{n - 4} 2 t(i)] + t(n - 3) + \\sum_{i = 0}^{n - 4} 2 t(i) \\\\\r= 2t(n - 1) + t(n - 3) \\\\\r\\]Full implementation The solution becomes trivial to implement using the simplified formula. We use a, b, c to hold \\(t(i - 3), t(i - 2),\\) and \\(t(i - 1)\\) respectively. We store \\(t(i)\\) inside variable d at each step. We iterate from \\(i = 4\\) to \\(i = n\\). After the loop, the final value \\(t(n)\\) is stored inside d (and c, because of the variable swap). We apply modulo according to the instructions to avoid overflows.\nclass Solution { public: int numTilings(int n) { if (n == 1) { return 1; } else if (n == 2) { return 2; } else if (n == 3) { return 5; } size_t a = 1; size_t b = 2; size_t c = 5; size_t d; for (size_t i = 4; i \u0026lt;= n; ++i) { d = (2 * c + a) % 1000000007; a = b; b = c; c = d; } return d; } }; This solution requires \\(O(n)\\) time and \\(O(1)\\) space. LeetCode reports a runtime of 0 ms (beating 100% of other solutions) and a memory use of 7.78 MB (beating 95.07% of other solutions). Super efficient!\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_790/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/domino-and-tromino-tiling\"\u003eLeetCode problem 790: Domino and Tromino Tiling\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou have two types of tiles: a \u003ccode\u003e2 x 1\u003c/code\u003e domino shape and a tromino shape. You may rotate these shapes.\nGiven an integer \\(n\\), return the number of ways to tile an \u003ccode\u003e2 x n\u003c/code\u003e board. Since the answer may be very large, return it modulo \u003ccode\u003e10^9 + 7\u003c/code\u003e.\nIn a tiling, every square must be covered by a tile. Two tilings are different if and only if there are two 4-directionally adjacent cells on the board such that exactly one of the tilings has both squares occupied by a tile.\u003c/p\u003e","title":"LeetCode 790: Domino and Tromino Tiling"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 875: Koko Eating Bananas. The instructions are as follows:\nKoko loves to eat bananas. There are n piles of bananas, the \\(i\\)-th pile has piles[i] bananas. The guards have gone and will come back in h hours. Koko can decide her bananas-per-hour eating speed of k. Each hour, she chooses some pile of bananas and eats k bananas from that pile. If the pile has less than k bananas, she eats all of them instead and will not eat any more bananas during this hour. Koko likes to eat slowly but still wants to finish eating all the bananas before the guards return. Return the minimum integer k such that she can eat all the bananas within h hours.\nConstraints:\n1 \u0026lt;= piles.length \u0026lt;= 10^4 piles.length \u0026lt;= h \u0026lt;= 10^9 1 \u0026lt;= piles[i] \u0026lt;= 10^9 Let\u0026rsquo;s dive in!\nChecking if a given rate is valid To check if a rate k is valid, we have to first compute the total time spent eating bananas across all piles with rate k and then ensure that this time is at most h. Let\u0026rsquo;s write this as helper function:\nint ceilDivision(int a, int b) { // return ceil(a / b) where a and b are integers return (a + b - 1) / b; } bool validRate(vector\u0026lt;int\u0026gt; *piles, int h, int k) { int total = 0; for (int i = 0; i \u0026lt; piles-\u0026gt;size(); ++i) { total += ceilDivision(piles-\u0026gt;at(i), k); } return total \u0026lt;= h; } If ceilDivision appears too complicated, think about this: the time spent eating pile \\(i\\) is equal to piles[i] / k if k evenly divides piles[i]. If it doesn\u0026rsquo;t, then there are still some bananas leftover and Koko has to spend an hour eating them. We can use the one-liner below.\ntotal += piles-\u0026gt;at(i) / k + (piles-\u0026gt;at(i) % k \u0026gt; 0); This is equivalent to our ceilDivision(piles-\u0026gt;at(i), k) function. More on the function in this StackOverflow discussion.\nBinary search strategy We\u0026rsquo;re trying to find the minimum integer rate k such that Koko can still eat all of the bananas in time h. The maximum possible rate is \\(m\\); the number of bananas on the biggest pile. Since h is at least the number of piles, using rate \\(m\\) means spending one hour for each pile. The minimum possible rate is \\(1\\).\nWe can simply apply binary search on the set \\(\\{1, 2, \\dots, m - 1, m\\}\\). For a candidate rate in the middle between the minimum and maximum rate, we check if it\u0026rsquo;s valid with the validRate function. If the rate is valid, we shift the maximum rate to the candidate rate (since the rate can\u0026rsquo;t be bigger). If it\u0026rsquo;s invalid, we shift the minimum rate to the candidate rate and add \\(1\\) (that\u0026rsquo;s the first rate that could possibly be valid).\nThe implementation is straightforward. Below is the full code.\nclass Solution { public: int ceilDivision(int a, int b) { // return ceil(a / b) where a and b are integers return (a + b - 1) / b; } bool validRate(vector\u0026lt;int\u0026gt; *piles, int h, int k) { int total = 0; for (int i = 0; i \u0026lt; piles-\u0026gt;size(); ++i) { total += ceilDivision(piles-\u0026gt;at(i), k); } return total \u0026lt;= h; } int minEatingSpeed(vector\u0026lt;int\u0026gt;\u0026amp; piles, int h) { int minRate = 1; int maxRate = *max_element(piles.begin(), piles.end()); while (minRate \u0026lt; maxRate) { int midRate = (minRate + maxRate) / 2; if (validRate(\u0026amp;piles, h, midRate)) { maxRate = midRate; } else { minRate = midRate + 1; } } return minRate; } }; This solution requires \\(O(n \\log m)\\) time and \\(O(1)\\) extra space. The time complexity derives from using \\(O(\\log m)\\) binary search steps, each requiring us to check \\(n\\) piles. LeetCode reports a runtime of 11 ms and a memory use of 22.83 MB (beating 76.17% of other solutions).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_875/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/koko-eating-bananas\"\u003eLeetCode problem 875: Koko Eating Bananas\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eKoko loves to eat bananas. There are \u003ccode\u003en\u003c/code\u003e piles of bananas, the \\(i\\)-th pile has \u003ccode\u003epiles[i]\u003c/code\u003e bananas.\nThe guards have gone and will come back in \u003ccode\u003eh\u003c/code\u003e hours.\nKoko can decide her bananas-per-hour eating speed of \u003ccode\u003ek\u003c/code\u003e.\nEach hour, she chooses some pile of bananas and eats \u003ccode\u003ek\u003c/code\u003e bananas from that pile.\nIf the pile has less than \u003ccode\u003ek\u003c/code\u003e bananas, she eats all of them instead and will not eat any more bananas during this hour.\nKoko likes to eat slowly but still wants to finish eating all the bananas before the guards return.\nReturn the minimum integer \u003ccode\u003ek\u003c/code\u003e such that she can eat all the bananas within \u003ccode\u003eh\u003c/code\u003e hours.\u003c/p\u003e","title":"LeetCode 875: Koko Eating Bananas"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 72: Edit distance. The instructions are as follows:\nGiven two strings word1 and word2, return the minimum number of operations required to convert word1 to word2. You have the following three operations permitted on a word:\nInsert a character Delete a character Replace a character Let\u0026rsquo;s dive in!\nThe Wagner-Fischer algorithm There are several types of edit distance. This LeetCode problem defines it as the Levenshtein distance. The most common algorithm to compute it is the Wagner-Fischer algorithm.\nSuppose word1 has length \\(m\\) and word2 has length \\(n\\). The Wagner-Fischer computes a matrix \\(D\\) of size \\((m+1) \\times (n+1)\\) that holds the edit distances between all prefixes of word1 and all prefixes of word2. Computing each edit distance reuses the adjacent edit distances in the matrix, making this a dynamic programming algorithm.\nSuppose word1[:i] is the length-\\(i\\) prefix of word1 and word2[:j] is the length-\\(j\\) prefix of word2. Then \\(D_{i,j}\\) holds the edit distance between word1[:i] and word2[:j].\nWe initialize the first row with values from 0 to \\(n\\) and the first column with values from 0 to \\(m\\). That\u0026rsquo;s because converting an empty string to word2[:j] requires \\(j\\) insertions. Similarly, converting word1[:i] to an empty string requires \\(i\\) deletions.\nHere\u0026rsquo;s the key rule to compute the edit distance:\n\\[\rD_{i,j} = \\min (D_{i-1, j} + 1, D_{i, j - 1} + 1, D_{i-1, j-1} + s),\r\\] where \\(s = 0\\) if word1[i - 1] == word2[j - 1] and \\(s = 1\\) otherwise.\nThe three terms in the minimum respectively correspond to deletion, insertion, and substitution. If we are in cell \\(D_{i,j}\\), then:\n\\(D_{i-1, j} + 1\\) corresponds to deleting word1[i - 1] from word1, \\(D_{i, j - 1} + 1\\) corresponds to inserting word2[j - 1] into word1 to match the longer prefix of word2, \\(D_{i - 1, j - 1} + s\\) corresponds to substituting word1[i - 1] with word2[j - 1] (or doing nothing if they are equal). After filling the matrix in this way, the final edit distance is \\(D_{m,n}\\).\nHere\u0026rsquo;s an example for word1 = \u0026quot;kitten\u0026quot; and word2 = \u0026quot;sitting\u0026quot;. The true edit distance is three: substitute \u0026quot;k\u0026quot; with \u0026quot;s\u0026quot;, substitute \u0026quot;e\u0026quot; with \u0026quot;i\u0026quot;, add \u0026quot;g\u0026quot; to the end.\nk i t t e n 0 1 2 3 4 5 6 s 1 1 1 2 3 4 5 i 2 2 1 2 3 4 5 t 3 3 2 1 2 3 4 t 4 4 3 2 1 2 3 i 5 5 4 3 2 2 3 n 6 6 5 4 3 3 2 g 7 7 6 5 4 4 3 The bottom right value in the matrix is indeed the true distance: 3.\nThe full code is shown below. Before running the Wagner-Fischer algorithm, we check if the two words are equal, which only takes \\(O(\\max(m, n))\\) time. The full algorithm takes \\(O(mn)\\) time and space.\nclass Solution { public: int minDistance(string word1, string word2) { if (word1 == word2) { return 0; } // Wagner-Fischer algorithm size_t m = word1.size(); size_t n = word2.size(); vector\u0026lt;vector\u0026lt;size_t\u0026gt;\u0026gt; d(m + 1, vector\u0026lt;size_t\u0026gt;(n + 1, 0)); for (size_t i = 1; i \u0026lt;= m; ++i) { d[i][0] = i; } for (size_t j = 1; j \u0026lt;= n; ++j) { d[0][j] = j; } for (size_t j = 1; j \u0026lt;= n; ++j) { for (size_t i = 1; i \u0026lt;= m; ++i) { bool substituted = (word1[i - 1] != word2[j - 1]); d[i][j] = min( d[i - 1][j] + 1, // deletion min( d[i][j - 1] + 1, // insertion d[i - 1][j - 1] + substituted // substitution ) ); } } return d[m][n]; } }; Running the code takes 4 ms (beating 81.58% of other solutions) and needs 15 MB of memory (beating 12.96% of other solutions).\nOptimized version with reduced space complexity The Wagner-Fischer algorithm can be optimized to use less space. The code above has to fill the matrix column-by-column. However, filling each cell only needs the values of the cells to the left, above, and to the top-left. This means we only need to keep:\nthe current column (namely the values above the current cell), and the column to the left of the current one. Now the space complexity will only be \\(O(m)\\), substantially less than \\(O(nm)\\). The time complexity remains the same.\nIt\u0026rsquo;s equivalent to keep two rows instead of two columns, as it\u0026rsquo;s essentially working with a transposed matrix \\(D\\). We\u0026rsquo;ll use the rows strategy so we can easily keep track of rows with the swap function. We\u0026rsquo;ll have a top row and a bottom row. Each row will have \\(n + 1\\) elements. After processing all characters in both words, we will implicitly have filled up all rows in the matrix. The result is stored in the last element of the bottom row.\nLet\u0026rsquo;s look at the code below. There\u0026rsquo;s a small optimization: if word1 with length \\(m\\) is shorter than word2 with length \\(n\\), we swap them. This brings down the space complexity to \\(O(\\min (m, n))\\) because \\(m \u003c n\\) and we now only have \\(m+1\\) elements in each row.\nclass Solution { public: int minDistance(string word1, string word2) { if (word1 == word2) { return 0; } if (word1.size() \u0026lt; word2.size()) { swap(word1, word2); } // Wagner-Fischer algorithm size_t m = word1.size(); size_t n = word2.size(); // Only store two rows vector\u0026lt;size_t\u0026gt; top(n + 1, 0); vector\u0026lt;size_t\u0026gt; bottom(n + 1, 0); for (size_t j = 1; j \u0026lt;= n; ++j) { top[j] = j; } for (size_t i = 1; i \u0026lt;= m; ++i) { bottom[0] = i; for (size_t j = 1; j \u0026lt;= n; ++j) { bool substituted = (word1[i - 1] != word2[j - 1]); bottom[j] = min( min( top[j] + 1, // deletion bottom[j - 1] + 1 // insertion ), top[j - 1] + substituted // substitution ); } swap(top, bottom); } return top[n]; // because of the swap } }; Running the code now takes 0 ms (beating 100% of other solutions) and needs 10.4 MB of memory (beating 98.46% of other solutions). The used space in the optimized version is about 2/3 of the space in the basic version of the algorithm.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_72/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/edit-distance\"\u003eLeetCode problem 72: Edit distance\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eGiven two strings \u003ccode\u003eword1\u003c/code\u003e and \u003ccode\u003eword2\u003c/code\u003e, return the minimum number of operations required to convert \u003ccode\u003eword1\u003c/code\u003e to \u003ccode\u003eword2\u003c/code\u003e. You have the following three operations permitted on a word:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eInsert a character\u003c/li\u003e\n\u003cli\u003eDelete a character\u003c/li\u003e\n\u003cli\u003eReplace a character\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLet\u0026rsquo;s dive in!\u003c/p\u003e\n\u003ch2 id=\"the-wagner-fischer-algorithm\"\u003eThe Wagner-Fischer algorithm\u003c/h2\u003e\n\u003cp\u003eThere are several types of \u003ca href=\"https://en.wikipedia.org/wiki/Edit_distance\"\u003eedit distance\u003c/a\u003e.\nThis LeetCode problem defines it as the \u003ca href=\"https://en.wikipedia.org/wiki/Levenshtein_distance\"\u003eLevenshtein distance\u003c/a\u003e.\nThe most common algorithm to compute it is the \u003ca href=\"https://en.wikipedia.org/wiki/Wagner%E2%80%93Fischer_algorithm\"\u003eWagner-Fischer algorithm\u003c/a\u003e.\u003c/p\u003e","title":"LeetCode 72: Edit distance"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 746: Min Cost Climbing Stairs. The instructions are as follows:\nYou are given an integer array cost where cost[i] is the cost of \\(i\\)-th step on a staircase. Once you pay the cost, you can either climb one or two steps. You can either start from the step with index 0, or the step with index 1. Return the minimum cost to reach the top of the floor.\nLet\u0026rsquo;s dive in!\nStrategy and solution Let\u0026rsquo;s think about the minimum cost required to reach stair \\(i\\). We could have arrived there from:\nstair \\(i-2\\), costing cost[i - 2] plus the minimum cost to arrive at stair \\(i - 2\\), or stair \\(i-1\\), costing cost[i - 1] plus the minimum cost to arrive at stair \\(i - 1\\). The cheapest path means taking the stair with the lower cost. If \\(m_i\\) is the minimum cost to arrive at stair \\(i\\) and \\(c_i\\) is cost[i], we can write the recurrence as:\n\\[\rm_i = \\min(c_{i - 2} + m_{i - 2}, c_{i - 1} + m_{i - 1}).\r\\]Since we can start at either stair 0 or stair 1, arriving there costs nothing. Therefore \\(m_0 = m_1 = 0\\). We could program this recursively and memoize the results to avoid recomputation. However, it\u0026rsquo;s much easier to simply use an iterative approach.\nLet\u0026rsquo;s look at the code below. We use minCost1 to hold \\(m_{i-2}\\) and minCost2 to hold \\(m_{i-1}\\). We store \\(m_i\\) inside minCost3. After each iteration, we set minCost1 to minCost2 and minCost2 to minCost3. The final result is in minCost2. This is similar to iteratively computing a number from the Fibonacci sequence.\nclass Solution { public: int minCostClimbingStairs(vector\u0026lt;int\u0026gt;\u0026amp; cost) { size_t minCost1 = 0; // cost to reach first stair size_t minCost2 = 0; // cost to reach second stair size_t minCost3; for (size_t i = 2; i \u0026lt;= cost.size(); ++i) { minCost3 = min( minCost1 + cost[i - 2], minCost2 + cost[i - 1] ); minCost1 = minCost2; minCost2 = minCost3; } return minCost2; } }; Given \\(n\\) stairs, the code requires \\(O(n)\\) time and \\(O(1)\\) space, which looks to be optimal. LeetCode reports a runtime of 0 ms (beating 100% of other solutions) and memory use of 17.56 MB, which is effectively just from the input data. Our actual code only uses a few integers. A very efficient solution!\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_746/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/min-cost-climbing-stairs\"\u003eLeetCode problem 746: Min Cost Climbing Stairs\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou are given an integer array \u003ccode\u003ecost\u003c/code\u003e where \u003ccode\u003ecost[i]\u003c/code\u003e is the cost of \\(i\\)-th step on a staircase. Once you pay the cost, you can either climb one or two steps.\nYou can either start from the step with index 0, or the step with index 1.\nReturn the minimum cost to reach the top of the floor.\u003c/p\u003e","title":"LeetCode 746: Min Cost Climbing Stairs"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 435: Non-overlapping intervals. The instructions are as follows:\nGiven an array of intervals intervals where intervals[i] = [start_i, end_i], return the minimum number of intervals you need to remove to make the rest of the intervals non-overlapping. Note that intervals which only touch at a point are non-overlapping. For example, [1, 2] and [2, 3] are non-overlapping.\nLet\u0026rsquo;s dive in!\nInterval scheduling reformulation Interval scheduling is a class of problems that involve a set of tasks, represented by their start and end times. The interval scheduling maximization problem (ISMP) is about finding the largest set of non-overlapping tasks. This is highly related to our interval removal problem. In fact, the following statements are equivalent:\nn is the total number of tasks and k is the maximum number of non-overlapping tasks that can be executed; the minimum number of intervals to make the rest non-overlapping is n - k. Let\u0026rsquo;s solve a variant of the well-known ISMP and use the result to answer the removal question. This is the single-interval scheduling problem (SISP), where we create an interval schedule in which no intervals overlap. A greedy algorithm called Earliest deadline first (EDF) finds the optimal solution to SISP. It\u0026rsquo;s described as follows:\nSelect the interval x with the earliest finishing time. Remove x and all intervals intersecting it from the set of candidate intervals. Repeat until there are no more candidate intervals. EDF starts by sorting the intervals by their end time in non-decreasing order. It then processes intervals from first to last.\nThis problem is also related to a similar interview question: maximum number of meetings in one room.\nSolving the counting problem Since we only need to count the number of compatible intervals, we don\u0026rsquo;t need to actually perform any removals. Instead, we start by sorting the intervals according to their end times. We initialize a counter k = 1 that counts the number of non-overlapping intervals. The first non-overlapping interval is simply the first one in the sorted list, i.e., the interval at index 0. We store its index in a variable prev = 0. Then loop over the rest of the intervals, starting at index i = 1. At each index, we check if interval at index i overlaps with the previously executed one. If so, we increment k and set prev = i. Otherwise, we simply move forward, as the interval at index i was caught in an overlap. We finally return n - k.\nLet\u0026rsquo;s look at the full code below.\nclass Solution { public: int eraseOverlapIntervals(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; intervals) { // Sort by end times sort( intervals.begin(), intervals.end(), [](const vector\u0026lt;int\u0026gt;\u0026amp; left, const vector\u0026lt;int\u0026gt;\u0026amp; right) { return left[1] \u0026lt; right[1]; } ); // Apply *Earliest deadline first* (EDF) size_t prev = 0; size_t k = 1; for (size_t i = 1; i \u0026lt; intervals.size(); ++i) { if (intervals[i][0] \u0026gt;= intervals[prev][1]) { k++; prev = i; } } // Return the number of intervals to remove return intervals.size() - k; } }; Complexity and empirical performance Our counting variant of EDF takes \\(O(n \\log n)\\) time to sort the intervals and \\(O(n)\\) to count the number of compatible intervals, so the total time complexity is \\(O(n \\log n)\\). Ignoring the input data, the space complexity is \\(O(1)\\) as we only need to use two integers: prev and k. LeetCode reports a runtime of 35 ms, which beats 95.23% of all solutions, as well as memory usage of 93.79 MB, which beats 98.60% of all solutions.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_435/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/non-overlapping-intervals\"\u003eLeetCode problem 435: Non-overlapping intervals\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eGiven an array of intervals intervals where \u003ccode\u003eintervals[i] = [start_i, end_i]\u003c/code\u003e, return the minimum number of intervals you need to remove to make the rest of the intervals non-overlapping.\nNote that intervals which only touch at a point are non-overlapping. For example, \u003ccode\u003e[1, 2]\u003c/code\u003e and \u003ccode\u003e[2, 3]\u003c/code\u003e are non-overlapping.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLet\u0026rsquo;s dive in!\u003c/p\u003e\n\u003ch2 id=\"interval-scheduling-reformulation\"\u003eInterval scheduling reformulation\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Interval_scheduling\"\u003eInterval scheduling\u003c/a\u003e is a class of problems that involve a set of tasks, represented by their start and end times.\nThe \u003cem\u003einterval scheduling maximization problem\u003c/em\u003e (ISMP) is about finding the largest set of non-overlapping tasks.\nThis is highly related to our interval removal problem.\nIn fact, the following statements are equivalent:\u003c/p\u003e","title":"LeetCode 435: Non-overlapping Intervals"},{"content":"Hi, everyone! Today, we\u0026rsquo;ll be looking at LeetCode problem 399. In this problem, we are given a bunch of reference equations of the form \\(a_i / b_i = c_i\\) for \\(i = 1 , \\dots, n\\). The symbols \\(a_i, b_i\\) are given as strings, while \\(c_i\\) are given as floating point numbers. We\u0026rsquo;re then asked to compute the value of a query equation \\(q_1 / q_2\\).\nIf \\(q_1 / q_2\\) is one of the reference equations, we can return that value. Otherwise, we can follow a kind of chain-rule strategy. Suppose we are given \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot; with value 2.0 and \u0026quot;b\u0026quot; / \u0026quot;c\u0026quot; with value 3.0, then we can compute \u0026quot;a\u0026quot; / \u0026quot;c\u0026quot; by the product: \u0026quot;a\u0026quot; / \u0026quot;c\u0026quot; = \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot; * \u0026quot;b\u0026quot; / \u0026quot;c\u0026quot;, which is equal to 2.0 * 3.0 = 6.0. If there\u0026rsquo;s no way to find a solution, we return -1.\nWe\u0026rsquo;ll approach this as a graph problem and use breadth-first search (BFS). Let\u0026rsquo;s dive in!\nConstructing a graph of symbols We approach this problem by first constructing a graph. Each node represents a symbol as given in the reference equations. If there is an edge going from node \u0026quot;a\u0026quot; to node \u0026quot;b\u0026quot;, its value is the reference value \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot;.\nLet\u0026rsquo;s consider an example where the reference equations are [[\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;], [\u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;]] and the reference values are [2.0, 3.0].\nTo find the value of \u0026quot;a\u0026quot; / \u0026quot;c\u0026quot;, we start in node \u0026quot;a\u0026quot;, then traverse past node \u0026quot;b\u0026quot; and arrive at node \u0026quot;c\u0026quot;. We multiply the values of all edges along the way and obtain 6.0.\nIt\u0026rsquo;s possible that an edge might exist from one variable to the other, but we need to traverse the path in the opposite direction. To handle this, we can add another edge whose value is the reciprocal of the reference equation value. For example, if the given equation is \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot; = 2.0, we add edges \u0026quot;a\u0026quot; -\u0026gt; \u0026quot;b\u0026quot; with value 2.0 and \u0026quot;b\u0026quot; -\u0026gt; \u0026quot;a\u0026quot; with value 1 / 2.0.\nEach symbol can be represented as a struct with incoming and outgoing connections. Each connection is a pair containing the other symbol and the edge value.\nstruct Symbol { vector\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; incoming; vector\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; outgoing; }; Let\u0026rsquo;s look at how to construct the graph. We store symbol objects in an unordered map, accessed by string keys. As we traverse the equations, we add new symbols to the map if they don\u0026rsquo;t yet exist. At every step, we also update the incoming and outgoing edges of each symbol with the appropriate equation value.\nvector\u0026lt;double\u0026gt; calcEquation(vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt;\u0026amp; equations, vector\u0026lt;double\u0026gt;\u0026amp; values, vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt;\u0026amp; queries) { unordered_map\u0026lt;string, Symbol*\u0026gt; symbols; for (size_t i = 0; i \u0026lt; equations.size(); ++i) { vector\u0026lt;string\u0026gt; eq = equations[i]; double value = values[i]; string s1 = eq[0]; string s2 = eq[1]; if (!symbols.contains(s1)) { symbols[s1] = new Symbol; } if (!symbols.contains(s2)) { symbols[s2] = new Symbol; } symbols[s1]-\u0026gt;outgoing.push_back({symbols[s2], value}); symbols[s2]-\u0026gt;incoming.push_back({symbols[s1], 1 / value}); } ... // we\u0026#39;ll implement the rest later } Evaluating an equation with BFS We\u0026rsquo;ll evaluate the equation by traversing the graph. However, cycles in the graph might cause us to loop indefinitely. We can avoid this by keeping track of already visited states in a set. We can avoid going to deep into the graph by using BFS instead of depth-first search (DFS), but a DFS solution is possible as well.\nWhen given a query \\(q_1 / q_2\\), we will construct a queue that contains with \\(q_1\\) and the corresponding initial path product 1.0. While the queue is not empty, we will pop its front element and add all its connected nodes to the back of the queue. If the popped element corresponds to \\(q_2\\), we will return the corresponding path product.\nLet\u0026rsquo;s look at the code. We first initialize the set of visited states and a queue containing the symbols and equation values. We then execute the queue loop as outlined above.\ndouble evaluate(Symbol *src, Symbol *dst) { set\u0026lt;Symbol*\u0026gt; visited; queue\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; q; q.push({src, 1.0}); while (!q.empty()) { pair\u0026lt;Symbol*, double\u0026gt; p = q.front(); q.pop(); // If we have not yet visited this symbol if (visited.find(p.first) == visited.end()) { // Have we arrived at the destination? if (p.first == dst) { return p.second; } // Add connecting symbols into ther queue for (auto pNext: p.first-\u0026gt;outgoing) { q.push({pNext.first, pNext.second * p.second}); } for (auto pNext: p.first-\u0026gt;incoming) { q.push({pNext.first, pNext.second * p.second}); } // Mark this symbol as visited visited.insert(p.first); } } // If no solution was found in the loop, return -1 return -1; } Full solution and complexity Below is the full solution code. The only practical addition is constructing an output vector and processing each query equation one-by-one.\nclass Solution { public: struct Symbol { vector\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; incoming; vector\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; outgoing; }; double evaluate(Symbol *src, Symbol *dst) { set\u0026lt;Symbol*\u0026gt; visited; queue\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; q; q.push({src, 1.0}); while (!q.empty()) { pair\u0026lt;Symbol*, double\u0026gt; p = q.front(); q.pop(); if (visited.find(p.first) == visited.end()) { if (p.first == dst) { return p.second; } for (auto pNext: p.first-\u0026gt;outgoing) { q.push({pNext.first, pNext.second * p.second}); } for (auto pNext: p.first-\u0026gt;incoming) { q.push({pNext.first, pNext.second * p.second}); } visited.insert(p.first); } } return -1; } vector\u0026lt;double\u0026gt; calcEquation(vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt;\u0026amp; equations, vector\u0026lt;double\u0026gt;\u0026amp; values, vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt;\u0026amp; queries) { unordered_map\u0026lt;string, Symbol*\u0026gt; symbols; for (size_t i = 0; i \u0026lt; equations.size(); ++i) { vector\u0026lt;string\u0026gt; eq = equations[i]; double value = values[i]; string s1 = eq[0]; string s2 = eq[1]; if (!symbols.contains(s1)) { symbols[s1] = new Symbol; } if (!symbols.contains(s2)) { symbols[s2] = new Symbol; } symbols[s1]-\u0026gt;outgoing.push_back({symbols[s2], value}); symbols[s2]-\u0026gt;incoming.push_back({symbols[s1], 1 / value}); } vector\u0026lt;double\u0026gt; out; for (size_t i = 0; i \u0026lt; queries.size(); ++i) { vector\u0026lt;string\u0026gt; eq = queries[i]; string s1 = eq[0]; string s2 = eq[1]; if (!symbols.contains(s1) || !symbols.contains(s2)) { out.push_back(-1.0); } else { out.push_back(evaluate(symbols[s1], symbols[s2])); } } return out; } }; Suppose there are \\(m\\) symbols in the \\(n\\) referenced equations. To evaluate a new query with BFS, we have to traverse at most \\(m\\) symbols. We can check whether a symbol is in symbol set or not in \\(O(1)\\) time, as the unordered set is implemented as a hash table with constant-time lookup. Given \\(k\\) queries, the worst-case time complexity is thus \\(O(km)\\).\nWe also need to store \\(m\\) symbols, at most \\(n\\) outgoing edges, and at most \\(n\\) incoming edges. Within each evaluation call, the constructed queue contains a variable amount of elements, potentially more than \\(m\\) depending on the input graph. However, never more than \\(m^2\\). The practical space complexity is \\(O(m+n)\\) to hold the graph and \\(O(m)\\) for the queue, although it can be dominated by \\(O(m^2)\\) for complicated input graphs. Let\u0026rsquo;s say \\(O(n+m)\\) for practical cases.\nLeetCode reports that this algorithm runs in 0ms, beating 100% of solution in runtime. It takes 11.75 MB memory, beating 80.54% in space utilization. That\u0026rsquo;s quite good!\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_399/","summary":"\u003cp\u003eHi, everyone! Today, we\u0026rsquo;ll be looking at \u003ca href=\"https://leetcode.com/problems/evaluate-division/?envType=study-plan-v2\u0026amp;envId=leetcode-75\"\u003eLeetCode problem 399\u003c/a\u003e.\nIn this problem, we are given a bunch of reference equations of the form \\(a_i / b_i = c_i\\) for \\(i = 1 , \\dots, n\\).\nThe symbols \\(a_i, b_i\\) are given as strings, while \\(c_i\\) are given as floating point numbers.\nWe\u0026rsquo;re then asked to compute the value of a \u003cem\u003equery\u003c/em\u003e equation \\(q_1 / q_2\\).\u003c/p\u003e\n\u003cp\u003eIf \\(q_1 / q_2\\) is one of the reference equations, we can return that value.\nOtherwise, we can follow a kind of \u003cem\u003echain-rule\u003c/em\u003e strategy.\nSuppose we are given \u003ccode\u003e\u0026quot;a\u0026quot; / \u0026quot;b\u0026quot;\u003c/code\u003e with value \u003ccode\u003e2.0\u003c/code\u003e and \u003ccode\u003e\u0026quot;b\u0026quot; / \u0026quot;c\u0026quot;\u003c/code\u003e with value \u003ccode\u003e3.0\u003c/code\u003e, then we can compute \u003ccode\u003e\u0026quot;a\u0026quot; / \u0026quot;c\u0026quot;\u003c/code\u003e by the product:\n\u003ccode\u003e\u0026quot;a\u0026quot; / \u0026quot;c\u0026quot; = \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot; * \u0026quot;b\u0026quot; / \u0026quot;c\u0026quot;\u003c/code\u003e, which is equal to \u003ccode\u003e2.0 * 3.0 = 6.0\u003c/code\u003e.\nIf there\u0026rsquo;s no way to find a solution, we return \u003ccode\u003e-1\u003c/code\u003e.\u003c/p\u003e","title":"LeetCode 399: Evaluate Division"},{"content":"Very quick post about finding the peak element in an array. This is LeetCode problem 162. We have an array nums with \\(n\\) integers and want to find the index of one of its peaks in \\(O(\\log n)\\) time. The important detail is this: no two neighboring elements have the same value.\nLet\u0026rsquo;s dive in!\nSolution To solve this in logarithmic time, we will use binary search. We start with a left index and a right index. We then compute a mid point mid = (left + right) / 2. Now we investigate what the local behavior around mid is. If nums[mid] \u0026gt; nums[mid + 1], it means that there\u0026rsquo;s no point searching for the peak at mid + 1 or to its right, so we set right = mid. Otherwise, there\u0026rsquo;s no point in searching for the peak at mid or to its left, so we set left = mid + 1.\nWe keep repeating this until left is greater or equal to right. Here\u0026rsquo;s the code:\nclass Solution { public: int findPeakElement(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int left = 0; int right = nums.size() - 1; int mid; while (left \u0026lt; right) { int mid = (left + right) / 2; if (nums[mid] \u0026gt; nums[mid + 1]) { right = mid; } else { left = mid + 1; } } return left; } }; The code beats 100% of other solutions in terms of runtime. The time complexity is \\(O(\\log n)\\), because we narrow down the search to half of the array in each loop iteration. Even more precisely, the number of iterations is at most \\(\\lceil \\log_2 n \\rceil\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_162/","summary":"\u003cp\u003eVery quick post about finding the peak element in an array.\nThis is \u003ca href=\"https://leetcode.com/problems/find-peak-element\"\u003eLeetCode problem 162\u003c/a\u003e.\nWe have an array \u003ccode\u003enums\u003c/code\u003e with \\(n\\) integers and want to find the index of one of its peaks in \\(O(\\log n)\\) time.\nThe important detail is this: no two neighboring elements have the same value.\u003c/p\u003e\n\u003cp\u003eLet\u0026rsquo;s dive in!\u003c/p\u003e\n\u003ch2 id=\"solution\"\u003eSolution\u003c/h2\u003e\n\u003cp\u003eTo solve this in logarithmic time, we will use binary search.\nWe start with a \u003ccode\u003eleft\u003c/code\u003e index and a \u003ccode\u003eright\u003c/code\u003e index.\nWe then compute a mid point \u003ccode\u003emid = (left + right) / 2\u003c/code\u003e.\nNow we investigate what the local behavior around \u003ccode\u003emid\u003c/code\u003e is.\nIf \u003ccode\u003enums[mid] \u0026gt; nums[mid + 1]\u003c/code\u003e, it means that there\u0026rsquo;s no point searching for the peak at \u003ccode\u003emid + 1\u003c/code\u003e or to its right, so we set \u003ccode\u003eright = mid\u003c/code\u003e.\nOtherwise, there\u0026rsquo;s no point in searching for the peak at \u003ccode\u003emid\u003c/code\u003e or to its left, so we set \u003ccode\u003eleft = mid + 1\u003c/code\u003e.\u003c/p\u003e","title":"LeetCode 162: Find Peak Element"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! And it\u0026rsquo;s very intuitive!\nSimplifying the action tree We\u0026rsquo;ll simplify the action tree in two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\]What are the initial values? If we buy on day 1, we have \\(H_1 = -S_1 - f\\). If we don\u0026rsquo;t we have \\(F_1 = 0\\). If there are \\(n\\) days, then our output will be \\(F_n\\). After all, it\u0026rsquo;s better to have sold our last stock than to still be holding it.\nFull solution and time complexity analysis The implementation is super straightforward. We simply apply the formula every day:\nclass Solution { public: int maxProfit(vector\u0026lt;int\u0026gt;\u0026amp; prices, int fee) { int holdBalance = -fee - prices[0]; // H_i int freeBalance = 0; // F_i for (size_t i = 1; i \u0026lt; prices.size(); ++i) { int newHoldBalance = max(holdBalance, freeBalance - fee - prices[i]); int newFreeBalance = max(freeBalance, holdBalance + prices[i]); holdBalance = newHoldBalance; freeBalance = newFreeBalance; } return freeBalance; } } That\u0026rsquo;s it! LeetCode says this solution takes 0 ms, beating 100% of other solutions in terms of runtime. It takes 58.98 MB memory, but this is only due to the input array and LeetCode\u0026rsquo;s overhead. We\u0026rsquo;re only using four integers after all.\nThe time complexity is \\(O (n)\\) as we only have to loop through the prices array once. The space complexity is \\(O(1)\\) as we only use four integers regardless of \\(n\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"This is the first post in a series solving problems from Fifty Challenging Problems in Probability by Frederick Mosteller (1987). The problem is paraphrased below; for reference, it is inspired by the original book.\nA drawer contains some red and black socks. Two socks are drawn at random, and the probability that both are red is \\(1/2\\).\nWhat is the minimum total number of socks? What is the minimum if the number of black socks is even? Let\u0026rsquo;s dive in!\nSetting up the basic equation We want to express the probability of drawing two red socks. Let \\(r\\) denote the number of red socks and let \\(b\\) denote the number of black socks. We consider two events:\n\\(R_1\\), the event that the first sock we draw is red. \\(R_2\\), the event that the second sock we draw is red. The probability that they are both red can be expressed as \\(p = P(R_1) P(R_2 | R_1)\\). In other words, the probability that we draw red first multiplied by the probability that we draw red second under the condition that we already drew red first.\nWe can compute the first as \\(P(R_1) = r / (r + b)\\), since we wish to draw one of \\(r\\) red socks out of a drawer containing \\(r + b\\) total socks. We can compute the second as \\(P(R_2 | R_1) = (r - 1) / (r + b - 1)\\). That\u0026rsquo;s because we are picking between \\(r-1\\) remaining red socks (remember: we already drew one) among \\(r + b - 1\\) remaining total socks.\nLet\u0026rsquo;s summarize the findings: \\[\r\\frac{r}{r+b} \\cdot \\frac{r-1}{r+b-1} = \\frac{1}{2}.\r\\]The key inequality We can observe the following: \\[\r\\frac{r}{r + b} \u003e \\frac{r - 1}{r + b - 1}.\r\\]This is the most crucial observation to solving our problem. Let\u0026rsquo;s verify it:\n$$\r\\begin{aligned}\r\\frac{r}{r+b} \u0026\u003e \\frac{r-1}{r+b-1} \\\\\rr(r+b-1) \u0026\u003e (r+b)(r-1) \\\\\rr^2 + rb - r \u0026\u003e r^2 - r + rb - b \\\\\r0 \u0026\u003e -b \\\\\rb \u0026\u003e 0.\r\\end{aligned}\r$$The final statement is true, because we\u0026rsquo;re solving a problem with a positive number of black (and red) socks.\nImplications of the inequality Several things naturally follow from our established inequality. First, we can say: \\[\r\\left(\\frac{r}{r+b}\\right)^2 \u003e \\frac{1}{2} \\quad \\textrm{and also} \\quad \\left(\\frac{r-1}{r+b-1}\\right)^2 \u003c \\frac{1}{2}.\r\\] Let\u0026rsquo;s put the two statements together: \\[\r\\left(\\frac{r}{r+b}\\right)^2 \u003e \\frac{1}{2} \u003e \\left(\\frac{r-1}{r+b-1}\\right)^2.\r\\]Solving this is cumbersome due to the squares. Let\u0026rsquo;s take the square root instead (since all terms are positive): \\[\r\\frac{r}{r+b} \u003e \\frac{1}{\\sqrt{2}} \u003e \\frac{r-1}{r+b-1}.\r\\]Bounding \\(r\\) with \\(b\\) We now have two inequalities, which we can potentially rearrange to bound the number of one type of socks with the other. Let\u0026rsquo;s try to bound \\(r\\) with \\(b\\).\nWe can rearrange the first equality for the first bound: \\[\r\\begin{aligned}\r\\frac{r}{r+b} \u0026\u003e \\frac{1}{\\sqrt{2}} \\\\\rr \u0026\u003e \\frac{r + b}{\\sqrt{2}} \\\\\rr \u0026\u003e \\frac{r}{\\sqrt{2}} + \\frac{b}{\\sqrt{2}} \\\\\rr - \\frac{r}{\\sqrt{2}} \u0026\u003e \\frac{b}{\\sqrt{2}} \\\\\r\\frac{r\\sqrt{2} - r}{\\sqrt{2}} \u0026\u003e \\frac{b}{\\sqrt{2}} \\\\\rr\\sqrt{2} - r \u0026\u003e b \\\\\rr(\\sqrt{2} - 1) \u0026\u003e b \\\\\rr \u0026\u003e \\frac{b}{\\sqrt{2} - 1}. \\\\\r\\end{aligned}\r\\]We can also rearrange the second inqeuality for the second bound: \\[\r\\begin{aligned}\r\\frac{1}{\\sqrt{2}} \u0026\u003e \\frac{r-1}{r+b-1} \\\\\r\\frac{r-1}{r+b-1} \u0026\u003c \\frac{1}{\\sqrt{2}} \\\\\rr-1 \u0026\u003c \\frac{r+b-1}{\\sqrt{2}} \\\\\rr-1 \u0026\u003c \\frac{r}{\\sqrt{2}} + \\frac{b-1}{\\sqrt{2}} \\\\\rr-\\frac{r}{\\sqrt{2}} \u0026\u003c 1 + \\frac{b-1}{\\sqrt{2}} \\\\\rr-\\frac{r}{\\sqrt{2}} \u0026\u003c \\frac{b + \\sqrt{2} - 1}{\\sqrt{2}} \\\\\r\\frac{r(\\sqrt{2} - 1)}{\\sqrt{2}} \u0026\u003c \\frac{b + \\sqrt{2} - 1}{\\sqrt{2}} \\\\\rr(\\sqrt{2} - 1) \u0026\u003c b + \\sqrt{2} - 1 \\\\\rr \u0026\u003c \\frac{b + \\sqrt{2} - 1}{\\sqrt{2} - 1} \\\\\rr \u0026\u003c \\frac{(b + (\\sqrt{2} -1))(\\sqrt{2} + 1)}{(\\sqrt{2} - 1)(\\sqrt{2} + 1)} \\\\\rr \u0026\u003c \\frac{b (\\sqrt{2} + 1) + 1}{1} \\\\\rr - 1 \u0026\u003c b (\\sqrt{2} + 1). \\\\\rr \u0026\u003c b (\\sqrt{2} + 1) + 1. \\\\\r\\end{aligned}\r\\]Now we can finally express full the bound as:\n\\[\rb (\\sqrt{2} + 1) \u003c r \u003c b (\\sqrt{2} + 1) + 1.\r\\]And since we\u0026rsquo;re looking for integer valued solutions, we can say: \\[\rr = \\left\\lceil b(\\sqrt{2} + 1) \\right\\rceil.\r\\]Finding suitable values of \\(r\\) and \\(b\\) Let\u0026rsquo;s try a few values of \\(b\\) and keep in mind that \\(\\sqrt{2} + 1 \\approx 2.41\\).\nIf \\(b = 1\\), then \\(r = 3\\) is the integer-valued solution. Let\u0026rsquo;s plug both values into the probability equation:\n\\[\r\\frac{r}{r+b} \\frac{r-1}{r+b-1} = \\frac{3}{4} \\cdot \\frac{2}{3} = \\frac{1}{2}.\r\\]So \\(r = 3, b = 1\\) is a solution! In fact, \\(b\\) can\u0026rsquo;t possibly be smaller, so this solution answers question (a): the minimum number of socks is \\( 3 + 1 = 4\\).\nLet\u0026rsquo;s try \\(b = 2\\); \\(r = 5\\) is the possible integer-valued solution. If we plug them into the probability formula, we get: \\[\r\\frac{r}{r+b} \\frac{r-1}{r+b-1} = \\frac{5}{7} \\cdot \\frac{4}{6} = \\frac{10}{21}.\r\\]Unfortunately, the probability is not equal to \\(1/2\\), so this is not a valid solution.\nWhile there is a real-valued solution for \\(r\\) in \\(\\left[b(\\sqrt{2}-1), b(\\sqrt{2}-1)+1 \\right]\\), there is no integer-valued solution. Only some values of \\(b\\) give valid values of \\(r\\). Let\u0026rsquo;s check them programatically to speed up our search. I\u0026rsquo;ve written a small Python script to do so:\nimport math c = math.sqrt(2) + 1 for b in range(1, 10000): r = int(math.ceil(b * c)) prob = r / (r + b) * (r - 1) / (r + b - 1) eps = 1e-10 if 0.5 - eps \u0026lt; prob \u0026lt; 0.5 + eps: print(f\u0026#39;r: {r}, b: {b} -\u0026gt; {prob}\u0026#39;) This script prints values of \\(r\\) and \\(b\\) when the probability is equal to 0.5 (allowing for some numerical imprecision). This will give us suitable candidates that we can check by hand. Running the script gives the following output:\nr: 3, b: 1 -\u0026gt; 0.5\rr: 15, b: 6 -\u0026gt; 0.5\rr: 85, b: 35 -\u0026gt; 0.5\rr: 493, b: 204 -\u0026gt; 0.5\rr: 2871, b: 1189 -\u0026gt; 0.5000000000000001\rr: 16731, b: 6930 -\u0026gt; 0.5 Our first solution shows up. The second solution is \\(r = 15, b = 6\\), which is the first with an even number of black socks. We can easily verify it by hand. This answers question (b): the minimum number of socks with an even number of black socks is \\(15 + 6 = 21\\). The four remaining solutions are also valid and there are more possibilities if we check greater values of \\(b\\).\nMinor optimization We can improve our solution-finding code. Instead of computing the probability, which involves division and hence some numerical errors, we can individually compute the numerator and denominator of the probability term. We can then check if the denominator is equal to two times the numerator. In fact, we can even avoid multiplication by two if we use a bit shift.\nHere\u0026rsquo;s the code.\nimport math c = math.sqrt(2) + 1 for b in range(1, 1000000): r = int(math.ceil(b * c)) p_numerator = r * (r - 1) p_denominator = (r + b) * (r + b - 1) if p_denominator == p_numerator \u0026lt;\u0026lt; 1: print(f\u0026#39;r: {r}, b: {b} -\u0026gt; 0.5\u0026#39;) I\u0026rsquo;ve even increased the number of iterations, since now we avoid false positives entirely. The code outputs these solutions:\nr: 3, b: 1 -\u0026gt; 0.5\rr: 15, b: 6 -\u0026gt; 0.5\rr: 85, b: 35 -\u0026gt; 0.5\rr: 493, b: 204 -\u0026gt; 0.5\rr: 2871, b: 1189 -\u0026gt; 0.5\rr: 16731, b: 6930 -\u0026gt; 0.5\rr: 97513, b: 40391 -\u0026gt; 0.5\rr: 568345, b: 235416 -\u0026gt; 0.5\rr: 3312555, b: 1372105 -\u0026gt; 0.5\rr: 19306983, b: 7997214 -\u0026gt; 0.5 Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More FCPP solutions coming soon :)\n","permalink":"http://localhost:1313/posts/fcpp_1_the_sock_drawer/","summary":"\u003cp\u003eThis is the first post in a series solving problems from \u003ca href=\"https://www.amazon.com/Challenging-Problems-Probability-Solutions-Mathematics/dp/0486653552\"\u003e\u003cem\u003eFifty Challenging Problems in Probability\u003c/em\u003e by Frederick Mosteller (1987)\u003c/a\u003e.\nThe problem is paraphrased below; for reference, it is inspired by the original book.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eA drawer contains some red and black socks. Two socks are drawn at random, and the probability that both are red is  \\(1/2\\).\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eWhat is the minimum total number of socks?\u003c/li\u003e\n\u003cli\u003eWhat is the minimum if the number of black socks is even?\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"FCPP 1: The Sock Drawer"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 2462: Total Cost to Hire K Workers. The instructions are as follows:\nYou are given a 0-indexed integer array costs where costs[i] is the cost of hiring the \\(i\\)-th worker. You are also given two integers \\(k\\) and candidates. We want to hire exactly \\(k\\) workers according to the following rules:\nYou will run \\(k\\) sessions and hire exactly one worker in each session. In each hiring session, choose the worker with the lowest cost from either the first candidates workers or the last candidates workers. Break the tie by the smallest index. For example, if costs = [3,2,7,7,1,2] and candidates = 2, then in the first hiring session, we will choose the 4th worker because they have the lowest cost [3,2,7,7,**1**,2]. In the second hiring session, we will choose 1st worker because they have the same lowest cost as 4th worker but they have the smallest index [3,**2**,7,7,2]. Please note that the indexing may be changed in the process. If there are fewer than candidates workers remaining, choose the worker with the lowest cost among them. Break the tie by the smallest index. A worker can only be chosen once. Return the total cost to hire exactly \\(k\\) workers.\nConstraints:\n1 \u0026lt;= costs.length \u0026lt;= 10^5 1 \u0026lt;= costs[i] \u0026lt;= 10^5 1 \u0026lt;= k, candidates \u0026lt;= costs.length Let\u0026rsquo;s dive in!\nStrategy Let \\(c\\) denote candidates for brevity.\nA naive strategy is to find the minimum from the first and last \\(c\\) options during each round. Each such round requires \\(2c\\) checking operations, which would give a time complexity of \\(O(kc)\\) across \\(k\\) rounds.\nWe can do better. Let\u0026rsquo;s maintain two priority queues: front and back. front will hold the first \\(c\\) unprocessed workers and back will hold the last \\(c\\) unprocessed workers. Each queue will grant access to its cheapest worker in \\(O(1)\\) time.\nDuring each round, we decide whether to choose the worker from front or back according to their cost. If we choose a worker from front, we add the next unprocessed worker from the left to front. If we choose a worker from back, we add the next unprocessed worker from the right to back. Each time we choose a worker, we increase the running cost to hire our workers.\nThere are two edge cases:\nIf there are at most \\(k\\) workers, then all workers will be accepted. If there are at most \\(2c\\) workers (i.e., \\(n \\leq 2c\\)), then we don\u0026rsquo;t need to maintain two priority queues. We can simply sort the workers by their cost in non-decreasing order and select the first \\(k\\). Implementation Let\u0026rsquo;s look at the code below. We maintain two indices: left and right. left tells us which worker we should add next to front. right tells us which worker we should add next to back. We also consider a technical edge case: if front is empty, we choose from back and vice-versa.\nclass Solution { public: long long totalCost(vector\u0026lt;int\u0026gt;\u0026amp; costs, int k, int candidates) { long long total = 0; size_t n = costs.size(); // Edge case 1 if (n \u0026lt;= k) { for (size_t i = 0; i \u0026lt; k; ++i) { total += costs[i]; } return total; } // Edge case 2 if (n \u0026lt;= 2 * candidates) { sort(costs.begin(), costs.end()); for (size_t i = 0; i \u0026lt; k; ++i) { total += costs[i]; } return total; } priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; front; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; back; for (size_t i = 0; i \u0026lt; candidates; ++i) { front.push(costs[i]); back.push(costs[n - 1 - i]); } size_t left = candidates - 1; size_t right = n - candidates; for (size_t i = 0; i \u0026lt; k; ++i) { if (front.empty() || back.top() \u0026lt; front.top()) { // Hire worker from the back total += back.top(); back.pop(); --right; if (left \u0026lt; right) { // Add new worker to the back back.push(costs[right]); } } else { // Hire worker from the front total += front.top(); front.pop(); ++left; if (left \u0026lt; right) { // Add new worker to the front front.push(costs[left]); } } } return total; } }; We break down the time complexity as follows:\nEdge case 1 requires \\(O(k)\\) time to sum the costs of all workers. This is equal to \\(O(n)\\) since this case only occurs when \\(k \\geq n\\). Edge case 2 requires \\(O(n \\log n)\\) time to sort the workers. Summing the first \\(k\\) costs takes \\(O(k)\\) time, but this is subsumed by the sorting time. The general case: We first make \\(c\\) insertions to each priority queue, with each insertion requiring \\(O(\\log c)\\) time. The time complexity for queue construction is thus \\(O(c \\log c)\\). We then make \\(k\\) iterations. In each iteration, we perform exactly one removal in \\(O(\\log c)\\) time and at most one insertion in \\(O(\\log c)\\) time. Overall, we need \\(O(k \\log c)\\) time for queue processing. The worst-case time complexity over all inputs is \\(O(n\\log n\\). However, time complexity becomes \\(O(c\\log c + k \\log c)\\) for inputs that are not edge cases.\nSince each priority queue holds at most \\(c\\) elements, the auxiliary space complexity is \\(O(c)\\).\nLeetCode indeed reports a runtime of 15 ms (beating 99.48% of other solutions) and a memory use of 74.50 MB (beating 100% of other solutions).\nMinor optimization Instead of constructing the heaps via incremental insertions into a priority_queue (which costs \\(O(c\\log c)\\) time), we can build them in linear time using make_heap (see the documentation). We construct front and back as vector objects and not priority queues. We then push the unsorted worker costs into each one in \\(O(c)\\) time. Finally, we call make_heap, which only requires \\(O(c)\\) time. We also have to modify the push and pop calls, though the high-level logic stays the same.\nLet\u0026rsquo;s look at the modified code for the general case. The actual runtime and space usage are pretty much the exact same, though this method is theoretically slightly faster, requiring \\(O(c)\\) time to construct each heap instead of the previous \\(O(c \\log c)\\).\nvector\u0026lt;int\u0026gt; front, back; front.reserve(candidates); back.reserve(candidates); for (int i = 0; i \u0026lt; candidates; ++i) { front.push_back(costs[i]); back.push_back(costs[n - 1 - i]); } // Build min-heaps make_heap(front.begin(), front.end(), greater\u0026lt;int\u0026gt;()); make_heap(back.begin(), back.end(), greater\u0026lt;int\u0026gt;()); size_t left = candidates - 1; size_t right = n - candidates; for (int i = 0; i \u0026lt; k; ++i) { if (front.empty() || (!back.empty() \u0026amp;\u0026amp; back.front() \u0026lt; front.front())) { // Take from back total += back.front(); pop_heap(back.begin(), back.end(), greater\u0026lt;int\u0026gt;()); back.pop_back(); --right; if (left \u0026lt; right) { back.push_back(costs[right]); push_heap(back.begin(), back.end(), greater\u0026lt;int\u0026gt;()); } } else { // Take from front total += front.front(); pop_heap(front.begin(), front.end(), greater\u0026lt;int\u0026gt;()); front.pop_back(); ++left; if (left \u0026lt; right) { front.push_back(costs[left]); push_heap(front.begin(), front.end(), greater\u0026lt;int\u0026gt;()); } } } Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\nSide note: with this blog post, I\u0026rsquo;ve finished the LeetCode 75 problem list! ðŸ¥³ðŸŽ‰ðŸŽ‰ðŸŽ‰\n","permalink":"http://localhost:1313/posts/leetcode_2462/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/total-cost-to-hire-k-workers/\"\u003eLeetCode problem 2462: Total Cost to Hire K Workers\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou are given a 0-indexed integer array \u003ccode\u003ecosts\u003c/code\u003e where \u003ccode\u003ecosts[i]\u003c/code\u003e is the cost of hiring the \\(i\\)-th worker.\nYou are also given two integers \\(k\\) and \u003ccode\u003ecandidates\u003c/code\u003e. We want to hire exactly \\(k\\) workers according to the following rules:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYou will run \\(k\\) sessions and hire exactly one worker in each session.\u003c/li\u003e\n\u003cli\u003eIn each hiring session, choose the worker with the lowest cost from either the first candidates workers or the last candidates workers. Break the tie by the smallest index.\n\u003cul\u003e\n\u003cli\u003eFor example, if \u003ccode\u003ecosts = [3,2,7,7,1,2]\u003c/code\u003e and \u003ccode\u003ecandidates = 2\u003c/code\u003e, then in the first hiring session, we will choose the 4th worker because they have the lowest cost \u003ccode\u003e[3,2,7,7,**1**,2]\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eIn the second hiring session, we will choose 1st worker because they have the same lowest cost as 4th worker but they have the smallest index \u003ccode\u003e[3,**2**,7,7,2]\u003c/code\u003e. Please note that the indexing may be changed in the process.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eIf there are fewer than candidates workers remaining, choose the worker with the lowest cost among them. Break the tie by the smallest index.\u003c/li\u003e\n\u003cli\u003eA worker can only be chosen once.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eReturn the total cost to hire exactly \\(k\\) workers.\u003c/p\u003e","title":"LeetCode 2462: Total Cost to Hire K Workers"},{"content":"Let\u0026rsquo;s solve LeetCode problem 88: Merge Sorted Array. This problem is quite short and straightforward.\nThe instructions are as follows:\nYou are given two integer arrays nums1 and nums2, sorted in non-decreasing order, and two integers \\(m\\) and \\(n\\), representing the number of elements in nums1 and nums2 respectively. Merge nums1 and nums2 into a single array sorted in non-decreasing order. The final sorted array should not be returned by the function, but instead be stored inside the array nums1. To accommodate this, nums1 has a length of \\(m\\) + \\(n\\), where the first \\(m\\) elements denote the elements that should be merged, and the last \\(n\\) elements are set to 0 and should be ignored. nums2 has a length of \\(n\\).\nConstraints:\nnums1.length == m + n nums2.length == n 0 \u0026lt;= m, n \u0026lt;= 200 1 \u0026lt;= m + n \u0026lt;= 200 -10^9 \u0026lt;= nums1[i], nums2[j] \u0026lt;= 10^9 Let\u0026rsquo;s dive in!\nStrategy and implementation We have to write the result to nums1. If we process the numbers from highest to lowest, we can avoid overwriting the first \\(m\\) values of nums1. Let\u0026rsquo;s create two indices i, j and initialize them to i = m - 1, j = n - 1. We will decrement these indices until they both reach 0. At each step, we do the following:\nIf nums1[i] \u0026gt; nums2[j], then we write nums1[i] to the next slot and decrement i. Otherwise, we write nums2[j] to the next slot and decrement j. The index of the next slot is simply i + j + 1.\nWhen i reaches 0, we write all the remaining values in nums2 to the start of nums1. When j reaches 0, we could write all the remaining values in nums1 to the start of nums1. However, this is already the case! Thus, we don\u0026rsquo;t need to do anything at all.\nLet\u0026rsquo;s look at the code below. I usually use size_t as the index data type, however I opted for int as decrementing past 0 causes an overflow and breaks the program.\nclass Solution { public: void merge(vector\u0026lt;int\u0026gt;\u0026amp; nums1, int m, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int n) { int i = m - 1; int j = n - 1; while (i \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026gt;= 0) { if (nums1[i] \u0026gt;= nums2[j]) { nums1[i + j + 1] = nums1[i]; i--; } else { nums1[i + j + 1] = nums2[j]; j--; } } while (j \u0026gt;= 0) { nums1[j] = nums2[j]; j--; } } }; LeetCode reports a runtime of 0 ms (beating 100% of other solutions) and memory usage of 12.17 MB (beating 95.41% of other solutions). I\u0026rsquo;m pretty sure this is effectively optimal and the memory usage is the lowest it could be.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_88/","summary":"\u003cp\u003eLet\u0026rsquo;s solve \u003ca href=\"https://leetcode.com/problems/merge-sorted-array/\"\u003eLeetCode problem 88: Merge Sorted Array\u003c/a\u003e.\nThis problem is quite short and straightforward.\u003c/p\u003e\n\u003cp\u003eThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou are given two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e, sorted in non-decreasing order, and two integers \\(m\\) and \\(n\\), representing the number of elements in \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e respectively.\nMerge \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e into a single array sorted in non-decreasing order.\nThe final sorted array should not be returned by the function, but instead be stored inside the array \u003ccode\u003enums1\u003c/code\u003e. To accommodate this, \u003ccode\u003enums1\u003c/code\u003e has a length of \\(m\\) + \\(n\\), where the first \\(m\\) elements denote the elements that should be merged, and the last \\(n\\) elements are set to 0 and should be ignored. \u003ccode\u003enums2\u003c/code\u003e has a length of \\(n\\).\u003c/p\u003e","title":"LeetCode 88: Merge Sorted Array"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 216: Combination Sum III. The instructions are as follows:\nFind all valid combinations of \\(k\\) numbers that sum up to \\(n\\) such that the following conditions are true:\nOnly numbers 1 through 9 are used. Each number is used at most once. Return a list of all possible valid combinations. The list must not contain the same combination twice, and the combinations may be returned in any order.\nConstraints:\n2 \u0026lt;= k \u0026lt;= 9 1 \u0026lt;= n \u0026lt;= 60 Let\u0026rsquo;s dive in!\nStrategy and implementation We can approach this problem by trying to fill up an empty vector v to size \\(k\\). Once v has length \\(k\\) and sums to \\(n\\), we add it to the vector of results. If it has length \\(k\\), but does not sum to \\(n\\), then we replace some elements in it.\nA systematic way of doing this is via backtracking. We create a recursive function void solve(size_t total), where total is the current sum of v. The function solve also has access to a global vector v, a global vector of vectors results, a target vector length variable, and a target sum variable.\nDuring each recursive call, we apply one of these three rules:\nIf v has length \\(k\\) and total equals \\(n\\), then we add v to results. If v is shorter than \\(k\\) and total \u0026lt; n, then we add recursively call solve several times. Before each call, we add a new number j to the end of the vector (j has to be bigger than the last element of v, but at most 9). We then call the function with solve(total + j) to indicate the change in the vector sum. During this call, solutions may be added to results. After the call finishes, we pop the last element of v and apply the procedure for the next value of j. If neither of the two rules above applies, we do nothing. Rule 1 and rule 3 are base cases for recursion. If rule 1 applies, we\u0026rsquo;ve identified v as one possible solution. If rule 3 applies, we did not. Rule 2 is the general case, during which we try to recursively construct solution vectors. In rule 2, backtracking occurs when we pop the last element of v.\nLet\u0026rsquo;s look at the code below. In combinationSum3, we set up two global variables and call solve with an empty vector v that has sum 0. Rule 2 is the most interesting part of solve. We start adding digits from j0 onward. If v is empty, we set j0 to 1, as that\u0026rsquo;s the smallest permissible number. If not, we set j0 to be one bigger than the last element of v. Then we add digits j from j0 to 9 inclusive. We apply the recursive call to solve and backtrack after the call finishes.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; results; vector\u0026lt;int\u0026gt; v; size_t targetLength; size_t targetSum; void solve(size_t total) { // Rule 1 if (v.size() == targetLength \u0026amp;\u0026amp; total == targetSum) { results.push_back(v); return; } // Rule 2 if (v.size() \u0026lt; targetLength \u0026amp;\u0026amp; total \u0026lt; targetSum) { size_t j0; if (v.size() == 0) { j0 = 1; } else { j0 = v.back() + 1; } for (size_t j = j0; j \u0026lt;= 9; j++) { v.push_back(j); solve(total + j); v.pop_back(); } return; } // Rule 3: nothing } vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; combinationSum3(int k, int n) { targetLength = k; targetSum = n; solve(0); return results; } }; We can bound the number of solutions to check with \\(9^k\\). A tighter bound is the number of strictly increasing sequences of length \\(k\\) with elements from \\(\\{1, \\dots, 9\\}\\). There are \\(\\binom{9}{k} = 9! / ((9-k)!k!)\\) such sequences. The maximal number of sequences is 126 and occurs at \\(k = 4\\) or \\(k = 5\\). The total number of candidates explored (including those shorter than \\(k\\)) is bounded by \\(\\sum_{i=0}^k \\binom{9}{i}\\), which is maximized when \\(k = 9\\) and equals 512.\nThe space complexity is \\(O(mk)\\) where \\(m\\) is the number of solutions. We can again say \\(m \\leq 126 \\) per the discussion above. Since \\(k \\leq 9\\), we need to store at most \\(9 \\cdot 126 = 1134 \\) digits, which is tiny.\nThe total runtime is effectively constant. LeetCode indeed reports a runtime of 0 ms (beating 100% of other solutions) and a memory use of 8.68 MB (beating 78.86% of other solutions).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_216/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/combination-sum-iii\"\u003eLeetCode problem 216: Combination Sum III\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eFind all valid combinations of \\(k\\) numbers that sum up to \\(n\\) such that the following conditions are true:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eOnly numbers 1 through 9 are used.\u003c/li\u003e\n\u003cli\u003eEach number is used at most once.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eReturn a list of all possible valid combinations. The list must not contain the same combination twice, and the combinations may be returned in any order.\u003c/p\u003e","title":"LeetCode 216: Combination Sum III"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 790: Domino and Tromino Tiling. The instructions are as follows:\nYou have two types of tiles: a 2 x 1 domino shape and a tromino shape. You may rotate these shapes. Given an integer \\(n\\), return the number of ways to tile an 2 x n board. Since the answer may be very large, return it modulo 10^9 + 7. In a tiling, every square must be covered by a tile. Two tilings are different if and only if there are two 4-directionally adjacent cells on the board such that exactly one of the tilings has both squares occupied by a tile.\nLet\u0026rsquo;s dive in!\nCounting the possible tilings Let\u0026rsquo;s look at all possible tilings for a few values of \\(n\\) in the image below. Unique new tilings We notice that each \\(n\\) has a few unique tilings that don\u0026rsquo;t show up before it:\nFor \\(n = 1\\), the last tiling is a unique new vertical domino. For \\(n = 2\\), the last tiling is a unique new pair of horizontal dominos. For \\(n = 3\\), the final two tilings are new and made up of two trominos. For \\(n = 4\\), the final two tilings are new and made up of two trominos and a domino. I\u0026rsquo;ve marked these in the image below. In fact, each new \\(n\\) introduces new unique tilings. Let\u0026rsquo;s look at these for \\(n \\leq 7\\). Clearly, there are always 2 new unique tilings for each \\(n \\geq 3\\).\nHow are the tilings constructed? Aside from these new and unique tilings, we can also notice a pattern in how the other tilings are constructed. Let\u0026rsquo;s consider \\(n = 4\\). I\u0026rsquo;ve purposely arranged the tilings to clearly see the pattern in the image below. The tilings are constructed as follows:\nTake all tilings for \\(n = 3\\) and append the unique tiling from \\(n = 1\\). Take all tilings for \\(n = 2\\) and append the unique tiling from \\(n = 2\\). Take all tilings for \\(n = 1\\) and append the unique tilings from \\(n = 3\\). We cover the edge case of new tilings by taking all the tilings for \\(n = 0\\) (i.e., nothing) and appending the unique tilings from \\(n = 4\\). The number of tilings for \\(n\\) are thus:\n\\[\rt(n) = t(n - 1) + t(n - 2) + \\sum_{i = 0}^{n - 3} 2 t(i).\r\\]The term \\(t(n - 1)\\) corresponds to tilings from \\(n - 1\\) and adding a vertical domino. The term \\(t(n - 2)\\) corresponds to tilings from \\(n - 2\\) and adding a horizontal domino pair. The remaining terms \\(t(i)\\) corresponds to tilings from \\(i\\) and adding two unique tilings (since we know each \\(n \\geq 3\\) has two new unique tilings), which is why each term is multiplied by \\(2\\).\nThis is the dynamic programming recurrence relation.\nSimplifying the recurrence relation We can simplify the equation above with some clever math. First, let\u0026rsquo;s construct a helper term with \\(t(n - 1)\\):\n\\[\rt(n - 1) = t(n - 2) + t(n - 3) + \\sum_{i = 0}^{n - 4} 2 t(i), \\;\\mathrm{therefore} \\\\\rt(n - 2) + t(n - 3) = t(n - 1) - \\sum_{i = 0}^{n - 4} 2 t(i).\r\\]We will use this term as a replacement inside the square brackets in the derivation below:\n\\[\rt(n) = t(n - 1) + t(n - 2) + \\sum_{i = 0}^{n - 3} 2 t(i) \\\\\r= t(n - 1) + t(n - 2) + 2 t(n - 3) + \\sum_{i = 0}^{n - 4} 2 t(i) \\\\\r= t(n - 1) + [t(n - 2) + t(n - 3)] + t(n - 3) + \\sum_{i = 0}^{n - 4} 2 t(i) \\\\\r= t(n - 1) + [t(n - 1) - \\sum_{i = 0}^{n - 4} 2 t(i)] + t(n - 3) + \\sum_{i = 0}^{n - 4} 2 t(i) \\\\\r= 2t(n - 1) + t(n - 3) \\\\\r\\]Full implementation The solution becomes trivial to implement using the simplified formula. We use a, b, c to hold \\(t(i - 3), t(i - 2),\\) and \\(t(i - 1)\\) respectively. We store \\(t(i)\\) inside variable d at each step. We iterate from \\(i = 4\\) to \\(i = n\\). After the loop, the final value \\(t(n)\\) is stored inside d (and c, because of the variable swap). We apply modulo according to the instructions to avoid overflows.\nclass Solution { public: int numTilings(int n) { if (n == 1) { return 1; } else if (n == 2) { return 2; } else if (n == 3) { return 5; } size_t a = 1; size_t b = 2; size_t c = 5; size_t d; for (size_t i = 4; i \u0026lt;= n; ++i) { d = (2 * c + a) % 1000000007; a = b; b = c; c = d; } return d; } }; This solution requires \\(O(n)\\) time and \\(O(1)\\) space. LeetCode reports a runtime of 0 ms (beating 100% of other solutions) and a memory use of 7.78 MB (beating 95.07% of other solutions). Super efficient!\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_790/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/domino-and-tromino-tiling\"\u003eLeetCode problem 790: Domino and Tromino Tiling\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou have two types of tiles: a \u003ccode\u003e2 x 1\u003c/code\u003e domino shape and a tromino shape. You may rotate these shapes.\nGiven an integer \\(n\\), return the number of ways to tile an \u003ccode\u003e2 x n\u003c/code\u003e board. Since the answer may be very large, return it modulo \u003ccode\u003e10^9 + 7\u003c/code\u003e.\nIn a tiling, every square must be covered by a tile. Two tilings are different if and only if there are two 4-directionally adjacent cells on the board such that exactly one of the tilings has both squares occupied by a tile.\u003c/p\u003e","title":"LeetCode 790: Domino and Tromino Tiling"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 875: Koko Eating Bananas. The instructions are as follows:\nKoko loves to eat bananas. There are n piles of bananas, the \\(i\\)-th pile has piles[i] bananas. The guards have gone and will come back in h hours. Koko can decide her bananas-per-hour eating speed of k. Each hour, she chooses some pile of bananas and eats k bananas from that pile. If the pile has less than k bananas, she eats all of them instead and will not eat any more bananas during this hour. Koko likes to eat slowly but still wants to finish eating all the bananas before the guards return. Return the minimum integer k such that she can eat all the bananas within h hours.\nConstraints:\n1 \u0026lt;= piles.length \u0026lt;= 10^4 piles.length \u0026lt;= h \u0026lt;= 10^9 1 \u0026lt;= piles[i] \u0026lt;= 10^9 Let\u0026rsquo;s dive in!\nChecking if a given rate is valid To check if a rate k is valid, we have to first compute the total time spent eating bananas across all piles with rate k and then ensure that this time is at most h. Let\u0026rsquo;s write this as helper function:\nint ceilDivision(int a, int b) { // return ceil(a / b) where a and b are integers return (a + b - 1) / b; } bool validRate(vector\u0026lt;int\u0026gt; *piles, int h, int k) { int total = 0; for (int i = 0; i \u0026lt; piles-\u0026gt;size(); ++i) { total += ceilDivision(piles-\u0026gt;at(i), k); } return total \u0026lt;= h; } If ceilDivision appears too complicated, think about this: the time spent eating pile \\(i\\) is equal to piles[i] / k if k evenly divides piles[i]. If it doesn\u0026rsquo;t, then there are still some bananas leftover and Koko has to spend an hour eating them. We can use the one-liner below.\ntotal += piles-\u0026gt;at(i) / k + (piles-\u0026gt;at(i) % k \u0026gt; 0); This is equivalent to our ceilDivision(piles-\u0026gt;at(i), k) function. More on the function in this StackOverflow discussion.\nBinary search strategy We\u0026rsquo;re trying to find the minimum integer rate k such that Koko can still eat all of the bananas in time h. The maximum possible rate is \\(m\\); the number of bananas on the biggest pile. Since h is at least the number of piles, using rate \\(m\\) means spending one hour for each pile. The minimum possible rate is \\(1\\).\nWe can simply apply binary search on the set \\(\\{1, 2, \\dots, m - 1, m\\}\\). For a candidate rate in the middle between the minimum and maximum rate, we check if it\u0026rsquo;s valid with the validRate function. If the rate is valid, we shift the maximum rate to the candidate rate (since the rate can\u0026rsquo;t be bigger). If it\u0026rsquo;s invalid, we shift the minimum rate to the candidate rate and add \\(1\\) (that\u0026rsquo;s the first rate that could possibly be valid).\nThe implementation is straightforward. Below is the full code.\nclass Solution { public: int ceilDivision(int a, int b) { // return ceil(a / b) where a and b are integers return (a + b - 1) / b; } bool validRate(vector\u0026lt;int\u0026gt; *piles, int h, int k) { int total = 0; for (int i = 0; i \u0026lt; piles-\u0026gt;size(); ++i) { total += ceilDivision(piles-\u0026gt;at(i), k); } return total \u0026lt;= h; } int minEatingSpeed(vector\u0026lt;int\u0026gt;\u0026amp; piles, int h) { int minRate = 1; int maxRate = *max_element(piles.begin(), piles.end()); while (minRate \u0026lt; maxRate) { int midRate = (minRate + maxRate) / 2; if (validRate(\u0026amp;piles, h, midRate)) { maxRate = midRate; } else { minRate = midRate + 1; } } return minRate; } }; This solution requires \\(O(n \\log m)\\) time and \\(O(1)\\) extra space. The time complexity derives from using \\(O(\\log m)\\) binary search steps, each requiring us to check \\(n\\) piles. LeetCode reports a runtime of 11 ms and a memory use of 22.83 MB (beating 76.17% of other solutions).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_875/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/koko-eating-bananas\"\u003eLeetCode problem 875: Koko Eating Bananas\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eKoko loves to eat bananas. There are \u003ccode\u003en\u003c/code\u003e piles of bananas, the \\(i\\)-th pile has \u003ccode\u003epiles[i]\u003c/code\u003e bananas.\nThe guards have gone and will come back in \u003ccode\u003eh\u003c/code\u003e hours.\nKoko can decide her bananas-per-hour eating speed of \u003ccode\u003ek\u003c/code\u003e.\nEach hour, she chooses some pile of bananas and eats \u003ccode\u003ek\u003c/code\u003e bananas from that pile.\nIf the pile has less than \u003ccode\u003ek\u003c/code\u003e bananas, she eats all of them instead and will not eat any more bananas during this hour.\nKoko likes to eat slowly but still wants to finish eating all the bananas before the guards return.\nReturn the minimum integer \u003ccode\u003ek\u003c/code\u003e such that she can eat all the bananas within \u003ccode\u003eh\u003c/code\u003e hours.\u003c/p\u003e","title":"LeetCode 875: Koko Eating Bananas"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 72: Edit distance. The instructions are as follows:\nGiven two strings word1 and word2, return the minimum number of operations required to convert word1 to word2. You have the following three operations permitted on a word:\nInsert a character Delete a character Replace a character Let\u0026rsquo;s dive in!\nThe Wagner-Fischer algorithm There are several types of edit distance. This LeetCode problem defines it as the Levenshtein distance. The most common algorithm to compute it is the Wagner-Fischer algorithm.\nSuppose word1 has length \\(m\\) and word2 has length \\(n\\). The Wagner-Fischer computes a matrix \\(D\\) of size \\((m+1) \\times (n+1)\\) that holds the edit distances between all prefixes of word1 and all prefixes of word2. Computing each edit distance reuses the adjacent edit distances in the matrix, making this a dynamic programming algorithm.\nSuppose word1[:i] is the length-\\(i\\) prefix of word1 and word2[:j] is the length-\\(j\\) prefix of word2. Then \\(D_{i,j}\\) holds the edit distance between word1[:i] and word2[:j].\nWe initialize the first row with values from 0 to \\(n\\) and the first column with values from 0 to \\(m\\). That\u0026rsquo;s because converting an empty string to word2[:j] requires \\(j\\) insertions. Similarly, converting word1[:i] to an empty string requires \\(i\\) deletions.\nHere\u0026rsquo;s the key rule to compute the edit distance:\n\\[\rD_{i,j} = \\min (D_{i-1, j} + 1, D_{i, j - 1} + 1, D_{i-1, j-1} + s),\r\\] where \\(s = 0\\) if word1[i - 1] == word2[j - 1] and \\(s = 1\\) otherwise.\nThe three terms in the minimum respectively correspond to deletion, insertion, and substitution. If we are in cell \\(D_{i,j}\\), then:\n\\(D_{i-1, j} + 1\\) corresponds to deleting word1[i - 1] from word1, \\(D_{i, j - 1} + 1\\) corresponds to inserting word2[j - 1] into word1 to match the longer prefix of word2, \\(D_{i - 1, j - 1} + s\\) corresponds to substituting word1[i - 1] with word2[j - 1] (or doing nothing if they are equal). After filling the matrix in this way, the final edit distance is \\(D_{m,n}\\).\nHere\u0026rsquo;s an example for word1 = \u0026quot;kitten\u0026quot; and word2 = \u0026quot;sitting\u0026quot;. The true edit distance is three: substitute \u0026quot;k\u0026quot; with \u0026quot;s\u0026quot;, substitute \u0026quot;e\u0026quot; with \u0026quot;i\u0026quot;, add \u0026quot;g\u0026quot; to the end.\nk i t t e n 0 1 2 3 4 5 6 s 1 1 1 2 3 4 5 i 2 2 1 2 3 4 5 t 3 3 2 1 2 3 4 t 4 4 3 2 1 2 3 i 5 5 4 3 2 2 3 n 6 6 5 4 3 3 2 g 7 7 6 5 4 4 3 The bottom right value in the matrix is indeed the true distance: 3.\nThe full code is shown below. Before running the Wagner-Fischer algorithm, we check if the two words are equal, which only takes \\(O(\\max(m, n))\\) time. The full algorithm takes \\(O(mn)\\) time and space.\nclass Solution { public: int minDistance(string word1, string word2) { if (word1 == word2) { return 0; } // Wagner-Fischer algorithm size_t m = word1.size(); size_t n = word2.size(); vector\u0026lt;vector\u0026lt;size_t\u0026gt;\u0026gt; d(m + 1, vector\u0026lt;size_t\u0026gt;(n + 1, 0)); for (size_t i = 1; i \u0026lt;= m; ++i) { d[i][0] = i; } for (size_t j = 1; j \u0026lt;= n; ++j) { d[0][j] = j; } for (size_t j = 1; j \u0026lt;= n; ++j) { for (size_t i = 1; i \u0026lt;= m; ++i) { bool substituted = (word1[i - 1] != word2[j - 1]); d[i][j] = min( d[i - 1][j] + 1, // deletion min( d[i][j - 1] + 1, // insertion d[i - 1][j - 1] + substituted // substitution ) ); } } return d[m][n]; } }; Running the code takes 4 ms (beating 81.58% of other solutions) and needs 15 MB of memory (beating 12.96% of other solutions).\nOptimized version with reduced space complexity The Wagner-Fischer algorithm can be optimized to use less space. The code above has to fill the matrix column-by-column. However, filling each cell only needs the values of the cells to the left, above, and to the top-left. This means we only need to keep:\nthe current column (namely the values above the current cell), and the column to the left of the current one. Now the space complexity will only be \\(O(m)\\), substantially less than \\(O(nm)\\). The time complexity remains the same.\nIt\u0026rsquo;s equivalent to keep two rows instead of two columns, as it\u0026rsquo;s essentially working with a transposed matrix \\(D\\). We\u0026rsquo;ll use the rows strategy so we can easily keep track of rows with the swap function. We\u0026rsquo;ll have a top row and a bottom row. Each row will have \\(n + 1\\) elements. After processing all characters in both words, we will implicitly have filled up all rows in the matrix. The result is stored in the last element of the bottom row.\nLet\u0026rsquo;s look at the code below. There\u0026rsquo;s a small optimization: if word1 with length \\(m\\) is shorter than word2 with length \\(n\\), we swap them. This brings down the space complexity to \\(O(\\min (m, n))\\) because \\(m \u003c n\\) and we now only have \\(m+1\\) elements in each row.\nclass Solution { public: int minDistance(string word1, string word2) { if (word1 == word2) { return 0; } if (word1.size() \u0026lt; word2.size()) { swap(word1, word2); } // Wagner-Fischer algorithm size_t m = word1.size(); size_t n = word2.size(); // Only store two rows vector\u0026lt;size_t\u0026gt; top(n + 1, 0); vector\u0026lt;size_t\u0026gt; bottom(n + 1, 0); for (size_t j = 1; j \u0026lt;= n; ++j) { top[j] = j; } for (size_t i = 1; i \u0026lt;= m; ++i) { bottom[0] = i; for (size_t j = 1; j \u0026lt;= n; ++j) { bool substituted = (word1[i - 1] != word2[j - 1]); bottom[j] = min( min( top[j] + 1, // deletion bottom[j - 1] + 1 // insertion ), top[j - 1] + substituted // substitution ); } swap(top, bottom); } return top[n]; // because of the swap } }; Running the code now takes 0 ms (beating 100% of other solutions) and needs 10.4 MB of memory (beating 98.46% of other solutions). The used space in the optimized version is about 2/3 of the space in the basic version of the algorithm.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_72/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/edit-distance\"\u003eLeetCode problem 72: Edit distance\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eGiven two strings \u003ccode\u003eword1\u003c/code\u003e and \u003ccode\u003eword2\u003c/code\u003e, return the minimum number of operations required to convert \u003ccode\u003eword1\u003c/code\u003e to \u003ccode\u003eword2\u003c/code\u003e. You have the following three operations permitted on a word:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eInsert a character\u003c/li\u003e\n\u003cli\u003eDelete a character\u003c/li\u003e\n\u003cli\u003eReplace a character\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLet\u0026rsquo;s dive in!\u003c/p\u003e\n\u003ch2 id=\"the-wagner-fischer-algorithm\"\u003eThe Wagner-Fischer algorithm\u003c/h2\u003e\n\u003cp\u003eThere are several types of \u003ca href=\"https://en.wikipedia.org/wiki/Edit_distance\"\u003eedit distance\u003c/a\u003e.\nThis LeetCode problem defines it as the \u003ca href=\"https://en.wikipedia.org/wiki/Levenshtein_distance\"\u003eLevenshtein distance\u003c/a\u003e.\nThe most common algorithm to compute it is the \u003ca href=\"https://en.wikipedia.org/wiki/Wagner%E2%80%93Fischer_algorithm\"\u003eWagner-Fischer algorithm\u003c/a\u003e.\u003c/p\u003e","title":"LeetCode 72: Edit distance"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 746: Min Cost Climbing Stairs. The instructions are as follows:\nYou are given an integer array cost where cost[i] is the cost of \\(i\\)-th step on a staircase. Once you pay the cost, you can either climb one or two steps. You can either start from the step with index 0, or the step with index 1. Return the minimum cost to reach the top of the floor.\nLet\u0026rsquo;s dive in!\nStrategy and solution Let\u0026rsquo;s think about the minimum cost required to reach stair \\(i\\). We could have arrived there from:\nstair \\(i-2\\), costing cost[i - 2] plus the minimum cost to arrive at stair \\(i - 2\\), or stair \\(i-1\\), costing cost[i - 1] plus the minimum cost to arrive at stair \\(i - 1\\). The cheapest path means taking the stair with the lower cost. If \\(m_i\\) is the minimum cost to arrive at stair \\(i\\) and \\(c_i\\) is cost[i], we can write the recurrence as:\n\\[\rm_i = \\min(c_{i - 2} + m_{i - 2}, c_{i - 1} + m_{i - 1}).\r\\]Since we can start at either stair 0 or stair 1, arriving there costs nothing. Therefore \\(m_0 = m_1 = 0\\). We could program this recursively and memoize the results to avoid recomputation. However, it\u0026rsquo;s much easier to simply use an iterative approach.\nLet\u0026rsquo;s look at the code below. We use minCost1 to hold \\(m_{i-2}\\) and minCost2 to hold \\(m_{i-1}\\). We store \\(m_i\\) inside minCost3. After each iteration, we set minCost1 to minCost2 and minCost2 to minCost3. The final result is in minCost2. This is similar to iteratively computing a number from the Fibonacci sequence.\nclass Solution { public: int minCostClimbingStairs(vector\u0026lt;int\u0026gt;\u0026amp; cost) { size_t minCost1 = 0; // cost to reach first stair size_t minCost2 = 0; // cost to reach second stair size_t minCost3; for (size_t i = 2; i \u0026lt;= cost.size(); ++i) { minCost3 = min( minCost1 + cost[i - 2], minCost2 + cost[i - 1] ); minCost1 = minCost2; minCost2 = minCost3; } return minCost2; } }; Given \\(n\\) stairs, the code requires \\(O(n)\\) time and \\(O(1)\\) space, which looks to be optimal. LeetCode reports a runtime of 0 ms (beating 100% of other solutions) and memory use of 17.56 MB, which is effectively just from the input data. Our actual code only uses a few integers. A very efficient solution!\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_746/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/min-cost-climbing-stairs\"\u003eLeetCode problem 746: Min Cost Climbing Stairs\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou are given an integer array \u003ccode\u003ecost\u003c/code\u003e where \u003ccode\u003ecost[i]\u003c/code\u003e is the cost of \\(i\\)-th step on a staircase. Once you pay the cost, you can either climb one or two steps.\nYou can either start from the step with index 0, or the step with index 1.\nReturn the minimum cost to reach the top of the floor.\u003c/p\u003e","title":"LeetCode 746: Min Cost Climbing Stairs"},{"content":"Today, let\u0026rsquo;s look at LeetCode problem 435: Non-overlapping intervals. The instructions are as follows:\nGiven an array of intervals intervals where intervals[i] = [start_i, end_i], return the minimum number of intervals you need to remove to make the rest of the intervals non-overlapping. Note that intervals which only touch at a point are non-overlapping. For example, [1, 2] and [2, 3] are non-overlapping.\nLet\u0026rsquo;s dive in!\nInterval scheduling reformulation Interval scheduling is a class of problems that involve a set of tasks, represented by their start and end times. The interval scheduling maximization problem (ISMP) is about finding the largest set of non-overlapping tasks. This is highly related to our interval removal problem. In fact, the following statements are equivalent:\nn is the total number of tasks and k is the maximum number of non-overlapping tasks that can be executed; the minimum number of intervals to make the rest non-overlapping is n - k. Let\u0026rsquo;s solve a variant of the well-known ISMP and use the result to answer the removal question. This is the single-interval scheduling problem (SISP), where we create an interval schedule in which no intervals overlap. A greedy algorithm called Earliest deadline first (EDF) finds the optimal solution to SISP. It\u0026rsquo;s described as follows:\nSelect the interval x with the earliest finishing time. Remove x and all intervals intersecting it from the set of candidate intervals. Repeat until there are no more candidate intervals. EDF starts by sorting the intervals by their end time in non-decreasing order. It then processes intervals from first to last.\nThis problem is also related to a similar interview question: maximum number of meetings in one room.\nSolving the counting problem Since we only need to count the number of compatible intervals, we don\u0026rsquo;t need to actually perform any removals. Instead, we start by sorting the intervals according to their end times. We initialize a counter k = 1 that counts the number of non-overlapping intervals. The first non-overlapping interval is simply the first one in the sorted list, i.e., the interval at index 0. We store its index in a variable prev = 0. Then loop over the rest of the intervals, starting at index i = 1. At each index, we check if interval at index i overlaps with the previously executed one. If so, we increment k and set prev = i. Otherwise, we simply move forward, as the interval at index i was caught in an overlap. We finally return n - k.\nLet\u0026rsquo;s look at the full code below.\nclass Solution { public: int eraseOverlapIntervals(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; intervals) { // Sort by end times sort( intervals.begin(), intervals.end(), [](const vector\u0026lt;int\u0026gt;\u0026amp; left, const vector\u0026lt;int\u0026gt;\u0026amp; right) { return left[1] \u0026lt; right[1]; } ); // Apply *Earliest deadline first* (EDF) size_t prev = 0; size_t k = 1; for (size_t i = 1; i \u0026lt; intervals.size(); ++i) { if (intervals[i][0] \u0026gt;= intervals[prev][1]) { k++; prev = i; } } // Return the number of intervals to remove return intervals.size() - k; } }; Complexity and empirical performance Our counting variant of EDF takes \\(O(n \\log n)\\) time to sort the intervals and \\(O(n)\\) to count the number of compatible intervals, so the total time complexity is \\(O(n \\log n)\\). Ignoring the input data, the space complexity is \\(O(1)\\) as we only need to use two integers: prev and k. LeetCode reports a runtime of 35 ms, which beats 95.23% of all solutions, as well as memory usage of 93.79 MB, which beats 98.60% of all solutions.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_435/","summary":"\u003cp\u003eToday, let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/non-overlapping-intervals\"\u003eLeetCode problem 435: Non-overlapping intervals\u003c/a\u003e.\nThe instructions are as follows:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eGiven an array of intervals intervals where \u003ccode\u003eintervals[i] = [start_i, end_i]\u003c/code\u003e, return the minimum number of intervals you need to remove to make the rest of the intervals non-overlapping.\nNote that intervals which only touch at a point are non-overlapping. For example, \u003ccode\u003e[1, 2]\u003c/code\u003e and \u003ccode\u003e[2, 3]\u003c/code\u003e are non-overlapping.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLet\u0026rsquo;s dive in!\u003c/p\u003e\n\u003ch2 id=\"interval-scheduling-reformulation\"\u003eInterval scheduling reformulation\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Interval_scheduling\"\u003eInterval scheduling\u003c/a\u003e is a class of problems that involve a set of tasks, represented by their start and end times.\nThe \u003cem\u003einterval scheduling maximization problem\u003c/em\u003e (ISMP) is about finding the largest set of non-overlapping tasks.\nThis is highly related to our interval removal problem.\nIn fact, the following statements are equivalent:\u003c/p\u003e","title":"LeetCode 435: Non-overlapping Intervals"},{"content":"Hi, everyone! Today, we\u0026rsquo;ll be looking at LeetCode problem 399. In this problem, we are given a bunch of reference equations of the form \\(a_i / b_i = c_i\\) for \\(i = 1 , \\dots, n\\). The symbols \\(a_i, b_i\\) are given as strings, while \\(c_i\\) are given as floating point numbers. We\u0026rsquo;re then asked to compute the value of a query equation \\(q_1 / q_2\\).\nIf \\(q_1 / q_2\\) is one of the reference equations, we can return that value. Otherwise, we can follow a kind of chain-rule strategy. Suppose we are given \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot; with value 2.0 and \u0026quot;b\u0026quot; / \u0026quot;c\u0026quot; with value 3.0, then we can compute \u0026quot;a\u0026quot; / \u0026quot;c\u0026quot; by the product: \u0026quot;a\u0026quot; / \u0026quot;c\u0026quot; = \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot; * \u0026quot;b\u0026quot; / \u0026quot;c\u0026quot;, which is equal to 2.0 * 3.0 = 6.0. If there\u0026rsquo;s no way to find a solution, we return -1.\nWe\u0026rsquo;ll approach this as a graph problem and use breadth-first search (BFS). Let\u0026rsquo;s dive in!\nConstructing a graph of symbols We approach this problem by first constructing a graph. Each node represents a symbol as given in the reference equations. If there is an edge going from node \u0026quot;a\u0026quot; to node \u0026quot;b\u0026quot;, its value is the reference value \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot;.\nLet\u0026rsquo;s consider an example where the reference equations are [[\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;], [\u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;]] and the reference values are [2.0, 3.0].\nTo find the value of \u0026quot;a\u0026quot; / \u0026quot;c\u0026quot;, we start in node \u0026quot;a\u0026quot;, then traverse past node \u0026quot;b\u0026quot; and arrive at node \u0026quot;c\u0026quot;. We multiply the values of all edges along the way and obtain 6.0.\nIt\u0026rsquo;s possible that an edge might exist from one variable to the other, but we need to traverse the path in the opposite direction. To handle this, we can add another edge whose value is the reciprocal of the reference equation value. For example, if the given equation is \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot; = 2.0, we add edges \u0026quot;a\u0026quot; -\u0026gt; \u0026quot;b\u0026quot; with value 2.0 and \u0026quot;b\u0026quot; -\u0026gt; \u0026quot;a\u0026quot; with value 1 / 2.0.\nEach symbol can be represented as a struct with incoming and outgoing connections. Each connection is a pair containing the other symbol and the edge value.\nstruct Symbol { vector\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; incoming; vector\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; outgoing; }; Let\u0026rsquo;s look at how to construct the graph. We store symbol objects in an unordered map, accessed by string keys. As we traverse the equations, we add new symbols to the map if they don\u0026rsquo;t yet exist. At every step, we also update the incoming and outgoing edges of each symbol with the appropriate equation value.\nvector\u0026lt;double\u0026gt; calcEquation(vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt;\u0026amp; equations, vector\u0026lt;double\u0026gt;\u0026amp; values, vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt;\u0026amp; queries) { unordered_map\u0026lt;string, Symbol*\u0026gt; symbols; for (size_t i = 0; i \u0026lt; equations.size(); ++i) { vector\u0026lt;string\u0026gt; eq = equations[i]; double value = values[i]; string s1 = eq[0]; string s2 = eq[1]; if (!symbols.contains(s1)) { symbols[s1] = new Symbol; } if (!symbols.contains(s2)) { symbols[s2] = new Symbol; } symbols[s1]-\u0026gt;outgoing.push_back({symbols[s2], value}); symbols[s2]-\u0026gt;incoming.push_back({symbols[s1], 1 / value}); } ... // we\u0026#39;ll implement the rest later } Evaluating an equation with BFS We\u0026rsquo;ll evaluate the equation by traversing the graph. However, cycles in the graph might cause us to loop indefinitely. We can avoid this by keeping track of already visited states in a set. We can avoid going to deep into the graph by using BFS instead of depth-first search (DFS), but a DFS solution is possible as well.\nWhen given a query \\(q_1 / q_2\\), we will construct a queue that contains with \\(q_1\\) and the corresponding initial path product 1.0. While the queue is not empty, we will pop its front element and add all its connected nodes to the back of the queue. If the popped element corresponds to \\(q_2\\), we will return the corresponding path product.\nLet\u0026rsquo;s look at the code. We first initialize the set of visited states and a queue containing the symbols and equation values. We then execute the queue loop as outlined above.\ndouble evaluate(Symbol *src, Symbol *dst) { set\u0026lt;Symbol*\u0026gt; visited; queue\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; q; q.push({src, 1.0}); while (!q.empty()) { pair\u0026lt;Symbol*, double\u0026gt; p = q.front(); q.pop(); // If we have not yet visited this symbol if (visited.find(p.first) == visited.end()) { // Have we arrived at the destination? if (p.first == dst) { return p.second; } // Add connecting symbols into ther queue for (auto pNext: p.first-\u0026gt;outgoing) { q.push({pNext.first, pNext.second * p.second}); } for (auto pNext: p.first-\u0026gt;incoming) { q.push({pNext.first, pNext.second * p.second}); } // Mark this symbol as visited visited.insert(p.first); } } // If no solution was found in the loop, return -1 return -1; } Full solution and complexity Below is the full solution code. The only practical addition is constructing an output vector and processing each query equation one-by-one.\nclass Solution { public: struct Symbol { vector\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; incoming; vector\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; outgoing; }; double evaluate(Symbol *src, Symbol *dst) { set\u0026lt;Symbol*\u0026gt; visited; queue\u0026lt;pair\u0026lt;Symbol*, double\u0026gt;\u0026gt; q; q.push({src, 1.0}); while (!q.empty()) { pair\u0026lt;Symbol*, double\u0026gt; p = q.front(); q.pop(); if (visited.find(p.first) == visited.end()) { if (p.first == dst) { return p.second; } for (auto pNext: p.first-\u0026gt;outgoing) { q.push({pNext.first, pNext.second * p.second}); } for (auto pNext: p.first-\u0026gt;incoming) { q.push({pNext.first, pNext.second * p.second}); } visited.insert(p.first); } } return -1; } vector\u0026lt;double\u0026gt; calcEquation(vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt;\u0026amp; equations, vector\u0026lt;double\u0026gt;\u0026amp; values, vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt;\u0026amp; queries) { unordered_map\u0026lt;string, Symbol*\u0026gt; symbols; for (size_t i = 0; i \u0026lt; equations.size(); ++i) { vector\u0026lt;string\u0026gt; eq = equations[i]; double value = values[i]; string s1 = eq[0]; string s2 = eq[1]; if (!symbols.contains(s1)) { symbols[s1] = new Symbol; } if (!symbols.contains(s2)) { symbols[s2] = new Symbol; } symbols[s1]-\u0026gt;outgoing.push_back({symbols[s2], value}); symbols[s2]-\u0026gt;incoming.push_back({symbols[s1], 1 / value}); } vector\u0026lt;double\u0026gt; out; for (size_t i = 0; i \u0026lt; queries.size(); ++i) { vector\u0026lt;string\u0026gt; eq = queries[i]; string s1 = eq[0]; string s2 = eq[1]; if (!symbols.contains(s1) || !symbols.contains(s2)) { out.push_back(-1.0); } else { out.push_back(evaluate(symbols[s1], symbols[s2])); } } return out; } }; Suppose there are \\(m\\) symbols in the \\(n\\) referenced equations. To evaluate a new query with BFS, we have to traverse at most \\(m\\) symbols. We can check whether a symbol is in symbol set or not in \\(O(1)\\) time, as the unordered set is implemented as a hash table with constant-time lookup. Given \\(k\\) queries, the worst-case time complexity is thus \\(O(km)\\).\nWe also need to store \\(m\\) symbols, at most \\(n\\) outgoing edges, and at most \\(n\\) incoming edges. Within each evaluation call, the constructed queue contains a variable amount of elements, potentially more than \\(m\\) depending on the input graph. However, never more than \\(m^2\\). The practical space complexity is \\(O(m+n)\\) to hold the graph and \\(O(m)\\) for the queue, although it can be dominated by \\(O(m^2)\\) for complicated input graphs. Let\u0026rsquo;s say \\(O(n+m)\\) for practical cases.\nLeetCode reports that this algorithm runs in 0ms, beating 100% of solution in runtime. It takes 11.75 MB memory, beating 80.54% in space utilization. That\u0026rsquo;s quite good!\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_399/","summary":"\u003cp\u003eHi, everyone! Today, we\u0026rsquo;ll be looking at \u003ca href=\"https://leetcode.com/problems/evaluate-division/?envType=study-plan-v2\u0026amp;envId=leetcode-75\"\u003eLeetCode problem 399\u003c/a\u003e.\nIn this problem, we are given a bunch of reference equations of the form \\(a_i / b_i = c_i\\) for \\(i = 1 , \\dots, n\\).\nThe symbols \\(a_i, b_i\\) are given as strings, while \\(c_i\\) are given as floating point numbers.\nWe\u0026rsquo;re then asked to compute the value of a \u003cem\u003equery\u003c/em\u003e equation \\(q_1 / q_2\\).\u003c/p\u003e\n\u003cp\u003eIf \\(q_1 / q_2\\) is one of the reference equations, we can return that value.\nOtherwise, we can follow a kind of \u003cem\u003echain-rule\u003c/em\u003e strategy.\nSuppose we are given \u003ccode\u003e\u0026quot;a\u0026quot; / \u0026quot;b\u0026quot;\u003c/code\u003e with value \u003ccode\u003e2.0\u003c/code\u003e and \u003ccode\u003e\u0026quot;b\u0026quot; / \u0026quot;c\u0026quot;\u003c/code\u003e with value \u003ccode\u003e3.0\u003c/code\u003e, then we can compute \u003ccode\u003e\u0026quot;a\u0026quot; / \u0026quot;c\u0026quot;\u003c/code\u003e by the product:\n\u003ccode\u003e\u0026quot;a\u0026quot; / \u0026quot;c\u0026quot; = \u0026quot;a\u0026quot; / \u0026quot;b\u0026quot; * \u0026quot;b\u0026quot; / \u0026quot;c\u0026quot;\u003c/code\u003e, which is equal to \u003ccode\u003e2.0 * 3.0 = 6.0\u003c/code\u003e.\nIf there\u0026rsquo;s no way to find a solution, we return \u003ccode\u003e-1\u003c/code\u003e.\u003c/p\u003e","title":"LeetCode 399: Evaluate Division"},{"content":"Very quick post about finding the peak element in an array. This is LeetCode problem 162. We have an array nums with \\(n\\) integers and want to find the index of one of its peaks in \\(O(\\log n)\\) time. The important detail is this: no two neighboring elements have the same value.\nLet\u0026rsquo;s dive in!\nSolution To solve this in logarithmic time, we will use binary search. We start with a left index and a right index. We then compute a mid point mid = (left + right) / 2. Now we investigate what the local behavior around mid is. If nums[mid] \u0026gt; nums[mid + 1], it means that there\u0026rsquo;s no point searching for the peak at mid + 1 or to its right, so we set right = mid. Otherwise, there\u0026rsquo;s no point in searching for the peak at mid or to its left, so we set left = mid + 1.\nWe keep repeating this until left is greater or equal to right. Here\u0026rsquo;s the code:\nclass Solution { public: int findPeakElement(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int left = 0; int right = nums.size() - 1; int mid; while (left \u0026lt; right) { int mid = (left + right) / 2; if (nums[mid] \u0026gt; nums[mid + 1]) { right = mid; } else { left = mid + 1; } } return left; } }; The code beats 100% of other solutions in terms of runtime. The time complexity is \\(O(\\log n)\\), because we narrow down the search to half of the array in each loop iteration. Even more precisely, the number of iterations is at most \\(\\lceil \\log_2 n \\rceil\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_162/","summary":"\u003cp\u003eVery quick post about finding the peak element in an array.\nThis is \u003ca href=\"https://leetcode.com/problems/find-peak-element\"\u003eLeetCode problem 162\u003c/a\u003e.\nWe have an array \u003ccode\u003enums\u003c/code\u003e with \\(n\\) integers and want to find the index of one of its peaks in \\(O(\\log n)\\) time.\nThe important detail is this: no two neighboring elements have the same value.\u003c/p\u003e\n\u003cp\u003eLet\u0026rsquo;s dive in!\u003c/p\u003e\n\u003ch2 id=\"solution\"\u003eSolution\u003c/h2\u003e\n\u003cp\u003eTo solve this in logarithmic time, we will use binary search.\nWe start with a \u003ccode\u003eleft\u003c/code\u003e index and a \u003ccode\u003eright\u003c/code\u003e index.\nWe then compute a mid point \u003ccode\u003emid = (left + right) / 2\u003c/code\u003e.\nNow we investigate what the local behavior around \u003ccode\u003emid\u003c/code\u003e is.\nIf \u003ccode\u003enums[mid] \u0026gt; nums[mid + 1]\u003c/code\u003e, it means that there\u0026rsquo;s no point searching for the peak at \u003ccode\u003emid + 1\u003c/code\u003e or to its right, so we set \u003ccode\u003eright = mid\u003c/code\u003e.\nOtherwise, there\u0026rsquo;s no point in searching for the peak at \u003ccode\u003emid\u003c/code\u003e or to its left, so we set \u003ccode\u003eleft = mid + 1\u003c/code\u003e.\u003c/p\u003e","title":"LeetCode 162: Find Peak Element"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! And it\u0026rsquo;s very intuitive!\nSimplifying the action tree We\u0026rsquo;ll simplify the action tree in two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\]What are the initial values? If we buy on day 1, we have \\(H_1 = -S_1 - f\\). If we don\u0026rsquo;t we have \\(F_1 = 0\\). If there are \\(n\\) days, then our output will be \\(F_n\\). After all, it\u0026rsquo;s better to have sold our last stock than to still be holding it.\nFull solution and time complexity analysis The implementation is super straightforward. We simply apply the formula every day:\nclass Solution { public: int maxProfit(vector\u0026lt;int\u0026gt;\u0026amp; prices, int fee) { int holdBalance = -fee - prices[0]; // H_i int freeBalance = 0; // F_i for (size_t i = 1; i \u0026lt; prices.size(); ++i) { int newHoldBalance = max(holdBalance, freeBalance - fee - prices[i]); int newFreeBalance = max(freeBalance, holdBalance + prices[i]); holdBalance = newHoldBalance; freeBalance = newFreeBalance; } return freeBalance; } } That\u0026rsquo;s it! LeetCode says this solution takes 0 ms, beating 100% of other solutions in terms of runtime. It takes 58.98 MB memory, but this is only due to the input array and LeetCode\u0026rsquo;s overhead. We\u0026rsquo;re only using four integers after all.\nThe time complexity is \\(O (n)\\) as we only have to loop through the prices array once. The space complexity is \\(O(1)\\) as we only use four integers regardless of \\(n\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi â˜•. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"}]