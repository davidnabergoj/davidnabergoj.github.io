[{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nStrategy When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nStrategy When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nStrategy When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nStrategy When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! If we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)? \\(H_{i+1}\\) will be the maximum of two:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we bought the stock valued at \\(S_{i+1}\\) The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)? \\(H_{i+1}\\) will be the maximum of two:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with a formula: \\[\ra = 3\r\\]The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with a formula: \\[\r(H_i, F_i) \\mapsto \\]The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with a formula: \\[\r(H_i, F_i) \\mapsto (\\max (H_i, F_i - f - S_{i+1}), \\max (F_i, H_i + S_{i + 1}))\r\\]The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with a formula: \\[\r(H_i, F_i) \\mapsto (\\max (H_i, F_i - f - S_{i+1}), \\max (F_i, H_i + S_{i + 1}))\r\\]The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with a formula: \\[\r(H_i, F_i) \\mapsto (\\max (H_i, F_i - f - S_{i+1}), \\max (F_i, H_i + S_{i + 1})).\r\\]The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \\mapsto \\max (H_i, F_i - f - S_{i+1},\rF_i \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\]The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\]The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \u0026\\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \u0026\\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\]The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\]The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \u0026 \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \u0026 \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\]The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\begin{align} H_i \u0026amp; \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\ F_i \u0026amp; \\mapsto \\max (F_i, H_i + S_{i + 1}). \\end{align}\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\r\\begin{align}\rH_i \u0026 \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \u0026 \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\end{align}\r\\]The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\]The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nSimplifying the action tree If we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! In two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\] The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! And it\u0026rsquo;s very intuitive!\nSimplifying the action tree We\u0026rsquo;ll simplify the action tree in two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\] The find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! And it\u0026rsquo;s very intuitive!\nSimplifying the action tree We\u0026rsquo;ll simplify the action tree in two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\]What are the initial values? If we buy on day 1, we have \\(H_1 = -S_1 - f\\). If we don\u0026rsquo;t we have \\(F_1 = 0\\).\nFull solution The implementation is super straightforward. We simply apply the formula every day:\nclass Solution { public: int maxProfit(vector\u0026lt;int\u0026gt;\u0026amp; prices, int fee) { int holdBalance = -fee - prices[0]; // H_i int freeBalance = 0; // F_i } } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! And it\u0026rsquo;s very intuitive!\nSimplifying the action tree We\u0026rsquo;ll simplify the action tree in two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\]What are the initial values? If we buy on day 1, we have \\(H_1 = -S_1 - f\\). If we don\u0026rsquo;t we have \\(F_1 = 0\\).\nFull solution The implementation is super straightforward. We simply apply the formula every day:\nclass Solution { public: int maxProfit(vector\u0026lt;int\u0026gt;\u0026amp; prices, int fee) { int holdBalance = -fee - prices[0]; // H_i int freeBalance = 0; // F_i for (size_t i = 1; i \u0026lt; prices.size(); ++i) { int newHoldBalance = max(holdBalance, freeBalance - fee - prices[i]); int newFreeBalance = max(freeBalance, holdBalance + prices[i]); holdBalance = newHoldBalance; freeBalance = newFreeBalance; } return freeBalance; } } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! And it\u0026rsquo;s very intuitive!\nSimplifying the action tree We\u0026rsquo;ll simplify the action tree in two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\]What are the initial values? If we buy on day 1, we have \\(H_1 = -S_1 - f\\). If we don\u0026rsquo;t we have \\(F_1 = 0\\). If there are \\(n\\) days, then our output will be \\(F_n\\). After all, it\u0026rsquo;s better to have sold our last stock than to still be holding it.\nFull solution The implementation is super straightforward. We simply apply the formula every day:\nclass Solution { public: int maxProfit(vector\u0026lt;int\u0026gt;\u0026amp; prices, int fee) { int holdBalance = -fee - prices[0]; // H_i int freeBalance = 0; // F_i for (size_t i = 1; i \u0026lt; prices.size(); ++i) { int newHoldBalance = max(holdBalance, freeBalance - fee - prices[i]); int newFreeBalance = max(freeBalance, holdBalance + prices[i]); holdBalance = newHoldBalance; freeBalance = newFreeBalance; } return freeBalance; } } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! And it\u0026rsquo;s very intuitive!\nSimplifying the action tree We\u0026rsquo;ll simplify the action tree in two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\]What are the initial values? If we buy on day 1, we have \\(H_1 = -S_1 - f\\). If we don\u0026rsquo;t we have \\(F_1 = 0\\). If there are \\(n\\) days, then our output will be \\(F_n\\). After all, it\u0026rsquo;s better to have sold our last stock than to still be holding it.\nFull solution and time complexity analysis The implementation is super straightforward. We simply apply the formula every day:\nclass Solution { public: int maxProfit(vector\u0026lt;int\u0026gt;\u0026amp; prices, int fee) { int holdBalance = -fee - prices[0]; // H_i int freeBalance = 0; // F_i for (size_t i = 1; i \u0026lt; prices.size(); ++i) { int newHoldBalance = max(holdBalance, freeBalance - fee - prices[i]); int newFreeBalance = max(freeBalance, holdBalance + prices[i]); holdBalance = newHoldBalance; freeBalance = newFreeBalance; } return freeBalance; } } That\u0026rsquo;s it! LeetCode says this solution takes 0 ms, beating 100% of other solutions in terms of runtime. It takes 58.98 MB memory, but this is only due to the input array and LeetCode\u0026rsquo;s overhead. We\u0026rsquo;re only using four integers after all.\nI mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! And it\u0026rsquo;s very intuitive!\nSimplifying the action tree We\u0026rsquo;ll simplify the action tree in two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\]What are the initial values? If we buy on day 1, we have \\(H_1 = -S_1 - f\\). If we don\u0026rsquo;t we have \\(F_1 = 0\\). If there are \\(n\\) days, then our output will be \\(F_n\\). After all, it\u0026rsquo;s better to have sold our last stock than to still be holding it.\nFull solution and time complexity analysis The implementation is super straightforward. We simply apply the formula every day:\nclass Solution { public: int maxProfit(vector\u0026lt;int\u0026gt;\u0026amp; prices, int fee) { int holdBalance = -fee - prices[0]; // H_i int freeBalance = 0; // F_i for (size_t i = 1; i \u0026lt; prices.size(); ++i) { int newHoldBalance = max(holdBalance, freeBalance - fee - prices[i]); int newFreeBalance = max(freeBalance, holdBalance + prices[i]); holdBalance = newHoldBalance; freeBalance = newFreeBalance; } return freeBalance; } } That\u0026rsquo;s it! LeetCode says this solution takes 0 ms, beating 100% of other solutions in terms of runtime. It takes 58.98 MB memory, but this is only due to the input array and LeetCode\u0026rsquo;s overhead. We\u0026rsquo;re only using four integers after all.\nThe time complexity is \\(O (n)\\) as we only have to loop through the prices array once. The space complexity is \\(O(1)\\) as we only use four integers regardless of \\(n\\).\nI mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"},{"content":"Welcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at LeetCode problem 714. We\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both). When we sell a stock, we have to pay a transaction fee. We want to find the maximum profit we can achieve.\nWe approach this using dynamic programming. Let\u0026rsquo;s dive in!\nVisualizing possible actions When tackling dynamic programming problems, I instantly think: how can I reuse results I\u0026rsquo;ve already computed? I found it very useful to visualize what actions I can take every day. Let\u0026rsquo;s look at a tree of options: After taking a path of actions, we arrive at a particular node. The value in the node is our balance after all the actions we took along the way. We can see that some nodes give us a higher value than others. The best outcome in this case is a balance of 10, while the worst is a balance of -10.\nIf we simulate all options, we\u0026rsquo;ll clearly end up with exponentially many possibilities. That would take too long to compute in reasonable time. Could we simplify this tree a bit?\nYes! And it\u0026rsquo;s very intuitive!\nSimplifying the action tree We\u0026rsquo;ll simplify the action tree in two ways:\nIf we have no stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got to that day. What matters is the balance we have. We might as well only continue with the highest possible balance. If we have a stock to sell on a particular day, then it doesn\u0026rsquo;t really matter how we got there. After all, we paid for the stock (including the fee) on a previous day. What we have right now is our balance and an option to sell. We might as well only continue with the highest possible balance in this case too. This completely removes the need to simulate all options! Let\u0026rsquo;s just keep the highest balance based on if we have a stock or not. Let\u0026rsquo;s say \\(H_i\\) is the balance on day \\(i\\) if we are holding a stock that we can sell. Let\u0026rsquo;s call \\(F_i\\) the balance on day \\(i\\) if we have no stock to sell. We will denote the buying fee with \\(f\\) and the stock on day \\(i\\) with \\(S_i\\).\nWhat happens on day \\(i+1\\)?\n\\(H_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(H_i\\), indicating that we haven\u0026rsquo;t sold the stock on day \\(i+1\\), or A new balance \\(F_i - f - S_{i+1}\\), indicating that we paid \\(f\\) to buy the stock valued at \\(S_{i+1}\\) while the previous balance was \\(F_i\\). This is like overwriting \\(H_i\\) with a new, better path in the action tree. Similarly, \\(F_{i+1}\\) will be the maximum of two values:\nThe previous balance \\(F_i\\), indicating that we haven\u0026rsquo;t bought the stock on day \\(i+1\\), or A new balance \\(H_i + S_{i+1}\\), indicating that we sold the stock valued at \\(S_{i+1}\\) while the previous balance was \\(H_i\\). This is like overwriting \\(F_i\\) with a new, better path in the action tree. We can represent the step with two formulas: \\[\rH_i \\mapsto \\max (H_i, F_i - f - S_{i+1}, \\\\\rF_i \\mapsto \\max (F_i, H_i + S_{i + 1}).\r\\]What are the initial values? If we buy on day 1, we have \\(H_1 = -S_1 - f\\). If we don\u0026rsquo;t we have \\(F_1 = 0\\). If there are \\(n\\) days, then our output will be \\(F_n\\). After all, it\u0026rsquo;s better to have sold our last stock than to still be holding it.\nFull solution and time complexity analysis The implementation is super straightforward. We simply apply the formula every day:\nclass Solution { public: int maxProfit(vector\u0026lt;int\u0026gt;\u0026amp; prices, int fee) { int holdBalance = -fee - prices[0]; // H_i int freeBalance = 0; // F_i for (size_t i = 1; i \u0026lt; prices.size(); ++i) { int newHoldBalance = max(holdBalance, freeBalance - fee - prices[i]); int newFreeBalance = max(freeBalance, holdBalance + prices[i]); holdBalance = newHoldBalance; freeBalance = newFreeBalance; } return freeBalance; } } That\u0026rsquo;s it! LeetCode says this solution takes 0 ms, beating 100% of other solutions in terms of runtime. It takes 58.98 MB memory, but this is only due to the input array and LeetCode\u0026rsquo;s overhead. We\u0026rsquo;re only using four integers after all.\nThe time complexity is \\(O (n)\\) as we only have to loop through the prices array once. The space complexity is \\(O(1)\\) as we only use four integers regardless of \\(n\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_714/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! Let\u0026rsquo;s look at \u003ca href=\"https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/description/\"\u003eLeetCode problem 714\u003c/a\u003e.\nWe\u0026rsquo;re given an array of stock prices. Each day, we can either buy a stock if we have none or sell a stock we own (but not both).\nWhen we sell a stock, we have to pay a transaction fee.\nWe want to find the maximum profit we can achieve.\u003c/p\u003e\n\u003cp\u003eWe approach this using dynamic programming.\nLet\u0026rsquo;s dive in!\u003c/p\u003e","title":"LeetCode 714: Best Time to Buy and Sell Stock with Transaction Fee"},{"content":"Welcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling LeetCode problem 1268. We\u0026rsquo;re given an array of strings called products, as well as a string searchWord. Our goal is to suggest three products after typing each character of searchWord. This is a tiny autocompletion method! We could solve this problem with a Trie, like the one we implemented to solve LeetCode problem 208. Check it out!\nBut today, I felt like solving this without writing hyper-optimized or over-engineered code. Our solution will be simple and straightforward\u0026hellip; but still efficient! Let\u0026rsquo;s dive in.\nStrategy Let\u0026rsquo;s first sort the products array.\nThen let\u0026rsquo;s cut off the right part of searchWord and get a string called prefix. For example, we can take searchWord = \u0026quot;mouse\u0026quot; and get prefix = \u0026quot;mous\u0026quot;. After products is sorted, we can traverse it from left to right with index i. One of two things may happen:\nproducts[i] could start with prefix for some i, OR No such i is found. In the second case, there\u0026rsquo;s nothing to suggest! But in the first case, we can simply check the next two elements: products[i+1] and products[i+2]. If they also start with prefix, we\u0026rsquo;ve found the three products! It\u0026rsquo;s possible that we only find one or two, in which case we return those.\nThe find function First let\u0026rsquo;s implement a function to find a prefix p inside the sorted array:\nint find(vector\u0026lt;string\u0026gt; *a, string *p) { for (int index = 0; index \u0026lt; a-\u0026gt;size(); ++index) { if (a-\u0026gt;at(index).substr(0, p-\u0026gt;size()) == *p) { return index; } } return -1; } I mentioned there won\u0026rsquo;t be optimizations, but we can make a small one. You\u0026rsquo;ll see later why this is useful. The first change: we don\u0026rsquo;t compute the entire substring. Instead, we traverse prefix and a-\u0026gt;at(index) with i. As soon as the characters prefix[i] and a-\u0026gt;at(index)[i] do not match, we return -1. If this never happens, we return index. The second change: we only start looking through the sorted array at index start. This will allow us to skip some entries later on and save time for long prefixes.\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { // begin with `start` bool found = true; for (size_t i = 0; i \u0026lt; p-\u0026gt;size(); ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } Ok, one last tiny optimization: let\u0026rsquo;s pass the prefix size into find. Now we won\u0026rsquo;t need to create substrings of searchWord at all, saving some time and memory if searchWord is long!\nint find(vector\u0026lt;string\u0026gt; *a, string *p, size_t start, size_t prefixSize) { for (int index = start; index \u0026lt; a-\u0026gt;size(); ++index) { bool found; for (size_t i = 0; i \u0026lt; prefixSize; ++i) { if (a-\u0026gt;at(index)[i] == p-\u0026gt;at(i)) { found = false; break; } } if (found) { return index; } } return -1; } The suggestedProducts function Now what\u0026rsquo;s left is to apply find for different prefixes.\nAs stated before, we first sort the array of products. Then we try to match increasingly bigger prefixes of searchWord within products using find. Two things may happen:\nIf successful, we look for at most two extra products. Afterwards, we store the suggestions for this prefix into an array called output. If unsuccessful, typing further characters won\u0026rsquo;t change anything. We can simply skip looking for further products. Here\u0026rsquo;s the suggestedProducts code:\nvector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; suggestedProducts(vector\u0026lt;string\u0026gt;\u0026amp; products, string searchWord) { std::sort(products.begin(), products.end()); vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; output; int index = 0; // Check all prefixes of searchWord for (size_t i = 0; i \u0026lt; searchWord.size(); ++i) { // Skip the search if a previous prefix was not found if (index != -1) { // Look for searchWord\u0026#39;s prefix inside the products array index = find(\u0026amp;products, \u0026amp;searchWord, index, i + 1); } vector\u0026lt;string\u0026gt; tmp; // products for this prefix if (index != -1) { // Add the first product tmp.push_back(products[index]); // Find one or two more products for (size_t offset = 1; offset \u0026lt; 3 \u0026amp;\u0026amp; (index + offset \u0026lt; products.size()); ++offset) { // Check the prefixes with size i + 1 match bool found = true; for (size_t j = 0; j \u0026lt; i + 1; ++j) { if (products[index + offset][j] != searchWord[j]) { found = false; break; } } if (found) { // Add the product to tmp tmp.push_back(products[index + offset]); } else { // No more checking needed - lets us skip checking for the third product if the second was not found break; } } } // Append the products to the full output output.push_back(tmp); } return output; } Runtime, memory usage, and time complexity analysis This code passes all tests with a runtime of 7ms and 32.2 MB memory usage. That\u0026rsquo;s better than 93 percent of all solutions in terms of runtime and better than 82 percent in terms of memory!\nLet\u0026rsquo;s say:\nproducts has size \\(n\\), searchWord has size \\(m\\). the longest product has size \\(k\\) We break down the time complexity as follows:\nWe perform \\(O(n \\log n)\\) element-level comparisons during sorting. To compare the strings, we perform \\(O(k)\\) comparison operations. We thus spend \\(O (k n \\log n)\\) time on sorting. We call find \\(m\\) times. There are fewer elements to check each time. However, each call may still scan at most \\(n\\) products, and the prefix length grows from \\(1\\) to \\(m\\). Each product may therefore be compared against increasingly longer prefixes. The total time spent on the find function is thus \\(O (nm^2) \\). Checking if the two additional products takes at most \\(2m\\) comparisons. Since we check this for at most \\(m\\) prefixes, the additional search takes \\(O(m^2)\\), noting that the \\(2\\) does not affect asymptotic complexity. The total time complexity is thus \\(O(kn \\log n + nm^2) = O(n (k \\log n + m^2))\\).\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1268/","summary":"\u003cp\u003eWelcome back to another LeetCode walkthrough! This time, we\u0026rsquo;ll be tackling \u003ca href=\"https://leetcode.com/problems/search-suggestions-system\"\u003eLeetCode problem 1268\u003c/a\u003e.\nWe\u0026rsquo;re given an array of strings called \u003ccode\u003eproducts\u003c/code\u003e, as well as a string \u003ccode\u003esearchWord\u003c/code\u003e.\nOur goal is to suggest three products after typing each character of \u003ccode\u003esearchWord\u003c/code\u003e.\nThis is a tiny autocompletion method!\nWe could solve this problem with a Trie, like the one we implemented to solve \u003ca href=\"/posts/leetcode_208/\"\u003eLeetCode problem 208\u003c/a\u003e. Check it out!\u003c/p\u003e\n\u003cp\u003eBut today, I felt like solving this without writing hyper-optimized or over-engineered code.\nOur solution will be simple and straightforward\u0026hellip; but still efficient!\nLet\u0026rsquo;s dive in.\u003c/p\u003e","title":"LeetCode 1268: Search Suggestions System"},{"content":"I\u0026rsquo;ve been learning about CUDA C++ programming this week, following this blog post by Mark Harris. What makes CUDA useful is its ability to execute many computations in parallel instead of sequentially. The linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each. I\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products. You can see the full code in my repository here: https://github.com/davidnabergoj/cuda-programming.\nSequential addition The sequential approach to adding two vectors is straightforward. We simply iterate over all indices and add the values. x and y are pointers to two arrays of size n.\nvoid add(int n, float *x, float *y) { for (size_t i = 0; i \u0026lt; n; i++) { y[i] = x[i] + y[i]; } } However, adding vectors this way only executes one addition at a time. Doing so in parallel would save us a lot of time, as we wouldn\u0026rsquo;t have to wait for previous additions to finish.\nParallel addition - single block CUDA kernels are an extension of C++ code which are executed on the GPU. We can change our previous function into a CUDA kernel by adding the __global__ keyword.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = threadIdx.x; int stride = blockDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } Our CUDA kernel accesses two global variables: threadIdx.x and blockDim.x that describe which thread is used for this computation. When executing the kernel, we are essentially working with an array of threads called a block. We want each thread to compute x[i] + y[i] for indices i in its part of the array. We are essentially delegating work to different threads. We can imagine threads in a block to be like construction workers in a team.\nSuppose we have a block with four threads and \\(n = 11\\) elements in both our arrays. This makes blockDim.x = 4. The value of threadIdx.x will be one of 0, 1, 2, or 3. Let\u0026rsquo;s give each thread a color: orange for zero, blue for 1, green for 2, and purple for 3. For a given thread with index threadIdx.x, the for loop will go through indices i = threadIdx.x + 0, i = threadIdx.x + 4, i = threadIdx.x + 8, etc. The loop will stop once i goes beyond the bounds of the input arrays. At each index, the thread will compute and store the sum of the two array elements.\nSince the threads are executed in parallel, each for loop will only take three iterations. The purple thread with threadIdx.x = 3 will be done two iterations, while others need three. This is in contrast to 11 iterations on the CPU program. In this case, the CUDA approach will theoretically only need \\(n / 4\\) loop iterations. Increasing the number of threads makes this even faster! With \\(m\\) threads, we only need \\(n / m\\) iterations. This is great for very large vectors!\nParallel addition - multiple blocks We can take our parallelization one step further by using multiple blocks in parallel. These blocks are arranged in a grid. Using our analogy from before, multiple blocks are like multiple teams of construction workers. The grid is like a construction site with multiple teams, each working on their own separate task.\n__global__ void add(int n, float *x, float *y, float *sum) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (size_t i = index; i \u0026lt; n; i += stride) { sum[i] = x[i] + y[i]; } } The kernel code stays largely the same. The only difference is figuring out which parts of the array our thread should process. The initial index for each thread is threadIdx.x - local to its block, offset by the total number of threads in all blocks before it. The stride was previously equal to the number of threads in the block, meaning the for loop increments the index by the block size. However, the new way of indexing requires that we increment the index by the sum of all block sizes.\nYou can check out the picture below for a visualization. Solid lines denote threads in block 1, while dashed lines denote threads in block 2. I\u0026rsquo;m not showing the actual values of x and y, as there are too many :P\nIf we have \\(B\\) blocks with \\(m\\) threads each, we now only require \\(n / (Bm)\\) for loop steps! This makes parallel execution even faster.\nComputing the dot product Let\u0026rsquo;s look at another example: computing the dot product of two vectors. Mathematically, the dot product is defined as \\(a^\\top b = \\sum_{i = 1}^n a_i b_i\\). Translating this to C++ means looping over the elements and adding the products a[i] * b[i] to a result out. In the code below, d is a pointer to a float.\nvoid dot(float *a, float *b, float *d, size_t n) { float out = 0.0; for (size_t i = 0; i \u0026lt; n; i++) { out += a[i] * b[i]; } *d = out; } How can we make this faster? We tell each block to compute a partial sum. The mathematical idea is \\(a^\\top b = \\sum_{i = 1}^n a_i b_i = \\sum_{j = 1}^k \\sum_{i = 1}^m a_{jk+i} b_{jk+i} \\) where \\(j\\) is an index over \\(k\\) blocks, and \\(i\\) is an index over \\(m\\) threads within each block.\n#define BLOCK_SIZE 32 __global__ void dot_psum(float* a, float* b, float* p, size_t n) { __shared__ float sdata[BLOCK_SIZE]; // the whole block can access this size_t tid = threadIdx.x; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? a[idx] * b[idx] : 0; __syncthreads(); // wait until all threads in this block have written to sdata for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Only allow thread 0 to write, otherwise we get race conditions and undefined behavior if (tid == 0) { p[blockIdx.x] = sdata[0]; } } In the kernel above, p is a pointer to a float array which holds \\( k \\) partial sums. We use an array called sdata with size \\(m\\) that is shared across all threads in a block. Each thread writes its own product to sdata. We use __syncthreads() to wait until all threads have successfully written to sdata.\nWe want to then sum all elements in sdata to create the partial sum. We use a clever strategy which only needs \\(O(\\log_2 m)\\) parallel iterations. In each thread, we use a for loop to produce different offsets s. If the thread index tid is less than the offset s, we look at the numbers in sdata[tid] and its offset counterpart sdata[tid + s]. We add sdata[tid + s] to sdata[tid]. After each loop step, we no longer have to look at sdata[tid + s], as its value has been accumulated into sdata[tid].\nCheck out the visualization for the first step, where we\u0026rsquo;re pretending to have a block of size \\(m = 8\\). The accumulation is only performed by threads 0, 1, 2, and 3, because threads 4, 5, 6, 7 have index greater than s = 4.\nAfterward, we apply the reduction again.\nAnd again :)\nNow the entire sum is located in the first element of sdata and we can write it to the output array. We\u0026rsquo;ll tell thread 0 of the block to do it, as having more than one thread trying to write to the same value will result in problems.\nif (tid == 0) { p[blockIdx.x] = sdata[0]; } Once all blocks have done this, the array of partial sums p is full. What remains is to sum the partial sums. A simple way of doing so is transferring the result back to the CPU and summing them sequentially.\nfloat result = 0.0f; for (size_t i = 0; i \u0026lt; blocks; i++) { result += p[i]; } However, we can take it a step further and use a CUDA kernel to apply the final summation. The code is very similar! The only difference is we do not multiply two values when construcing sdata, but instead simply copy them over. In this kernel, we use the input array of partial sums in as the output as well, effectively modifying it in place. At the end, the result is stored in p[0].\n__global__ void reduce_sum(float* in, size_t n) { size_t tid = threadIdx.x; __shared__ float sdata[BLOCK_SIZE]; size_t idx = blockIdx.x * BLOCK_SIZE + threadIdx.x; sdata[tid] = (idx \u0026lt; n) ? in[idx] : 0; __syncthreads(); for (size_t s = BLOCK_SIZE / 2; s \u0026gt; 0; s \u0026gt;\u0026gt;= 1) { if (tid \u0026lt; s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } if (tid == 0) { in[blockIdx.x] = sdata[0]; } } Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More CUDA coming soon :)\n","permalink":"http://localhost:1313/posts/cuda_intro/","summary":"\u003cp\u003eI\u0026rsquo;ve been learning about CUDA C++ programming this week, following \u003ca href=\"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\"\u003ethis blog post\u003c/a\u003e by Mark Harris.\nWhat makes CUDA useful is its ability to execute many computations in parallel instead of sequentially.\nThe linked blog post demonstrates how it can add two very large vectors with a size of 1 million elements each.\nI\u0026rsquo;ll present the most interesting code snippets in an approachable way and show how very similar code can perform vector-vector dot products.\nYou can see the full code in my repository here: \u003ca href=\"https://github.com/davidnabergoj/cuda-programming\"\u003ehttps://github.com/davidnabergoj/cuda-programming\u003c/a\u003e.\u003c/p\u003e","title":"Starting out with CUDA C++"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 1143. We have two strings text1 and text2 with sizes \\(n\\) and \\(m\\), respectively. We want to find the length of their longest common subsequence (LCS). A subsequence of a string s is obtained by deleting zero or more characters from s.\nStrategy Let\u0026rsquo;s assume we have two strings: s1 with size n1 and s2 with size n2. Let\u0026rsquo;s also assume we know their LCS length. What can we say about LCS length when we append a character c1 to s1 and a character c2 to s2?\nThe new characters are the same If c1 and c2 are the same, then the new LCS is the previous LCS plus the new character c1 (or c2, they are the same after all). The new LCS length is thus one plus the previous LCS length.\nFor example, say s1 = subjec and s2 = objec. The LCS is bjec and has length 4. We now add t to both, so c1 = t and c2 = t. The new strings are s1 = subject and s2 = object. The new LCS is bject and has length 5.\nThe new characters are different What if they\u0026rsquo;re not the same?\nIn this case, just adding c1 to s1 and keeping s2 unchanged may be enough to increase LCS length. We can add c2 to s2 afterwards, even though it won\u0026rsquo;t increase LCS length. The same goes for the reverse case: we may increase LCS length by adding c2 to s2. We can add c1 to s1 afterwards. We\u0026rsquo;re interested in the longer of these two lengths.\nThe new LCS length is thus the maximum of two LCS lengths: one where we only add c1 to s1 and one where we only add c2 to s2. Let\u0026rsquo;s look at an example below, where s1 = factor and s2 = stay. We try to add c1 = y and c2 = s.\nBasic implementation We will implement our approach using recursion. We\u0026rsquo;ll write a function lcsLength(string *text1, string *text2, int i, int j). This function will return LCS length of text1 up to index i (inclusive) and text2 up to index j (inclusive). This will be like adding text1[i] to s1 and text[j] to s2. We\u0026rsquo;ll pass in pointers to strings to avoid copying entire strings in each recursive call. The basic function can be implemented as follows:\nint lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { return lcsLength(text1, text2, i - 1, j - 1) + 1; } else { return max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } Implementation with dynamic programming The issue with the above code is that we call lcsLength multiple times with the same values of i and j. This wastes a lot of computation time, and causes a combinatorial explosion of the number of computations across recursive calls. We fix this by creating a matrix lcsLengthCache of size n x m which holds the computed values. Whenever we call lcsLength, we first check if the result is already in our matrix and attempt to return that instead of recomputing everything. We initialize the matrix with -1 in all cells, which indicates that the value had not yet been computed. Reusing computations in such a way is called dynamic programming.\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; // must be initialized to size n x m int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } Full solution Since the sizes of text1 and text2 are n and m, we want to compute lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1). This will be the LCS length across the entirety of both strings. Below is the full code.\nclass Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; lcsLengthCache; int lcsLength(string *text1, string *text2, int i, int j) { if (i \u0026lt; 0 || j \u0026lt; 0) { return 0; } if (lcsLengthCache[i][j] == -1) { if (text1-\u0026gt;at(i) == text2-\u0026gt;at(j)) { lcsLengthCache[i][j] = lcsLength(text1, text2, i - 1, j - 1) + 1; } else { lcsLengthCache[i][j] = max( lcsLength(text1, text2, i - 1, j), lcsLength(text1, text2, i, j - 1) ); } } return lcsLengthCache[i][j]; } int longestCommonSubsequence(string text1, string text2) { int n = text1.size(); int m = text2.size(); lcsLengthCache = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(m, -1)); return lcsLength(\u0026amp;text1, \u0026amp;text2, n - 1, m - 1); } }; Time complexity analysis The code passes all tests with a runtime of 55ms and 27.66 MB memory usage. There are a bunch of avenues for optimization, but the solution clearly highlights the approach and benefits of dynamic programming.\nThe total space complexity is \\(O(nm + n + m)\\) to hold the matrix and both inputs. It can be simplified to \\(O(nm)\\). The total time complexity is \\(O(nm)\\) as we need at most \\(nm\\) evaluations of lcsLength to compute the final output by filling the entire matrix.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_1143/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/longest-common-subsequence\"\u003eLeetCode problem 1143\u003c/a\u003e.\nWe have two strings \u003ccode\u003etext1\u003c/code\u003e and \u003ccode\u003etext2\u003c/code\u003e with sizes \\(n\\) and \\(m\\), respectively.\nWe want to find the length of their longest common subsequence (LCS).\nA subsequence of a string \u003ccode\u003es\u003c/code\u003e is obtained by deleting zero or more characters from \u003ccode\u003es\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s assume we have two strings: \u003ccode\u003es1\u003c/code\u003e with size \u003ccode\u003en1\u003c/code\u003e and \u003ccode\u003es2\u003c/code\u003e with size \u003ccode\u003en2\u003c/code\u003e.\nLet\u0026rsquo;s also assume we know their LCS length.\nWhat can we say about LCS length when we append a character \u003ccode\u003ec1\u003c/code\u003e to \u003ccode\u003es1\u003c/code\u003e and a character \u003ccode\u003ec2\u003c/code\u003e to \u003ccode\u003es2\u003c/code\u003e?\u003c/p\u003e","title":"LeetCode 1143: Longest Common Subsequence"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2542. We have two integer arrays nums1 and nums2 with size \\(n\\), as well as an integer \\(k\\). Let\u0026rsquo;s denote nums1 with \\(A\\) and nums2 with \\(B\\). If we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows: \\[\r\\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\\] There are many different sets \\(S\\) that give different scores. We want to find the maximum possible score.\nStrategy The total number of possible sets is \\(n! / (k! (n-k)!)\\), which is too big to make a brute-force solution feasible. We want an more effective way of picking the indices. If we can somehow sort the two arrays, then we may be able to observe \\(k\\) elements from left to right in a sliding window manner.\nLet\u0026rsquo;s try sorting \\(B\\) in non-increasing order. Because the two arrays are connected, we sort \\(A\\) using the same order. Each value of \\(B\\) will now be less or equal to the previous one. What\u0026rsquo;s more, it will be less than the previous \\(k - 1\\) values. This will be our minimum term for the score.\nWe will work with a vector of pairs to make sorting easy. This requires an extra \\(O(n)\\) space, but the overall space complexity is \\(O(n)\\) anyway for the input arrays. The sort function will sort \\(A\\) and \\(B\\) together according to values of \\(B\\) first. This is because they are the first in each pair. We use rbegin and rend to get a reversed ascending-order output, which is equivalent to a standard descending-order output.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); From this point, we treat \\(A\\) and \\(B\\) to be sorted as discussed above.\nIf we scan the arrays from left to right, we could impose a size \\(k\\) sliding window over \\(A\\) to keep track of the sum term. But there\u0026rsquo;s a catch! Say we\u0026rsquo;re at index \\(i\\). It\u0026rsquo;s possible that there\u0026rsquo;s an element \\(A_j\\) at index \\(j \u003c i\\) that greatly contributes to the score, but is not within the window \\((j \\leq i - k)\\). The corresponding index \\(j\\) could still be in the solution set \\(S\\) and the minimum term would not change, as \\(B_j\\) cannot be less than \\(B_i\\).\nInstead of a sliding window, we can keep a priority queue of size \\(k\\). The first element is the smallest element of \\(A\\) up to \\(i\\) \u0026ndash; the current index. As we loop through the sorted array, we fill the priority queue until it\u0026rsquo;s too large, at which point we pop the smallest element. This effectively defines \\(S\\) as indices between \\(0\\) and \\(i\\), with \\(i\\) always being included. At the same time, \\(B_i\\) is always the minimum term for the score computation. We keep track of the current sum term value, making sure to subtract values that we pop from the priority queue.\npriority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; // min-heap (smallest element on top) long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } // Start the second loop at k - 1, after the priority queue long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; // Update the sum term // Ensure we are always observing at most k elements if (pq.size() \u0026gt; k) { currentSum -= pq.top(); // Correct the sum term pq.pop(); } // Update the best score after the priority queue has exactly k elements bestScore = max(bestScore, currentSum * pairs[i].first); } Full solution and time complexity analysis Below is the full code! It passes all tests with a runtime of 71ms and 94.8 MB memory usage.\nWe break down the time complexity as follows:\nwe need \\(O(n \\log n)\\) time for sorting. we perform \\(n\\) priority queue insertions, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for insertions. we perform \\(n - (k - 1)\\) priority queue pops, each with complexity \\(O(\\log k)\\), leading to \\(O (n \\log k) \\) time for popping since \\(n \\geq k\\). The total runtime is dominated by the initial sorting process. If \\(k\\) is much less than \\(n\\), then overall complexity is \\(O(n \\log n)\\). Otherwise, we can more precisely say the time complexity is \\(O(n\\log n + n\\log k)\\).\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; class Solution { public: long long maxScore(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2, int k) { vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; pairs(nums1.size()); for (size_t i = 0; i \u0026lt; pairs.size(); i++) { pairs[i] = {nums2[i], nums1[i]}; } std::sort(rbegin(pairs), rend(pairs)); priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; pq; long long currentSum = 0; for (size_t i = 0; i \u0026lt; k - 1; i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; } long long bestScore = 0; for (size_t i = k - 1; i \u0026lt; pairs.size(); i++) { pq.push(pairs[i].second); currentSum += pairs[i].second; if (pq.size() \u0026gt; k) { currentSum -= pq.top(); pq.pop(); } bestScore = max(bestScore, currentSum * pairs[i].first); } return bestScore; } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2542/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/maximum-subsequence-score\"\u003eLeetCode problem 2542\u003c/a\u003e.\nWe have two integer arrays \u003ccode\u003enums1\u003c/code\u003e and \u003ccode\u003enums2\u003c/code\u003e with size \\(n\\), as well as an integer \\(k\\).\nLet\u0026rsquo;s denote \u003ccode\u003enums1\u003c/code\u003e with \\(A\\) and \u003ccode\u003enums2\u003c/code\u003e with \\(B\\).\nIf we pick a set of indices \\(S\\) with exactly \\(k\\) elements, we obtain a score as follows:\n\u003c/p\u003e\n\\[\r\n    \\min \\left\\{ B_i | i \\in S \\right\\} \\sum_{i \\in S} A_i\r\n\\]\u003cp\u003e\nThere are many different sets \\(S\\) that give different scores.\nWe want to find the maximum possible score.\u003c/p\u003e","title":"LeetCode 2542: Maximum Subsequence Score"},{"content":"In this post, we\u0026rsquo;ll be solving LeetCode problem 2236. We start with an infinite set containing all positive integers. We may remove and return the smallest integer using int popSmallest() or add a positive integer back into the set using void addBack(int num).\nStrategy If we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable n. We start with n = 1. Each time we pop, we increment n by one.\nWe only add num back into the set if num \u0026lt; n, as it is otherwise already in the set. If we successfully add num back, it will surely be smaller than n, so any further popSmallest calls should get rid of such numbers first. What\u0026rsquo;s more, we want to pop the smallest of the added num values first.\nWe implement this with a priority queue, which allows us to retrieve the smallest (alternatively, the largest) number inside it in \\(O(1)\\) time, pop it in \\(O(\\log m)\\) time, and insert a new value in \\(O(\\log m)\\) time. Here, \\(m\\) is the number of elements in the priority queue.\nAll numbers placed into the set via addBack are thus put into the priority queue. Whenever we call popSmallest, we first attempt to return the smallest value in the priority queue. If the queue is empty, we instead increment n.\nThere is a small catch: we may add the same num back several times. The priority queue will contain multiple copies. Such duplicates cannot appear in the infinite set. We handle this in popSmallest by observing the smallest element in the queue and store it into a variable output. We then pop from the queue until the smallest element changes. We finally return output.\nFull solution Below is the full solution for the LeetCode problem. Some notes:\nTo create the minPriorityQueue object in C++, we need specify the data type (int), the base data container (vector\u0026lt;int\u0026gt;), and the comparator which will ensure that the top element of the queue is always the smallest one inside it. In popSmallest, we write return n++;, which first returns n to a caller function, then increments its value inside the SmallestInfiniteSet instance. We could equivalently write n++; return n - 1; During my submission, the code needed 10ms of runtime and 43.1 MB of memory.\n#include \u0026lt;queue\u0026gt; class SmallestInfiniteSet { public: int n = 1; priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minPriorityQueue; SmallestInfiniteSet() { } int popSmallest() { int output; if (!minPriorityQueue.empty()) { output = minPriorityQueue.top(); while (!minPriorityQueue.empty() \u0026amp;\u0026amp; output == minPriorityQueue.top()) { minPriorityQueue.pop(); } return output; } else { return n++; } } void addBack(int num) { if (num \u0026lt; n) { minPriorityQueue.push(num); } } }; Thanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_2236/","summary":"\u003cp\u003eIn this post, we\u0026rsquo;ll be solving \u003ca href=\"https://leetcode.com/problems/smallest-number-in-infinite-set\"\u003eLeetCode problem 2236\u003c/a\u003e.\nWe start with an infinite set containing all positive integers.\nWe may remove and return the smallest integer using \u003ccode\u003eint popSmallest()\u003c/code\u003e or add a positive integer back into the set using \u003ccode\u003evoid addBack(int num)\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"strategy\"\u003eStrategy\u003c/h2\u003e\n\u003cp\u003eIf we only focus on popping smallest integers, then we only need to keep track of the smallest number in the set with a variable \u003ccode\u003en\u003c/code\u003e.\nWe start with \u003ccode\u003en = 1\u003c/code\u003e.\nEach time we pop, we increment \u003ccode\u003en\u003c/code\u003e by one.\u003c/p\u003e","title":"LeetCode 2336: smallest number in infinite set"},{"content":"A trie is data structure which holds strings. It allows fast search and insertion of strings, as well as fast search of string prefixes. This can be especially useful for text autocompletion and spellcheck.\nIn this post, we implement a trie in C++ with three basic operations: search, insert, and startsWith. This is the solution to LeetCode 208. The problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\nTrie class We implement the trie as a a tree. Each node contains a fixed vector of pointers (called next) to tries below it. Each pointer corresponds to a different character. For example, next['f'] corresponds to words with the substring.\nWe use a boolean wordEnd indicating that there exists a word that ends in the current trie root. An example where this is useful: the trie contains the word \u0026ldquo;apple\u0026rdquo;, but not \u0026ldquo;app\u0026rdquo;. Searching for \u0026ldquo;app\u0026rdquo; would otherwise be possible, as there exists a path from the root that contains all characters of the word \u0026ldquo;app\u0026rdquo;. This boolean lets us avoid the ambiguity.\nWe create a helper method getIndex that takes a character of\nclass Trie { private: vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor } Recursive solution search To search for a word in the trie, we start at the root and check if the pointer next[c], corresponding to the first character c, is not null. If it is null, the word is not present and we return false. If it isn\u0026rsquo;t, we recursively search if the remainder of the word is found in next[c]. If the word has no characters, we return true. This is the base case for recursion.\nbool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } It\u0026rsquo;s important to note that word.substr(1) creates another string object with just one element less than the original word. If \\(m\\) is the length of the word, this makes the recursion\u0026rsquo;s time complexity to \\(O(m^2)\\) and results in \\(O(m^2)\\) total allocated space. We could avoid allocating new memory by either:\ntreating word as a character array and incrementing the pointer to its beginning, passing in the index of the current word character, or using std::string_view from C++17 and greater. This would reduce the time complexity to the much more preferable \\(O(m)\\) and requires no additional allocated space. However, we keep this recursive implementation as it does not modify LeetCode\u0026rsquo;s framework. We\u0026rsquo;ll see later that an iterative solution makes this easy and avoids pointer manipulation.\ninsert Inserting a word into the trie is conceptualy similar to searching for it. We check if there is a trie, corresponding to the first character of word. If not, we create a trie for that character. Now that the trie surely exists, we insert the remainder of word into it. If the word has no characters, it has been fully inserted into the trie. At that point, we set wordEnd = true to indicate that the word belongs to the trie (separating it from its substrings).\nvoid insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } startsWith The startsWith function is very similar to the search function. The key difference is that the prefix may not have been inserted into the trie, but the path to it still exists. The only difference between search and startsWith is thus not checking if the word is contained in the trie during the recursive base case.\nbool startsWith(string prefix) { /* Returns `true` if there is a previously inserted word that starts with `prefix`, and `false` otherwise. */ if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } Full recursive solution We provide the full recursive solution below.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() { } void insert(string word) { if (word.size() == 0) { wordEnd = true; return; } int idx = getIndex(word[0]); if (!(next[idx])) { // If the Trie does not exist yet next[idx] = new Trie(); } next[idx]-\u0026gt;insert(word.substr(1)); } bool search(string word) { if (word.size() == 0) { return wordEnd; } int index = getIndex(word[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;search(word.substr(1)); } bool startsWith(string prefix) { if (prefix.size() == 0) { return true; } int index = getIndex(prefix[0]); if (!next[index]) { return false; } return next[index]-\u0026gt;startsWith(prefix.substr(1)); } }; Iterative solution The recursive solution is valid, but contains two sources of avoidable overhead:\nFor even moderately long words, we risk stack overflow and add considerable CPU overhead. Recursive calls use stack memory proportional to recursion depth (word length). We can avoid recursively entering a new stack frame when inserting a new word. Instead, we start with the root trie pointer and iteratively change it within a loop over word characters. Staying in a single frame like this is faster and uses less space. We modify the search and startsWith functions in a similar manner.\nBelow is the fully modified iterative solution.\nclass Trie { vector\u0026lt;Trie*\u0026gt; next = vector\u0026lt;Trie*\u0026gt;(26, nullptr); bool wordEnd = false; int getIndex(char query) { return query - \u0026#39;a\u0026#39;; } public: Trie() {} // Class constructor void insert(string word) { // Insert `word` into the trie Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { t-\u0026gt;next[idx] = new Trie(); } t = t-\u0026gt;next[idx]; } t-\u0026gt;wordEnd = true; } bool search(string word) { // Return true if the trie contains `word` and false otherwise Trie* t = this; for (int i = 0; i \u0026lt; word.size(); i++) { int idx = getIndex(word[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return t-\u0026gt;wordEnd; } bool startsWith(string prefix) { // Return true if the trie contains a word that starts with `prefix` Trie* t = this; for (int i = 0; i \u0026lt; prefix.size(); i++) { int idx = getIndex(prefix[i]); if (!t-\u0026gt;next[idx]) { return false; } t = t-\u0026gt;next[idx]; } return true; } }; Comparison between recursive and iterative solutions The actual runtime and memory consumption are indeed smaller for the iterative solution. LeetCode reports a runtime of 90ms and 145MB of memory for the recursive, but only 19ms and 54MB of memory for the iterative solution.\nThanks for reading! If you liked this post, you can support me on Ko-fi ☕. More LeetCode solutions coming soon :)\n","permalink":"http://localhost:1313/posts/leetcode_208/","summary":"\u003cp\u003eA \u003ca href=\"https://en.wikipedia.org/wiki/Trie\"\u003etrie\u003c/a\u003e is data structure which holds strings.\nIt allows fast search and insertion of strings, as well as fast search of string prefixes.\nThis can be especially useful for text autocompletion and spellcheck.\u003c/p\u003e\n\u003cp\u003eIn this post, we implement a trie in C++ with three basic operations: \u003ccode\u003esearch\u003c/code\u003e, \u003ccode\u003einsert\u003c/code\u003e, and \u003ccode\u003estartsWith\u003c/code\u003e.\nThis is the solution to \u003ca href=\"https://leetcode.com/problems/implement-trie-prefix-tree/description/\"\u003eLeetCode 208\u003c/a\u003e.\nThe problem assumes that all words use characters a-z in the English alphabet, but our solution can be extended to include more characters.\u003c/p\u003e","title":"LeetCode 208: Trie implementation"},{"content":"\nHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics. I use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\nI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana. For the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses. I do a lot of research on normalizing flows, a special family of generative models. I use flows to speed up MCMC by transforming difficult data spaces into simple ones. I\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley. I\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation. I\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\nFeel free to check out some of my recent papers:\nEmpirical evaluation of normalizing flows in Markov chain Monte Carlo (2025) Reducing normalizing flow complexity for MCMC preconditioning (2025) Control, Transport and Sampling: Towards Better Loss Design (2024) Accelerating astronomical and cosmological inference with preconditioned Monte Carlo (2022) I have a Github page that you\u0026rsquo;re welcome to follow and a LinkedIn profile for business. You can also send me an email: david at nabergoj dot org.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"David\" loading=\"lazy\" src=\"/david.jpg#avatar\"\u003e\u003c/p\u003e\n\u003cp\u003eHi! I\u0026rsquo;m David Nabergoj, a computer science researcher with a passion for machine learning, programming, and mathematics.\nI use this blog to share my learning journey, implement ML projects, and post solutions to interesting algorithm challenges.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m currently pursuing my PhD in computer science at the University of Ljubljana.\nFor the last four years, I\u0026rsquo;ve also been a TA for postgraduate probability and statistics courses.\nI do a lot of research on normalizing flows, a special family of generative models.\nI use flows to speed up MCMC by transforming difficult data spaces into simple ones.\nI\u0026rsquo;ve worked with fantastic people at the University of Ljubljana and UC Berkeley.\nI\u0026rsquo;ve delivered talks for the Flatiron institute and the American Slovenian Education Foundation.\nI\u0026rsquo;m also very proud and privileged to have won an award at the 2021 NASA/ESA/JAXA Earth Observation Dashboard competition with five amazing teammates.\u003c/p\u003e","title":"About Me"}]